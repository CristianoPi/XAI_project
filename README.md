# XAI_project

ğŸ¯ Obiettivo principale
	â€¢	Creare un dataset che evidenzi bias comuni (es. colori di sfondo, contesti ambientali).
	â€¢	Utilizzare quel dataset per testare un modello (o piÃ¹ modelli) e misurare le attivazioni (logits) per ogni classe.
	â€¢	Generare un report per ciascuna classe, che mostri in che misura il modello Ã¨ influenzato dai bias presenti.

â¸»

ğŸ§  Fase 1: Costruzione del dataset
	1.	Definisci le caratteristiche su cui indagare:
	â€¢	Ad esempio: sfondi (urbano, naturale, monocromo), dominanza di un colore (rosso, blu, verde), presenza di oggetti secondari (macchine, piante, persone).
	2.	Crea o raccogli immagini che coprano sistematicamente queste caratteristiche:
	â€¢	Puoi usare StableDiffusion o altre tecniche per generare le immagini con prompt come â€œa dog on a red backgroundâ€, â€œa cat in an urban environmentâ€, ecc.
	3.	Organizza il dataset in modo comparabile:
	â€¢	Ad esempio 100 immagini di cani su sfondo rosso, 100 su sfondo blu, 100 in ambiente urbano, ecc.
	â€¢	Le â€œclassiâ€ qui possono essere le entitÃ  da classificare (es. cane, gatto) o piÃ¹ semplicemente varianti di bias se vuoi studiare un solo soggetto.

â¸»

ğŸ§ª Fase 2: Testing e misurazione attivazioni
	1.	Passa le immagini attraverso il tuo modello (o modelli):
	â€¢	Ottieni il vettore di logits (valori prima del softmax) per ciascuna immagine.
	2.	Registra le attivazioni:
	â€¢	Per ogni immagine e per ciascuna classe considerata, misura lâ€™attivazione (logit).
	3.	Organizza i dati:
	â€¢	Per ogni classe target (es. â€œcaneâ€), metti in relazione lâ€™attivazione media con la caratteristica bias (es. sfondo rosso vs blu vs urbano).

â¸»

ğŸ§¾ Fase 3: Generazione report automatici con LLM
	1.	Prepara un prompt per un LLM (es. GPT-4):
	â€¢	Il prompt potrebbe includere una tabella (CSV o JSON) con colonne:
	â€¢	immagine ID, classe vera, caratteristica (tipo di bias), logits classe1, logits classe2, â€¦
	â€¢	Istruzioni del prompt:

â€œEcco i logits aggregati dal modello su un dataset diviso per bias.
 Per ciascuna classe (es. cane, gatto, autoâ€¦), analizza se ci sono differenze di attivazione
 legate al colore di sfondo o al contesto. Evidenzia tendenze, bias, suggerimenti su robustezza.â€


	2.	Ricevi in output il report:
	â€¢	LLM ti fornisce una narrazione per ogni classe, es.:
	â€¢	â€œIl modello attiva â€˜caneâ€™ piÃ¹ forte con sfondo rosso (+1.2 logit) rispetto al blu (+0.8)â€¦â€
	â€¢	â€œIl bias Ã¨ evidente: +0.4 logit significa che tende a preferire il rossoâ€.

â¸»

âœ… Risultati attesi
	â€¢	Due report:
	â€¢	Modello biasato (es. addestrato con immagini sbilanciate).
	â€¢	Modello senza bias (es. bilanciato o addestrato apposta).
	â€¢	I report devono mostrare comparativamente la sensibilitÃ  ai bias:
	â€¢	Quale classe Ã¨ piÃ¹ influenzata da cambi di colore/sfondo.
	â€¢	Quanto variano i logits tra condizioni.

â¸»

ğŸ“Œ In sintesi cosa devi fare
	1.	Progetta e costruisci un dataset pilota con vari livelli di bias (ad es. cani su sfondi diversi).
	2.	Esegui il modello sul dataset, estraendo i logits per ogni immagine/classe.
	3.	Aggrega i dati (medie, deviazioni) strutturandoli in un formato tabellare.
	4.	Invia i dati tabellari e le istruzioni a un LLM per ottenere il report finale.
	5.	Confronta i report tra il modello biasato e quello â€œcorrettoâ€ per dimostrare validitÃ  del sistema.
