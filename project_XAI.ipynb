{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a44d9906",
   "metadata": {},
   "source": [
    "## Project Overview: *Static Images Network Analyzer*\n",
    "\n",
    "This is the final project for the Cognitive Learning course, titled *Static Images Network Analyzer*.  \n",
    "The goal is to analyze **cognitive biases** in image classification models, focusing on **spurious correlations**â€”for example, when the model is influenced more by background context than by the actual object in the image.\n",
    "\n",
    "The project has two main phases:\n",
    "1. **Controlled dataset generation**: we created artificial images combining neutral objects with potentially bias-inducing visual contexts, using *Stable Diffusion v1.5*.  \n",
    "   > The image generation code is located in the file: `generate_dataset_diff_v1_5.py.py`.\n",
    "2. **Model analysis**: we evaluated how three pretrained classifiers (AlexNet, ResNet-18, ViT-18) responded to these images and measured whether their predictions aligned with the original prompt or were misled by context.  \n",
    "   > All analysis and evaluation steps are implemented in this notebook.\n",
    "\n",
    "We extract the **top-10 logits** for each image-model pair, and send both the original prompt and the predictions to a **language model (LLM)** for semantic auditing. The LLM provides a coherence score (0â€“1), a short explanation, and optional confidence. These evaluations are stored in a `.jsonl` file.\n",
    "\n",
    "Finally, we build an aggregated **bias report** using precomputed statistics and LLM-generated justifications. This final Markdown report includes:\n",
    "- Aggregate performance metrics\n",
    "- Recurring error patterns\n",
    "- Detailed list of incoherent predictions\n",
    "- Class-specific logit behavior\n",
    "- Overall model verdict\n",
    "\n",
    "This workflow allows us to systematically study the effect of **spurious visual cues** and assess the **robustness and reliability** of vision models through a cognitively informed pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3ae04aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip3 install -q openai pandas pyarrow pillow tqdm urllib3 pycocotools requests torch torchvision python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ec18c1",
   "metadata": {},
   "source": [
    "### CONFIGURATION: load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f2f68a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VISION_MODEL: vit_b_16\n",
      "LLM_MODEL: gpt-4o-mini\n",
      "OPENAI_API_KEY: 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\n",
      "IMG_DIR: dataset/images\n",
      "META_CSV: dataset/dataset_metadata.csv\n",
      "OUTPUT_DIR: analysis_vit_b_16_1\n",
      "COHERENCE_THRESHOLD: 0.3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carica da file .env se presente\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Variabili configurabili\n",
    "VISION_MODEL = os.getenv(\"VISION_MODEL\", \"alexnet\")\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"gpt-4o-mini\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "IMG_DIR = Path(os.getenv(\"IMG_DIR\", \"dataset_/images\"))\n",
    "META_CSV = Path(os.getenv(\"META_CSV\", \"dataset_/dataset_metadata.csv\"))\n",
    "OUTPUT_DIR = Path(os.getenv(\"OUTPUT_DIR\", \"analysis_out_\"))\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "COHERENCE_THRESHOLD = float(os.getenv(\"COHERENCE_TH\", 0.5))\n",
    "TARGET_CLASSES = os.getenv(\"TARGET_CLASSES\", \"pillow,toilet seat,park bench,laptop,fox squirrel,tennis ball\").split(\",\")\n",
    "\n",
    "print(f\"VISION_MODEL: {VISION_MODEL}\")\n",
    "print(f\"LLM_MODEL: {LLM_MODEL}\")\n",
    "print(f\"OPENAI_API_KEY: {OPENAI_API_KEY}\")\n",
    "print(f\"IMG_DIR: {IMG_DIR}\")\n",
    "print(f\"META_CSV: {META_CSV}\")\n",
    "print(f\"OUTPUT_DIR: {OUTPUT_DIR}\")\n",
    "print(f\"COHERENCE_THRESHOLD: {COHERENCE_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9334f0b1",
   "metadata": {},
   "source": [
    "### Load view model and ImageNet classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2bd4a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model dynamic loading\n",
    "model = getattr(models, VISION_MODEL)(pretrained=True).eval().to(device)\n",
    "\n",
    "#  ImageNet labels\n",
    "import urllib.request\n",
    "labels_url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "imagenet_labels = urllib.request.urlopen(labels_url).read().decode().splitlines()\n",
    "idx2label = {i: l for i, l in enumerate(imagenet_labels)}\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6111376e",
   "metadata": {},
   "source": [
    "### Top-10 Extraction\n",
    "\n",
    "The choice of 10 is not arbitrary.  \n",
    "Studies on ImageNet show that the **top ten logits** account for, on average, **over 95% of the softmax probability mass** in models such as **ResNet-50** or **ViT-B/16**.  \n",
    "This means that, in most cases, the remaining classes beyond the 10th position **contribute minimally to the overall semantic representation**.\n",
    "\n",
    "> Source: [arXiv:2206.07290](https://arxiv.org/pdf/2206.07290)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7db62bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121/121 [00:08<00:00, 14.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¾ Risultati salvati in: analysis_vit_b_16_1/logits.json\n",
      "\n",
      "âœ… Esempi di topâ€‘10 logits:\n",
      "\n",
      "ðŸ“Œ dataset/images/bookjacket__classroom__001.png\n",
      "Prompt: A neutral bookjacket in a classroom background\n",
      "Topâ€‘10 logits (softmax):\n",
      "  - 549: envelope (0.388)\n",
      "  - 767: rubber eraser (0.129)\n",
      "  - 769: rule (0.095)\n",
      "  - 446: binder (0.036)\n",
      "  - 921: book jacket (0.018)\n",
      "  - 418: ballpoint (0.018)\n",
      "  - 624: library (0.013)\n",
      "  - 419: Band Aid (0.012)\n",
      "  - 893: wallet (0.008)\n",
      "  - 623: letter opener (0.008)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 1.01\n",
      "  - 861: toilet seat = -0.11\n",
      "  - 703: park bench = 0.61\n",
      "  - 620: laptop = 1.22\n",
      "  - 335: fox squirrel = -0.63\n",
      "  - 852: tennis ball = -1.31\n",
      "\n",
      "ðŸ“Œ dataset/images/bookjacket__classroom__002.png\n",
      "Prompt: A neutral bookjacket in a classroom background\n",
      "Topâ€‘10 logits (softmax):\n",
      "  - 549: envelope (0.399)\n",
      "  - 893: wallet (0.088)\n",
      "  - 921: book jacket (0.084)\n",
      "  - 446: binder (0.053)\n",
      "  - 563: fountain pen (0.048)\n",
      "  - 418: ballpoint (0.045)\n",
      "  - 623: letter opener (0.032)\n",
      "  - 769: rule (0.017)\n",
      "  - 681: notebook (0.015)\n",
      "  - 583: guillotine (0.012)\n",
      "Logits classi target:\n",
      "  - 721: pillow = -0.29\n",
      "  - 861: toilet seat = -0.70\n",
      "  - 703: park bench = -0.77\n",
      "  - 620: laptop = 2.95\n",
      "  - 335: fox squirrel = -0.12\n",
      "  - 852: tennis ball = -0.86\n",
      "\n",
      "ðŸ“Œ dataset/images/bookjacket__garage__002.png\n",
      "Prompt: A neutral bookjacket in a garage background\n",
      "Topâ€‘10 logits (softmax):\n",
      "  - 587: hammer (0.764)\n",
      "  - 784: screwdriver (0.146)\n",
      "  - 477: carpenter's kit (0.011)\n",
      "  - 754: radio (0.005)\n",
      "  - 783: screw (0.003)\n",
      "  - 473: can opener (0.001)\n",
      "  - 896: washbasin (0.001)\n",
      "  - 596: hatchet (0.001)\n",
      "  - 707: pay-phone (0.001)\n",
      "  - 648: medicine chest (0.001)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 0.35\n",
      "  - 861: toilet seat = 0.38\n",
      "  - 703: park bench = -0.31\n",
      "  - 620: laptop = 1.13\n",
      "  - 335: fox squirrel = -0.71\n",
      "  - 852: tennis ball = -0.60\n",
      "\n",
      "ðŸ“Œ dataset/images/bookjacket__green__001.png\n",
      "Prompt: A neutral bookjacket in a green background\n",
      "Topâ€‘10 logits (softmax):\n",
      "  - 921: book jacket (0.743)\n",
      "  - 446: binder (0.186)\n",
      "  - 620: laptop (0.011)\n",
      "  - 549: envelope (0.007)\n",
      "  - 681: notebook (0.006)\n",
      "  - 592: hard disc (0.006)\n",
      "  - 917: comic book (0.002)\n",
      "  - 893: wallet (0.001)\n",
      "  - 922: menu (0.001)\n",
      "  - 481: cassette (0.001)\n",
      "Logits classi target:\n",
      "  - 721: pillow = -1.38\n",
      "  - 861: toilet seat = -0.61\n",
      "  - 703: park bench = 0.56\n",
      "  - 620: laptop = 5.86\n",
      "  - 335: fox squirrel = -0.20\n",
      "  - 852: tennis ball = 0.32\n",
      "\n",
      "ðŸ“Œ dataset/images/bookjacket__green__002.png\n",
      "Prompt: A neutral bookjacket in a green background\n",
      "Topâ€‘10 logits (softmax):\n",
      "  - 549: envelope (0.470)\n",
      "  - 921: book jacket (0.178)\n",
      "  - 446: binder (0.167)\n",
      "  - 692: packet (0.086)\n",
      "  - 749: quill (0.004)\n",
      "  - 922: menu (0.003)\n",
      "  - 769: rule (0.002)\n",
      "  - 868: tray (0.002)\n",
      "  - 623: letter opener (0.002)\n",
      "  - 741: prayer rug (0.002)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 0.51\n",
      "  - 861: toilet seat = -1.08\n",
      "  - 703: park bench = -0.16\n",
      "  - 620: laptop = 0.51\n",
      "  - 335: fox squirrel = 0.04\n",
      "  - 852: tennis ball = 0.15\n",
      "\n",
      "ðŸ“Œ dataset/images/bookjacket__hotel__001.png\n",
      "Prompt: A neutral bookjacket in a hotel background\n",
      "Topâ€‘10 logits (softmax):\n",
      "  - 921: book jacket (0.336)\n",
      "  - 591: handkerchief (0.167)\n",
      "  - 789: shoji (0.124)\n",
      "  - 446: binder (0.062)\n",
      "  - 563: fountain pen (0.020)\n",
      "  - 749: quill (0.017)\n",
      "  - 846: table lamp (0.008)\n",
      "  - 549: envelope (0.007)\n",
      "  - 619: lampshade (0.007)\n",
      "  - 893: wallet (0.007)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 1.03\n",
      "  - 861: toilet seat = 0.31\n",
      "  - 703: park bench = -0.20\n",
      "  - 620: laptop = 1.79\n",
      "  - 335: fox squirrel = -0.04\n",
      "  - 852: tennis ball = 0.13\n",
      "\n",
      "ðŸ“Œ dataset/images/bookjacket__hotel__002.png\n",
      "Prompt: A neutral bookjacket in a hotel background\n",
      "Topâ€‘10 logits (softmax):\n",
      "  - 905: window shade (0.061)\n",
      "  - 515: cowboy hat (0.051)\n",
      "  - 619: lampshade (0.038)\n",
      "  - 859: toaster (0.036)\n",
      "  - 789: shoji (0.033)\n",
      "  - 673: mouse (0.029)\n",
      "  - 968: cup (0.026)\n",
      "  - 714: pick (0.023)\n",
      "  - 846: table lamp (0.019)\n",
      "  - 534: dishwasher (0.017)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 0.90\n",
      "  - 861: toilet seat = 1.30\n",
      "  - 703: park bench = -0.60\n",
      "  - 620: laptop = 2.04\n",
      "  - 335: fox squirrel = -0.23\n",
      "  - 852: tennis ball = 0.61\n",
      "\n",
      "ðŸ“Œ dataset/images/bookjacket__kitchen__002.png\n",
      "Prompt: A neutral bookjacket in a kitchen background\n",
      "Topâ€‘10 logits (softmax):\n",
      "  - 921: book jacket (0.516)\n",
      "  - 681: notebook (0.245)\n",
      "  - 446: binder (0.066)\n",
      "  - 620: laptop (0.019)\n",
      "  - 868: tray (0.013)\n",
      "  - 778: scale (0.008)\n",
      "  - 549: envelope (0.006)\n",
      "  - 662: modem (0.005)\n",
      "  - 592: hard disc (0.004)\n",
      "  - 831: studio couch (0.003)\n",
      "Logits classi target:\n",
      "  - 721: pillow = -0.87\n",
      "  - 861: toilet seat = 0.84\n",
      "  - 703: park bench = -0.30\n",
      "  - 620: laptop = 5.27\n",
      "  - 335: fox squirrel = 0.02\n",
      "  - 852: tennis ball = -0.09\n",
      "\n",
      "ðŸ“Œ dataset/images/bookjacket__minimalist__001.png\n",
      "Prompt: A neutral bookjacket in a minimalist background\n",
      "Topâ€‘10 logits (softmax):\n",
      "  - 921: book jacket (0.469)\n",
      "  - 549: envelope (0.055)\n",
      "  - 446: binder (0.051)\n",
      "  - 767: rubber eraser (0.044)\n",
      "  - 868: tray (0.024)\n",
      "  - 563: fountain pen (0.021)\n",
      "  - 681: notebook (0.014)\n",
      "  - 648: medicine chest (0.013)\n",
      "  - 464: buckle (0.011)\n",
      "  - 626: lighter (0.009)\n",
      "Logits classi target:\n",
      "  - 721: pillow = -0.87\n",
      "  - 861: toilet seat = 1.45\n",
      "  - 703: park bench = 0.71\n",
      "  - 620: laptop = 1.36\n",
      "  - 335: fox squirrel = -0.10\n",
      "  - 852: tennis ball = -0.31\n",
      "\n",
      "ðŸ“Œ dataset/images/bookjacket__minimalist__002.png\n",
      "Prompt: A neutral bookjacket in a minimalist background\n",
      "Topâ€‘10 logits (softmax):\n",
      "  - 921: book jacket (0.284)\n",
      "  - 446: binder (0.270)\n",
      "  - 681: notebook (0.057)\n",
      "  - 549: envelope (0.048)\n",
      "  - 563: fountain pen (0.025)\n",
      "  - 823: stethoscope (0.018)\n",
      "  - 592: hard disc (0.013)\n",
      "  - 605: iPod (0.009)\n",
      "  - 778: scale (0.005)\n",
      "  - 632: loudspeaker (0.005)\n",
      "Logits classi target:\n",
      "  - 721: pillow = -2.42\n",
      "  - 861: toilet seat = -1.26\n",
      "  - 703: park bench = 0.39\n",
      "  - 620: laptop = 2.47\n",
      "  - 335: fox squirrel = -0.13\n",
      "  - 852: tennis ball = -0.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "import os \n",
    "\n",
    "def get_topk(logits, k=10):\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    top_p, top_i = torch.topk(probs, k)\n",
    "    return [(int(i), (idx2label[int(i)], float(p))) for p, i in zip(top_p.cpu(), top_i.cpu())]\n",
    "# Softmax is monotonic, so it can be used to rank logits, is more interpretable than raw logits for us and for LLM.\n",
    "\n",
    "def get_class_logits(logits, target_ids):\n",
    "    return {i: float(logits[i].cpu()) for i in target_ids}\n",
    "\n",
    "# load prompts from CSV\n",
    "prompts = {}\n",
    "with open(META_CSV, newline='') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        prompts[Path(row[\"file_name\"].strip()).name] = row[\"prompt\"]\n",
    "\n",
    "########### \n",
    "# target classes, for pt. 4 of the report  \n",
    "target_classes = TARGET_CLASSES\n",
    "labels_url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "imagenet_labels = urllib.request.urlopen(labels_url).read().decode().splitlines()\n",
    "idx2label = {i: l for i, l in enumerate(imagenet_labels)}\n",
    "label2idx = {l: i for i, l in enumerate(imagenet_labels)}\n",
    "target_ids = {label2idx[c]: c for c in target_classes}\n",
    "per_class_logit = defaultdict(list)\n",
    "#########\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "# Image analysis\n",
    "for img_path in tqdm(sorted(IMG_DIR.glob(\"*.png\"))):\n",
    "    prompt = prompts.get(img_path.name)\n",
    "    if not prompt:\n",
    "        continue\n",
    "\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    with torch.no_grad():\n",
    "        logits = model(transform(image).unsqueeze(0).to(device))[0]\n",
    "\n",
    "    # Softmax topâ€‘10 logits\n",
    "    top_logits = get_topk(logits, k=10)\n",
    "\n",
    "    # Raw Logits of 6 target classes\n",
    "    selected_logits = get_class_logits(logits, target_ids.keys())\n",
    "\n",
    "    results.append({\n",
    "        \"file_name\": str(img_path),\n",
    "        \"prompt\": prompt,\n",
    "        \"top_logits\": top_logits,\n",
    "        \"class_logits\": selected_logits\n",
    "    })\n",
    "\n",
    "    # aggregate per class (for the dedicated report)\n",
    "    for cls_id, val in selected_logits.items():\n",
    "        per_class_logit[cls_id].append({\n",
    "            \"file_name\": str(img_path),\n",
    "            \"prompt\": prompt,\n",
    "            \"logit\": val\n",
    "        })\n",
    "\n",
    "\n",
    "# Percorso del file in cui salvare i risultati\n",
    "LOGIT_RESULTS = Path(os.getenv(\"OUTPUT_DIR\", \"analysis_out\")) / \"logits.json\"\n",
    "\n",
    "# Salva i risultati in JSON\n",
    "with open(LOGIT_RESULTS, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nðŸ’¾ Risultati salvati in: {LOGIT_RESULTS}\")\n",
    "# Debug/preview\n",
    "print(\"\\nâœ… Esempi di topâ€‘10 logits:\")\n",
    "for r in results[:10]:\n",
    "    print(f\"\\nðŸ“Œ {r['file_name']}\")\n",
    "    print(f\"Prompt: {r['prompt']}\")\n",
    "    print(\"Topâ€‘10 logits (softmax):\")\n",
    "    for i, (label, p) in r[\"top_logits\"]:\n",
    "        print(f\"  - {i}: {label} ({p:.3f})\")\n",
    "    print(\"Logits classi target:\")\n",
    "    for i, val in r[\"class_logits\"].items():\n",
    "        print(f\"  - {i}: {idx2label[i]} = {val:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d479795",
   "metadata": {},
   "source": [
    "### LLM Coherence Audit \n",
    "\n",
    "This script audits the coherence between a prompt and a vision model's top-10 predictions using an LLM.\n",
    "\n",
    "- **`query_llm()`** sends the prompt and logits to an OpenAI model, which returns a JSON with a coherence `score`, a short `explanation`, and optional `confidence`.\n",
    "- A prediction is considered coherent if the score â‰¥ `COHERENCE_THRESHOLD` (default: 0.3).\n",
    "- Results are saved to `.jsonl` and `.txt` files.\n",
    "- The final report includes total examples, coherence rate, and breakdowns by object and context.\n",
    "\n",
    "This allows for automated semantic auditing of vision-language model outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fc0a408d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COHERENCE_THRESHOLD: 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM analysis: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121/121 [02:41<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== SUMMARY ==========\n",
      "Total images:   121\n",
      "Incoherent (<0.3): 33  (27.3 %)\n",
      "\n",
      "-- Incoherence by *object* --\n",
      "  bookjacket                         : 8/15  (53.3 %)\n",
      "  ceramiccoffeemug                   : 1/16  (6.2 %)\n",
      "  grannysmith                        : 6/15  (40.0 %)\n",
      "  notebookwithkraftcover             : 10/15  (66.7 %)\n",
      "  opaquemetalwaterbottle             : 6/20  (30.0 %)\n",
      "  softcouchpillow                    : 0/20  (0.0 %)\n",
      "  tablelampwithshadeoff              : 2/20  (10.0 %)\n",
      "\n",
      "-- Incoherence by *context* --\n",
      "  bathroom                           : 3/8  (37.5 %)\n",
      "  classroom                          : 2/12  (16.7 %)\n",
      "  garage                             : 4/10  (40.0 %)\n",
      "  green                              : 3/12  (25.0 %)\n",
      "  hotel                              : 3/14  (21.4 %)\n",
      "  kitchen                            : 2/12  (16.7 %)\n",
      "  minimalist                         : 3/14  (21.4 %)\n",
      "  modern                             : 7/14  (50.0 %)\n",
      "  plain                              : 3/14  (21.4 %)\n",
      "  science                            : 3/11  (27.3 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import openai, json, re, os, sys\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "from typing import List, Optional\n",
    "import csv\n",
    "from pathlib import Path \n",
    "\n",
    "# OpenAI API configuration\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Parameters\n",
    "COHERENCE_THRESHOLD = float(os.getenv(\"COHERENCE_TH\", 0.3))\n",
    "META_CSV = Path(os.getenv(\"META_CSV\", \"dataset/dataset_metadata.csv\"))\n",
    "LOG_JSONL_PATH = Path(os.getenv(\"OUTPUT_DIR\", \"analysis_out\")) / \"llm_audit.jsonl\"\n",
    "LIVE_TXT_PATH = Path(os.getenv(\"OUTPUT_DIR\", \"analysis_out\")) / \"llm_live_output.txt\"\n",
    "LOGIT_RESULTS = Path(os.getenv(\"OUTPUT_DIR\", \"analysis_out\")) / \"logits.json\"\n",
    "\n",
    "print(f\"COHERENCE_THRESHOLD: {COHERENCE_THRESHOLD}\")\n",
    "\n",
    "# Load logits JSON file\n",
    "with open(LOGIT_RESULTS, \"r\", encoding=\"utf-8\") as f:\n",
    "    logits_data = json.load(f)\n",
    "\n",
    "# Normalize file names to match those in metadata CSV\n",
    "def normalize_filename(path: str) -> str:\n",
    "    return Path(path).name  \n",
    "\n",
    "logits_lookup = {\n",
    "    normalize_filename(entry[\"file_name\"]): entry[\"top_logits\"]\n",
    "    for entry in logits_data\n",
    "}\n",
    "\n",
    "# Function to extract JSON from text\n",
    "def extract_json_from_text(text: str) -> dict:\n",
    "    m = re.search(r\"\\{.*?\\}\", text, re.DOTALL)\n",
    "    if not m:\n",
    "        raise ValueError(\"âš ï¸ No valid JSON found\")\n",
    "    return json.loads(m.group(0))\n",
    "\n",
    "# Function to query the LLM\n",
    "def query_llm(prompt: str, top_logits, vision_model: str) -> dict:\n",
    "    def safe_label_prob(item):\n",
    "        try:\n",
    "            label = str(item[0])\n",
    "            prob_raw = item[1]\n",
    "            prob = float(prob_raw[0]) if isinstance(prob_raw, (tuple, list)) else float(prob_raw)\n",
    "            return f\"{label} ({prob:.3f})\"\n",
    "        except Exception:\n",
    "            return f\"[MALFORMED: {item}]\"\n",
    "\n",
    "    top_str = \"; \".join([safe_label_prob(it) for it in top_logits])\n",
    "\n",
    "    user_msg = f\"\"\"\n",
    "You are auditing the output of **{vision_model}** to assess alignment with the prompt.\n",
    "\n",
    "Prompt:\n",
    "\\\"{prompt}\\\"\n",
    "\n",
    "Top-10 predictions with probabilities:\n",
    "{top_str}\n",
    "\n",
    "Return JSON only:\n",
    "{{\n",
    "  \"score\": <float 0-1>,\n",
    "  \"explanation\": <â‰¤25 words>,\n",
    "  \"confidence\": <float 0-1 (optional)>\n",
    "}}\n",
    "Be lenient; score â‰¥ 0.3 is considered coherent.\n",
    "\"\"\"\n",
    "\n",
    "    res = openai.chat.completions.create(\n",
    "        model=os.getenv(\"LLM_MODEL\", \"gpt-4o-mini\"),\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Return strict JSON only.\"},\n",
    "            {\"role\": \"user\", \"content\": user_msg}\n",
    "        ],\n",
    "        temperature=0.0\n",
    "    )\n",
    "    return extract_json_from_text(res.choices[0].message.content.strip())\n",
    "\n",
    "# Load dataset_metadata.csv\n",
    "metadata = []\n",
    "with open(META_CSV, newline='', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        metadata.append(row)\n",
    "\n",
    "# Variables for counting\n",
    "tot = tot_incoh = 0\n",
    "per_obj_tot = Counter()\n",
    "per_obj_incoh = Counter()\n",
    "per_ctx_tot = Counter()\n",
    "per_ctx_incoh = Counter()\n",
    "incoherent_cases = []\n",
    "\n",
    "# Main loop\n",
    "with open(LOG_JSONL_PATH, \"w\") as fout, open(LIVE_TXT_PATH, \"w\") as live:\n",
    "    for row in tqdm(metadata, desc=\"LLM analysis\"):\n",
    "        tot += 1\n",
    "        prompt = row[\"prompt\"]\n",
    "        obj = row[\"object\"]\n",
    "        ctx = row[\"background\"]\n",
    "\n",
    "        file_key = Path(row[\"file_name\"]).name\n",
    "        top_logits = logits_lookup.get(file_key, [])\n",
    "\n",
    "        per_obj_tot[obj] += 1\n",
    "        per_ctx_tot[ctx] += 1\n",
    "\n",
    "        # Query LLM\n",
    "        llm_out = query_llm(prompt, top_logits, os.getenv(\"VISION_MODEL\", \"alexnet\"))\n",
    "        record = {\n",
    "            **row,\n",
    "            **llm_out,\n",
    "            \"subject\": obj,\n",
    "            \"background\": ctx,\n",
    "            \"top_logits\": top_logits \n",
    "        }\n",
    "\n",
    "        fout.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "        live.write(json.dumps({\n",
    "            \"id\": tot,\n",
    "            \"score\": llm_out.get(\"score\"),\n",
    "            \"explanation\": llm_out.get(\"explanation\")\n",
    "        }, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "        if llm_out.get(\"score\", 0.0) < COHERENCE_THRESHOLD:\n",
    "            incoherent_cases.append(record)\n",
    "            tot_incoh += 1\n",
    "            per_obj_incoh[obj] += 1\n",
    "            per_ctx_incoh[ctx] += 1\n",
    "\n",
    "# Final report\n",
    "print(\"\\n========== SUMMARY ==========\")\n",
    "pct = 100 * tot_incoh / tot if tot else 0\n",
    "print(f\"Total images:   {tot}\")\n",
    "print(f\"Incoherent (<{COHERENCE_THRESHOLD}): {tot_incoh}  ({pct:.1f} %)\")\n",
    "\n",
    "print(\"\\n-- Incoherence by *object* --\")\n",
    "for o in sorted(per_obj_tot):\n",
    "    pct = 100 * per_obj_incoh[o] / per_obj_tot[o] if per_obj_tot[o] else 0\n",
    "    print(f\"  {o:35s}: {per_obj_incoh[o]}/{per_obj_tot[o]}  ({pct:.1f} %)\")\n",
    "\n",
    "print(\"\\n-- Incoherence by *context* --\")\n",
    "for c in sorted(per_ctx_tot):\n",
    "    pct = 100 * per_ctx_incoh[c] / per_ctx_tot[c] if per_ctx_tot[c] else 0\n",
    "    print(f\"  {c:35s}: {per_ctx_incoh[c]}/{per_ctx_tot[c]}  ({pct:.1f} %)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaae9b7a",
   "metadata": {},
   "source": [
    "### Bias Report & Model Verdict (Uses Pre-computed Metrics)\n",
    "\n",
    "This cell generates a bias analysis and verdict for the vision model based on previously computed LLM coherence scores and raw logits.\n",
    "\n",
    "- Loads all results from the audit (`llm_audit.jsonl`) and filters incoherent cases (`score` < threshold).\n",
    "- Computes global statistics: total images, mean/median/stdev scores, incoherence rates by object and context.\n",
    "- Analyzes raw logits per target class: average activations, top-5 examples.\n",
    "- Constructs a structured prompt for the LLM including:\n",
    "  - (A) global metrics\n",
    "  - (B) incoherent examples\n",
    "  - (C) target class activation stats\n",
    "- The LLM returns a detailed Markdown report with six required sections, including bias patterns and an overall model verdict.\n",
    "- Final report is saved as `report.md`.\n",
    "\n",
    "This step automates bias evaluation and model reliability assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b1d1a650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Target Class Analysis (Raw Logits)\n",
      "\n",
      "### Class `pillow` (ImageNet #721)\n",
      "- Average logit: 1.16 (std: 3.38)\n",
      "- Topâ€‘5 activations:\n",
      "  - `dataset/images/softcouchpillow__plain__001.png` â†’ logit=9.78\n",
      "  - `dataset/images/softcouchpillow__kitchen__001.png` â†’ logit=9.51\n",
      "  - `dataset/images/softcouchpillow__bathroom__001.png` â†’ logit=9.41\n",
      "  - `dataset/images/softcouchpillow__kitchen__002.png` â†’ logit=9.17\n",
      "  - `dataset/images/softcouchpillow__modern__002.png` â†’ logit=9.12\n",
      "\n",
      "### Class `toilet seat` (ImageNet #861)\n",
      "- Average logit: -0.19 (std: 1.08)\n",
      "- Topâ€‘5 activations:\n",
      "  - `dataset/images/ceramiccoffeemug__bathroom__001.png` â†’ logit=4.79\n",
      "  - `dataset/images/softcouchpillow__minimalist__001.png` â†’ logit=2.89\n",
      "  - `dataset/images/opaquemetalwaterbottle__bathroom__001.png` â†’ logit=2.69\n",
      "  - `dataset/images/bookjacket__plain__002.png` â†’ logit=2.59\n",
      "  - `dataset/images/ceramiccoffeemug__kitchen__001.png` â†’ logit=1.91\n",
      "\n",
      "### Class `park bench` (ImageNet #703)\n",
      "- Average logit: 0.06 (std: 0.56)\n",
      "- Topâ€‘5 activations:\n",
      "  - `dataset/images/softcouchpillow__science__001.png` â†’ logit=1.83\n",
      "  - `dataset/images/tablelampwithshadeoff__garage__002.png` â†’ logit=1.72\n",
      "  - `dataset/images/tablelampwithshadeoff__classroom__002.png` â†’ logit=1.68\n",
      "  - `dataset/images/softcouchpillow__green__001.png` â†’ logit=1.13\n",
      "  - `dataset/images/opaquemetalwaterbottle__green__002.png` â†’ logit=1.01\n",
      "\n",
      "### Class `laptop` (ImageNet #620)\n",
      "- Average logit: 0.81 (std: 1.37)\n",
      "- Topâ€‘5 activations:\n",
      "  - `dataset/images/bookjacket__green__001.png` â†’ logit=5.86\n",
      "  - `dataset/images/notebookwithkraftcover__science__001.png` â†’ logit=5.54\n",
      "  - `dataset/images/bookjacket__kitchen__002.png` â†’ logit=5.27\n",
      "  - `dataset/images/ceramiccoffeemug__modern__001.png` â†’ logit=4.38\n",
      "  - `dataset/images/notebookwithkraftcover__modern__001.png` â†’ logit=4.26\n",
      "\n",
      "### Class `fox squirrel` (ImageNet #335)\n",
      "- Average logit: -0.05 (std: 0.34)\n",
      "- Topâ€‘5 activations:\n",
      "  - `dataset/images/grannysmith__green__002.png` â†’ logit=0.71\n",
      "  - `dataset/images/softcouchpillow__modern__002.png` â†’ logit=0.70\n",
      "  - `dataset/images/softcouchpillow__science__002.png` â†’ logit=0.59\n",
      "  - `dataset/images/grannysmith__bathroom__002.png` â†’ logit=0.53\n",
      "  - `dataset/images/ceramiccoffeemug__kitchen__002.png` â†’ logit=0.49\n",
      "\n",
      "### Class `tennis ball` (ImageNet #852)\n",
      "- Average logit: 0.23 (std: 0.85)\n",
      "- Topâ€‘5 activations:\n",
      "  - `dataset/images/grannysmith__hotel__002.png` â†’ logit=3.52\n",
      "  - `dataset/images/grannysmith__green__002.png` â†’ logit=3.39\n",
      "  - `dataset/images/grannysmith__classroom__001.png` â†’ logit=2.46\n",
      "  - `dataset/images/grannysmith__minimalist__002.png` â†’ logit=2.44\n",
      "  - `dataset/images/ceramiccoffeemug__green__002.png` â†’ logit=2.03\n",
      "\n",
      "âœ… Report saved to: analysis_vit_b_16_1/report.md\n"
     ]
    }
   ],
   "source": [
    "import json, openai, statistics, os\n",
    "from pathlib import Path\n",
    "from statistics import mean, stdev\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# â”€â”€ load all the records from previous cell â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "with open(LOG_JSONL_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    records = [json.loads(l) for l in f]\n",
    "\n",
    "# Limit top_logits to 5 for each record\n",
    "for rec in records:\n",
    "    rec[\"top_logits\"] = rec.get(\"top_logits\", [])[:5]\n",
    "\n",
    "# List of incoherent records (those with score < COHERENCE_THRESHOLD)\n",
    "incoherent_recs = [\n",
    "    {k: rec[k] for k in (\"file_name\", \"prompt\", \"top_logits\", \"score\", \"explanation\")}\n",
    "    for rec in records if rec.get(\"score\", 0) < COHERENCE_THRESHOLD\n",
    "]\n",
    "\n",
    "# â”€â”€ global metrics already computed in previous cell â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "scores = [rec.get(\"score\", 0.0) for rec in records]\n",
    "metrics_summary = {\n",
    "    \"total_images\": tot,\n",
    "    \"mean_score\": statistics.mean(scores) if scores else 0.0,\n",
    "    \"median_score\": statistics.median(scores) if scores else 0.0,\n",
    "    \"stdev_score\": statistics.pstdev(scores) if len(scores) > 1 else 0.0,\n",
    "    \"percent_incoherent\": 100 * tot_incoh / tot if tot else 0.0,\n",
    "    \"object_stats\": {\n",
    "        obj: {\n",
    "            \"total\": per_obj_tot[obj],\n",
    "            \"incoherent\": per_obj_incoh[obj],\n",
    "            \"percent_incoherent\": 100 * per_obj_incoh[obj] / per_obj_tot[obj]\n",
    "            if per_obj_tot[obj] else 0.0\n",
    "        }\n",
    "        for obj in per_obj_tot\n",
    "    },\n",
    "    \"context_stats\": {\n",
    "        ctx: {\n",
    "            \"total\": per_ctx_tot[ctx],\n",
    "            \"incoherent\": per_ctx_incoh[ctx],\n",
    "            \"percent_incoherent\": 100 * per_ctx_incoh[ctx] / per_ctx_tot[ctx]\n",
    "            if per_ctx_tot[ctx] else 0.0\n",
    "        }\n",
    "        for ctx in per_ctx_tot\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save metrics to file (may be useful)\n",
    "Path(OUTPUT_DIR /  \"metrics.json\").write_text(json.dumps(metrics_summary, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "logit_report_section = \"\\n## Target Class Analysis (Raw Logits)\\n\"\n",
    "for cls_id, cls_name in target_ids.items():\n",
    "    values = [x[\"logit\"] for x in per_class_logit[cls_id]]\n",
    "    if not values:\n",
    "        continue\n",
    "\n",
    "    logit_report_section += f\"\\n### Class `{cls_name}` (ImageNet #{cls_id})\\n\"\n",
    "    logit_report_section += f\"- Average logit: {mean(values):.2f} (std: {stdev(values):.2f})\\n\"\n",
    "    logit_report_section += \"- Topâ€‘5 activations:\\n\"\n",
    "    top5 = sorted(per_class_logit[cls_id], key=lambda x: -x[\"logit\"])[:5]\n",
    "    for e in top5:\n",
    "       logit_report_section += f\"  - `{e['file_name']}` â†’ logit={e['logit']:.2f}\\n\"\n",
    "\n",
    "print(logit_report_section)\n",
    "\n",
    "# â”€â”€ Prompt for LLM â”€â”€â”€â”€â”€â”€\n",
    "prompt_header = f\"\"\"\n",
    "You are an AI-bias auditor.  \n",
    "Below you will find **(A) pre-computed global metrics**, **(B) per-image data**, and **(C) target class logit analysis**.\n",
    "\n",
    "Use the provided metrics; do NOT recalsculate means or percentages yourself.\n",
    "Respond in **Markdown** with the requested sections.\n",
    "\n",
    "## Required sections\n",
    "### 1 Aggregate statistics\n",
    "Summarise the numbers from (A).\n",
    "\n",
    "### 2 Recurring error patterns\n",
    "Identify frequent error types and link them to biases in **{VISION_MODEL}**.\n",
    "\n",
    "### 3 Detailed list of incoherent images\n",
    "For every image in (B) (score < {COHERENCE_THRESHOLD}) list:\n",
    "â€¢ file_name  â€¢ â‰¤15-word prompt summary  â€¢ three worst labels  â€¢ explanation (â‰¤2 sentences).\n",
    "\n",
    "### 4 Target class logit analysis (Full Details)\n",
    "Include the full details of the target class analysis from (C).  \n",
    "For each class, provide:\n",
    "- Average logit and standard deviation.\n",
    "- Top-5 activations with file names.\n",
    "- A comment on potential biases that could explain the activations (e.g., spurious correlations, over-reliance on context, etc.).\n",
    "### 5 Main biases of the model\n",
    "At least three systematic biases, with examples.\n",
    "\n",
    "### 6 Overall verdict\n",
    "Bullet strengths/weaknesses of **{VISION_MODEL}** + final reliability rating 1â€“5 (no mitigation advice).\n",
    "\n",
    "Respond **only** in Markdown, start each major section with '##'.\n",
    "\"\"\"\n",
    "\n",
    "payload = (\n",
    "    prompt_header\n",
    "    + \"\\n\\n### (A) Global metrics\\n```json\\n\"\n",
    "    + json.dumps(metrics_summary, ensure_ascii=False, indent=2)\n",
    "    + \"\\n```\\n\\n### (B) Incoherent images\\n```json\\n\"\n",
    "    + json.dumps(incoherent_recs, ensure_ascii=False)\n",
    "    + \"\\n```\\n\\n### (C) Target class logit analysis (Full Details)\\n\"\n",
    "    + logit_report_section\n",
    ")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=LLM_MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": \"You are a senior AI-bias analyst who MUST reply in Markdown headings.\"},\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": payload}\n",
    "    ],\n",
    "    temperature=0.25\n",
    ")\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "report_path = OUTPUT_DIR / \"report.md\"\n",
    "report_path.write_text(response.choices[0].message.content, encoding=\"utf-8\")\n",
    "print(\"âœ… Report saved to:\", report_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81372111",
   "metadata": {},
   "source": [
    "ðŸ“º Visualizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cfa58426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report salvato in: analysis_vit_b_16_1/report.md\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## 1 Aggregate statistics\n",
       "- **Total Images**: 121\n",
       "- **Mean Score**: 0.42\n",
       "- **Median Score**: 0.4\n",
       "- **Standard Deviation of Scores**: 0.23\n",
       "- **Percentage of Incoherent Images**: 27.27%\n",
       "- **Object Incoherence**:\n",
       "  - **Bookjacket**: 53.33% incoherent (8/15)\n",
       "  - **Ceramic Coffee Mug**: 6.25% incoherent (1/16)\n",
       "  - **Granny Smith**: 40.0% incoherent (6/15)\n",
       "  - **Notebook with Kraft Cover**: 66.67% incoherent (10/15)\n",
       "  - **Opaque Metal Water Bottle**: 30.0% incoherent (6/20)\n",
       "  - **Soft Couch Pillow**: 0.0% incoherent (0/20)\n",
       "  - **Table Lamp with Shade Off**: 10.0% incoherent (2/20)\n",
       "- **Context Incoherence**:\n",
       "  - **Classroom**: 16.67% incoherent (2/12)\n",
       "  - **Garage**: 40.0% incoherent (4/10)\n",
       "  - **Green**: 25.0% incoherent (3/12)\n",
       "  - **Hotel**: 21.43% incoherent (3/14)\n",
       "  - **Kitchen**: 16.67% incoherent (2/12)\n",
       "  - **Minimalist**: 21.43% incoherent (3/14)\n",
       "  - **Modern**: 50.0% incoherent (7/14)\n",
       "  - **Plain**: 21.43% incoherent (3/14)\n",
       "  - **Science**: 27.27% incoherent (3/11)\n",
       "  - **Bathroom**: 37.5% incoherent (3/8)\n",
       "\n",
       "## 2 Recurring error patterns\n",
       "- **Misalignment with Context**: Many images, particularly those featuring bookjackets and notebooks, frequently misidentify contextually relevant items (e.g., tools in a garage instead of the intended object).\n",
       "- **Over-reliance on Common Objects**: The model tends to focus on common items in the background rather than the specified subject, indicating a bias towards familiar objects over the prompt's intent.\n",
       "- **Inconsistent Object Recognition**: Certain objects, like the notebook and bookjacket, show high incoherence rates, suggesting a bias in recognizing these items across various contexts.\n",
       "\n",
       "## 3 Detailed list of incoherent images\n",
       "| File Name | Prompt Summary | Worst Labels | Explanation |\n",
       "|-----------|----------------|--------------|-------------|\n",
       "| images/bookjacket__garage__002.png | Bookjacket in garage | hammer, screwdriver, carpenter's kit | Predictions focus on tools rather than a bookjacket in a garage setting. |\n",
       "| images/bookjacket__green__002.png | Bookjacket in green | envelope, binder, packet | Predictions do not align with the prompt about a book jacket on a green background. |\n",
       "| images/bookjacket__hotel__002.png | Bookjacket in hotel | window shade, cowboy hat, lampshade | Predictions are unrelated to the prompt, indicating poor alignment. |\n",
       "| images/bookjacket__minimalist__002.png | Bookjacket in minimalist | book jacket, binder, notebook | Predictions focus on unrelated items, lacking relevance to a book jacket. |\n",
       "| images/bookjacket__modern__001.png | Bookjacket in modern | switch, envelope, wardrobe | Predictions are unrelated to the prompt, indicating poor alignment. |\n",
       "| images/bookjacket__plain__001.png | Bookjacket in plain | switch, buckle, lampshade | Predictions do not align with the prompt about a bookjacket. |\n",
       "| images/bookjacket__plain__002.png | Bookjacket in plain | bathtub, tub, washbasin | Predictions are unrelated to the prompt about a bookjacket. |\n",
       "| images/bookjacket__science__001.png | Bookjacket in science | book jacket, hard disc, fountain pen | Predictions are unrelated to the prompt about a book jacket in a science background. |\n",
       "| images/ceramiccoffeemug__classroom__001.png | Coffee mug in classroom | espresso, cup, coffee mug | Predictions focus on coffee-related items but lack alignment with 'neutral ceramic coffee mug' and 'classroom background'. |\n",
       "| images/grannysmith__bathroom__002.png | Granny Smith in bathroom | bathtub, tub, washbasin | Predictions focus on bathroom items, lacking any reference to a neutral grannysmith. |\n",
       "| images/grannysmith__garage__001.png | Granny Smith in garage | hammer, screwdriver, carpenter's kit | Predictions focus on tools, not the grannysmith or garage context. |\n",
       "| images/grannysmith__minimalist__002.png | Granny Smith in minimalist | table lamp, bookcase, studio couch | Predictions do not align with the prompt about a grannysmith apple. |\n",
       "| images/grannysmith__modern__001.png | Granny Smith in modern | wall clock, combination lock, wardrobe | Predictions do not relate to a neutral grannysmith or modern background. |\n",
       "| images/grannysmith__modern__002.png | Granny Smith in modern | wall clock, bottlecap, tray | Predictions do not relate to a neutral grannysmith or modern background. |\n",
       "| images/grannysmith__science__002.png | Granny Smith in science | menu, joystick, abacus | Predictions are largely unrelated to the prompt, indicating poor alignment. |\n",
       "| images/notebookwithkraftcover__garage__001.png | Notebook in garage | hammer, screwdriver, carpenter's kit | Predictions focus on tools rather than the requested notebook, indicating poor alignment with the prompt. |\n",
       "| images/notebookwithkraftcover__green__001.png | Notebook in green | book jacket, binder, envelope | Predictions do not align with the prompt about a notebook. |\n",
       "| images/notebookwithkraftcover__green__002.png | Notebook in green | ballpoint, rubber eraser, cup | Predictions do not align with the prompt about a notebook. |\n",
       "| images/notebookwithkraftcover__hotel__001.png | Notebook in hotel | ballpoint, rubber eraser, rule | Predictions do not align with the prompt about a notebook in a hotel background. |\n",
       "| images/notebookwithkraftcover__kitchen__001.png | Notebook in kitchen | fountain pen, ballpoint, binder | Predictions focus on writing instruments and unrelated items, lacking relevance to the notebook prompt. |\n",
       "| images/notebookwithkraftcover__kitchen__002.png | Notebook in kitchen | loudspeaker, binder, orange | Predictions do not align with the prompt; items are unrelated to a notebook or kitchen. |\n",
       "| images/notebookwithkraftcover__minimalist__002.png | Notebook in minimalist | binder, book jacket, ballpoint | Predictions mostly unrelated to the prompt, indicating poor alignment. |\n",
       "| images/notebookwithkraftcover__modern__001.png | Notebook in modern | envelope, binder, rubber eraser | Predictions do not align with the prompt, focusing on unrelated items. |\n",
       "| images/notebookwithkraftcover__modern__002.png | Notebook in modern | rule, rubber eraser, envelope | Predictions mostly unrelated to the prompt, indicating low alignment. |\n",
       "| images/notebookwithkraftcover__science__002.png | Notebook in science | ballpoint, rule, rubber eraser | Predictions are unrelated to the prompt about a notebook. |\n",
       "| images/opaquemetalwaterbottle__bathroom__001.png | Water bottle in bathroom | washbasin, soap dispenser, cocktail shaker | Predictions focus on bathroom items, not the specified neutral opaque metal water bottle. |\n",
       "| images/opaquemetalwaterbottle__bathroom__002.png | Water bottle in bathroom | soap dispenser, lotion, cocktail shaker | Predictions do not align with the prompt; items are unrelated to a metal water bottle. |\n",
       "| images/opaquemetalwaterbottle__hotel__001.png | Water bottle in hotel | water bottle, saltshaker, cocktail shaker | Predictions mostly misalign with the prompt, focusing on unrelated items. |\n",
       "| images/opaquemetalwaterbottle__modern__001.png | Water bottle in modern | cocktail shaker, water bottle, soap dispenser | Predictions mostly misalign with the prompt, focusing on unrelated items. |\n",
       "| images/opaquemetalwaterbottle__modern__002.png | Water bottle in modern | joystick, microphone, water bottle | Predictions include unrelated items, with 'water bottle' being the only relevant term. |\n",
       "| images/opaquemetalwaterbottle__plain__001.png | Water bottle in plain | pill bottle, saltshaker, syringe | Predictions mostly misalign with the prompt, focusing on unrelated items. |\n",
       "| images/tablelampwithshadeoff__classroom__002.png | Table lamp in classroom | dining table, library, folding chair | Predictions do not align with the prompt about a table lamp in a classroom. |\n",
       "| images/tablelampwithshadeoff__garage__001.png | Table lamp in garage | screwdriver, power drill, pencil sharpener | Predictions do not align with the prompt; no relevant objects identified. |\n",
       "\n",
       "## 4 Target class logit analysis (Full Details)\n",
       "### Class `pillow` (ImageNet #721)\n",
       "- **Average logit**: 1.16 (std: 3.38)\n",
       "- **Top-5 activations**:\n",
       "  - `dataset/images/softcouchpillow__plain__001.png` â†’ logit=9.78\n",
       "  - `dataset/images/softcouchpillow__kitchen__001.png` â†’ logit=9.51\n",
       "  - `dataset/images/softcouchpillow__bathroom__001.png` â†’ logit=9.41\n",
       "  - `dataset/images/softcouchpillow__kitchen__002.png` â†’ logit=9.17\n",
       "  - `dataset/images/softcouchpillow__modern__002.png` â†’ logit=9.12\n",
       "- **Comment**: High logits suggest a strong association with the pillow class, indicating effective recognition in relevant contexts.\n",
       "\n",
       "### Class `toilet seat` (ImageNet #861)\n",
       "- **Average logit**: -0.19 (std: 1.08)\n",
       "- **Top-5 activations**:\n",
       "  - `dataset/images/ceramiccoffeemug__bathroom__001.png` â†’ logit=4.79\n",
       "  - `dataset/images/softcouchpillow__minimalist__001.png` â†’ logit=2.89\n",
       "  - `dataset/images/opaquemetalwaterbottle__bathroom__001.png` â†’ logit=2.69\n",
       "  - `dataset/images/bookjacket__plain__002.png` â†’ logit=2.59\n",
       "  - `dataset/images/ceramiccoffeemug__kitchen__001.png` â†’ logit=1.91\n",
       "- **Comment**: The negative average logit indicates a bias against recognizing this class, with spurious correlations to bathroom-related items.\n",
       "\n",
       "### Class `park bench` (ImageNet #703)\n",
       "- **Average logit**: 0.06 (std: 0.56)\n",
       "- **Top-5 activations**:\n",
       "  - `dataset/images/softcouchpillow__science__001.png` â†’ logit=1.83\n",
       "  - `dataset/images/tablelampwithshadeoff__garage__002.png` â†’ logit=1.72\n",
       "  - `dataset/images/tablelampwithshadeoff__classroom__002.png` â†’ logit=1.68\n",
       "  - `dataset/images/softcouchpillow__green__001.png` â†’ logit=1.13\n",
       "  - `dataset/images/opaquemetalwaterbottle__green__002.png` â†’ logit=1.01\n",
       "- **Comment**: The low average logit suggests weak recognition of this class, potentially due to over-reliance on context rather than object features.\n",
       "\n",
       "### Class `laptop` (ImageNet #620)\n",
       "- **Average logit**: 0.81 (std: 1.37)\n",
       "- **Top-5 activations**:\n",
       "  - `dataset/images/bookjacket__green__001.png` â†’ logit=5.86\n",
       "  - `dataset/images/notebookwithkraftcover__science__001.png` â†’ logit=5.54\n",
       "  - `dataset/images/bookjacket__kitchen__002.png` â†’ logit=5.27\n",
       "  - `dataset/images/ceramiccoffeemug__modern__001.png` â†’ logit=4.38\n",
       "  - `dataset/images/notebookwithkraftcover__modern__001.png` â†’ logit=4.26\n",
       "- **Comment**: The positive average logit indicates some recognition of laptops, but the reliance on other objects suggests a potential bias in feature extraction.\n",
       "\n",
       "### Class `fox squirrel` (ImageNet #335)\n",
       "- **Average logit**: -0.05 (std: 0.34)\n",
       "- **Top-5 activations**:\n",
       "  - `dataset/images/grannysmith__green__002.png` â†’ logit=0.71\n",
       "  - `dataset/images/softcouchpillow__modern__002.png` â†’ logit=0.70\n",
       "  - `dataset/images/softcouchpillow__science__002.png` â†’ logit=0.59\n",
       "  - `dataset/images/grannysmith__bathroom__002.png` â†’ logit=0.53\n",
       "  - `dataset/images/ceramiccoffeemug__kitchen__002.png` â†’ logit=0.49\n",
       "- **Comment**: The average logit near zero indicates a lack of strong recognition, possibly due to spurious correlations with other classes.\n",
       "\n",
       "### Class `tennis ball` (ImageNet #852)\n",
       "- **Average logit**: 0.23 (std: 0.85)\n",
       "- **Top-5 activations**:\n",
       "  - `dataset/images/grannysmith__hotel__002.png` â†’ logit=3.52\n",
       "  - `dataset/images/grannysmith__green__002.png` â†’ logit=3.39\n",
       "  - `dataset/images/grannysmith__classroom__001.png` â†’ logit=2.46\n",
       "  - `dataset/images/grannysmith__minimalist__002.png` â†’ logit=2.44\n",
       "  - `dataset/images/ceramiccoffeemug__green__002.png` â†’ logit=2.03\n",
       "- **Comment**: The low average logit suggests weak recognition of tennis balls, with a tendency to misidentify them in contexts related to Granny Smith apples.\n",
       "\n",
       "## 5 Main biases of the model\n",
       "- **Contextual Bias**: The model often misidentifies objects based on the context rather than their actual features, leading to incoherent predictions.\n",
       "- **Over-reliance on Common Objects**: The model tends to favor familiar items, such as tools in garage settings, over the specified subjects, indicating a bias towards commonality.\n",
       "- **Inconsistent Object Recognition**: Certain objects, particularly those with less distinctive features (like notebooks and bookjackets), show high rates of incoherence, suggesting a bias in feature extraction.\n",
       "\n",
       "## 6 Overall verdict\n",
       "- **Strengths**:\n",
       "  - High performance in recognizing certain objects like pillows.\n",
       "  - Some contextual understanding in specific scenarios.\n",
       "- **Weaknesses**:\n",
       "  - Frequent misalignment with prompts, especially in varied contexts.\n",
       "  - High incoherence rates for certain object classes.\n",
       "- **Final Reliability Rating**: 2/5"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 7: Output finale\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "print(\"Report salvato in:\", OUTPUT_DIR / \"report.md\")\n",
    "report_md = report_path.read_text(encoding=\"utf-8\")\n",
    "display(Markdown(report_md))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
