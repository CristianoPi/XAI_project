{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a44d9906",
   "metadata": {},
   "source": [
    "## Project Overview: *Static Images Network Analyzer*\n",
    "\n",
    "This is the final project for the Cognitive Learning course, titled *Static Images Network Analyzer*.  \n",
    "The goal is to analyze **cognitive biases** in image classification models, focusing on **spurious correlations**—for example, when the model is influenced more by background context than by the actual object in the image.\n",
    "\n",
    "The project has two main phases:\n",
    "1. **Controlled dataset generation**: we created artificial images combining neutral objects with potentially bias-inducing visual contexts, using *Stable Diffusion v1.5*.  \n",
    "   > The image generation code is located in the file: `generate_dataset_diff_v1_5.py.py`.\n",
    "2. **Model analysis**: we evaluated how three pretrained classifiers (AlexNet, ResNet-18, ViT-18) responded to these images and measured whether their predictions aligned with the original prompt or were misled by context.  \n",
    "   > All analysis and evaluation steps are implemented in this notebook.\n",
    "\n",
    "We extract the **top-10 logits** for each image-model pair, and send both the original prompt and the predictions to a **language model (LLM)** for semantic auditing. The LLM provides a coherence score (0–1), a short explanation, and optional confidence. These evaluations are stored in a `.jsonl` file.\n",
    "\n",
    "Finally, we build an aggregated **bias report** using precomputed statistics and LLM-generated justifications. This final Markdown report includes:\n",
    "- Aggregate performance metrics\n",
    "- Recurring error patterns\n",
    "- Detailed list of incoherent predictions\n",
    "- Class-specific logit behavior\n",
    "- Overall model verdict\n",
    "\n",
    "This workflow allows us to systematically study the effect of **spurious visual cues** and assess the **robustness and reliability** of vision models through a cognitively informed pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ae04aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip3 install -q openai pandas pyarrow pillow tqdm urllib3 pycocotools requests torch torchvision python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3ba049",
   "metadata": {},
   "source": [
    "## Analizzo un modello a partire dal DataSet di Immagini\n",
    "\n",
    "A questo punto del notebook si deve avere un DataSet di immagini coerenti, con il DataSet Metadata. Bisogna stare attenti alla successive configurazioni, le cartelle devono essere quelle che si voglio analizzare ecc.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ec18c1",
   "metadata": {},
   "source": [
    "### CONFIGURATION: load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f68a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VISION_MODEL: alexnet\n",
      "LLM_MODEL: gpt-4o-mini\n",
      "OPENAI_API_KEY: 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\n",
      "IMG_DIR: dataset/images\n",
      "META_CSV: dataset/dataset_metadata.csv\n",
      "OUTPUT_DIR: analysis_alexnet_1\n",
      "COHERENCE_THRESHOLD: 0.3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carica da file .env se presente\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Variabili configurabili\n",
    "VISION_MODEL = os.getenv(\"VISION_MODEL\", \"alexnet\")\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"gpt-4o-mini\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "IMG_DIR = Path(os.getenv(\"IMG_DIR\", \"dataset_/images\"))\n",
    "META_CSV = Path(os.getenv(\"META_CSV\", \"dataset_/dataset_metadata.csv\"))\n",
    "OUTPUT_DIR = Path(os.getenv(\"OUTPUT_DIR\", \"analysis_out_\"))\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "COHERENCE_THRESHOLD = float(os.getenv(\"COHERENCE_TH\", 0.5))\n",
    "TARGET_CLASSES = os.getenv(\"TARGET_CLASSES\", \"pillow,toilet seat,park bench,laptop,fox squirrel,tennis ball\").split(\",\")\n",
    "\n",
    "print(f\"VISION_MODEL: {VISION_MODEL}\")\n",
    "print(f\"LLM_MODEL: {LLM_MODEL}\")\n",
    "print(f\"OPENAI_API_KEY: {OPENAI_API_KEY}\")\n",
    "print(f\"IMG_DIR: {IMG_DIR}\")\n",
    "print(f\"META_CSV: {META_CSV}\")\n",
    "print(f\"OUTPUT_DIR: {OUTPUT_DIR}\")\n",
    "print(f\"COHERENCE_THRESHOLD: {COHERENCE_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9334f0b1",
   "metadata": {},
   "source": [
    "### Load view model and ImageNet classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd4a2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Caricamento modello dinamico\n",
    "model = getattr(models, VISION_MODEL)(pretrained=True).eval().to(device)\n",
    "\n",
    "# Etichette ImageNet\n",
    "import urllib.request\n",
    "labels_url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "imagenet_labels = urllib.request.urlopen(labels_url).read().decode().splitlines()\n",
    "idx2label = {i: l for i, l in enumerate(imagenet_labels)}\n",
    "\n",
    "# Trasformazioni immagine\n",
    "transform = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6111376e",
   "metadata": {},
   "source": [
    "### Top-10 Extraction\n",
    "\n",
    "The choice of 10 is not arbitrary.  \n",
    "Studies on ImageNet show that the **top ten logits** account for, on average, **over 95% of the softmax probability mass** in models such as **ResNet-50** or **ViT-B/16**.  \n",
    "This means that, in most cases, the remaining classes beyond the 10th position **contribute minimally to the overall semantic representation**.\n",
    "\n",
    "> Source: [arXiv:2206.07290](https://arxiv.org/pdf/2206.07290)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db62bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:01<00:00, 96.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Esempi di top‑10 logits:\n",
      "\n",
      "📌 dataset/images/ceramiccoffeemug__bathroom__001.png\n",
      "Prompt: A neutral ceramic coffee mug in a bathroom vanity matte tiles background\n",
      "Top‑10 logits (softmax):\n",
      "  - 804: soap dispenser (0.484)\n",
      "  - 896: washbasin (0.101)\n",
      "  - 876: tub (0.074)\n",
      "  - 861: toilet seat (0.064)\n",
      "  - 435: bathtub (0.055)\n",
      "  - 794: shower curtain (0.037)\n",
      "  - 999: toilet tissue (0.034)\n",
      "  - 897: washer (0.019)\n",
      "  - 453: bookcase (0.013)\n",
      "  - 731: plunger (0.008)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 4.73\n",
      "  - 861: toilet seat = 10.20\n",
      "  - 703: park bench = -2.80\n",
      "  - 620: laptop = 3.73\n",
      "  - 335: fox squirrel = -3.53\n",
      "  - 852: tennis ball = 2.47\n",
      "\n",
      "📌 dataset/images/ceramiccoffeemug__classroom__001.png\n",
      "Prompt: A neutral ceramic coffee mug in a classroom row of desks daylight background\n",
      "Top‑10 logits (softmax):\n",
      "  - 967: espresso (0.934)\n",
      "  - 504: coffee mug (0.043)\n",
      "  - 968: cup (0.016)\n",
      "  - 925: consomme (0.004)\n",
      "  - 969: eggnog (0.001)\n",
      "  - 809: soup bowl (0.001)\n",
      "  - 960: chocolate sauce (0.000)\n",
      "  - 901: whiskey jug (0.000)\n",
      "  - 666: mortar (0.000)\n",
      "  - 725: pitcher (0.000)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 0.64\n",
      "  - 861: toilet seat = 6.99\n",
      "  - 703: park bench = -1.75\n",
      "  - 620: laptop = 1.88\n",
      "  - 335: fox squirrel = -4.87\n",
      "  - 852: tennis ball = 3.68\n",
      "\n",
      "📌 dataset/images/ceramiccoffeemug__classroom__002.png\n",
      "Prompt: A neutral ceramic coffee mug in a classroom row of desks daylight background\n",
      "Top‑10 logits (softmax):\n",
      "  - 968: cup (0.229)\n",
      "  - 618: ladle (0.077)\n",
      "  - 632: loudspeaker (0.062)\n",
      "  - 745: projector (0.061)\n",
      "  - 772: safety pin (0.053)\n",
      "  - 605: iPod (0.043)\n",
      "  - 504: coffee mug (0.038)\n",
      "  - 999: toilet tissue (0.033)\n",
      "  - 418: ballpoint (0.021)\n",
      "  - 771: safe (0.016)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 2.29\n",
      "  - 861: toilet seat = 4.30\n",
      "  - 703: park bench = 0.44\n",
      "  - 620: laptop = 5.39\n",
      "  - 335: fox squirrel = -2.62\n",
      "  - 852: tennis ball = 5.08\n",
      "\n",
      "📌 dataset/images/ceramiccoffeemug__garage__001.png\n",
      "Prompt: A neutral ceramic coffee mug in a garage workshop tools on pegboard background\n",
      "Top‑10 logits (softmax):\n",
      "  - 587: hammer (0.126)\n",
      "  - 784: screwdriver (0.086)\n",
      "  - 721: pillow (0.074)\n",
      "  - 918: crossword puzzle (0.053)\n",
      "  - 921: book jacket (0.044)\n",
      "  - 539: doormat (0.025)\n",
      "  - 695: padlock (0.020)\n",
      "  - 662: modem (0.018)\n",
      "  - 720: pill bottle (0.018)\n",
      "  - 427: barrel (0.016)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 7.30\n",
      "  - 861: toilet seat = -0.30\n",
      "  - 703: park bench = -0.92\n",
      "  - 620: laptop = 2.19\n",
      "  - 335: fox squirrel = -1.61\n",
      "  - 852: tennis ball = 1.71\n",
      "\n",
      "📌 dataset/images/ceramiccoffeemug__green__002.png\n",
      "Prompt: A neutral ceramic coffee mug in a green park lawn afternoon light background\n",
      "Top‑10 logits (softmax):\n",
      "  - 504: coffee mug (0.866)\n",
      "  - 968: cup (0.064)\n",
      "  - 967: espresso (0.035)\n",
      "  - 725: pitcher (0.024)\n",
      "  - 809: soup bowl (0.002)\n",
      "  - 666: mortar (0.001)\n",
      "  - 899: water jug (0.001)\n",
      "  - 647: measuring cup (0.001)\n",
      "  - 505: coffeepot (0.001)\n",
      "  - 849: teapot (0.001)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 4.50\n",
      "  - 861: toilet seat = 8.60\n",
      "  - 703: park bench = 1.37\n",
      "  - 620: laptop = 3.19\n",
      "  - 335: fox squirrel = -3.96\n",
      "  - 852: tennis ball = 6.00\n",
      "\n",
      "📌 dataset/images/ceramiccoffeemug__hotel__001.png\n",
      "Prompt: A neutral ceramic coffee mug in a hotel room desk area background\n",
      "Top‑10 logits (softmax):\n",
      "  - 504: coffee mug (0.632)\n",
      "  - 968: cup (0.309)\n",
      "  - 725: pitcher (0.041)\n",
      "  - 505: coffeepot (0.008)\n",
      "  - 899: water jug (0.003)\n",
      "  - 999: toilet tissue (0.001)\n",
      "  - 849: teapot (0.001)\n",
      "  - 773: saltshaker (0.001)\n",
      "  - 647: measuring cup (0.001)\n",
      "  - 901: whiskey jug (0.001)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 8.44\n",
      "  - 861: toilet seat = 9.65\n",
      "  - 703: park bench = -0.76\n",
      "  - 620: laptop = 3.85\n",
      "  - 335: fox squirrel = -5.75\n",
      "  - 852: tennis ball = 5.46\n",
      "\n",
      "📌 dataset/images/ceramiccoffeemug__hotel__002.png\n",
      "Prompt: A neutral ceramic coffee mug in a hotel room desk area background\n",
      "Top‑10 logits (softmax):\n",
      "  - 846: table lamp (0.104)\n",
      "  - 527: desktop computer (0.080)\n",
      "  - 526: desk (0.072)\n",
      "  - 664: monitor (0.070)\n",
      "  - 681: notebook (0.070)\n",
      "  - 782: screen (0.067)\n",
      "  - 968: cup (0.066)\n",
      "  - 851: television (0.066)\n",
      "  - 626: lighter (0.050)\n",
      "  - 598: home theater (0.024)\n",
      "Logits classi target:\n",
      "  - 721: pillow = -1.30\n",
      "  - 861: toilet seat = 4.79\n",
      "  - 703: park bench = 0.33\n",
      "  - 620: laptop = 8.88\n",
      "  - 335: fox squirrel = -0.58\n",
      "  - 852: tennis ball = 1.38\n",
      "\n",
      "📌 dataset/images/ceramiccoffeemug__kitchen__001.png\n",
      "Prompt: A neutral ceramic coffee mug in a kitchen countertop daylight background\n",
      "Top‑10 logits (softmax):\n",
      "  - 648: medicine chest (0.462)\n",
      "  - 550: espresso maker (0.069)\n",
      "  - 631: lotion (0.038)\n",
      "  - 651: microwave (0.035)\n",
      "  - 859: toaster (0.033)\n",
      "  - 504: coffee mug (0.024)\n",
      "  - 849: teapot (0.024)\n",
      "  - 844: switch (0.019)\n",
      "  - 551: face powder (0.017)\n",
      "  - 505: coffeepot (0.015)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 3.89\n",
      "  - 861: toilet seat = 6.36\n",
      "  - 703: park bench = 0.50\n",
      "  - 620: laptop = 4.06\n",
      "  - 335: fox squirrel = -1.91\n",
      "  - 852: tennis ball = -0.12\n",
      "\n",
      "📌 dataset/images/ceramiccoffeemug__kitchen__002.png\n",
      "Prompt: A neutral ceramic coffee mug in a kitchen countertop daylight background\n",
      "Top‑10 logits (softmax):\n",
      "  - 968: cup (0.411)\n",
      "  - 504: coffee mug (0.287)\n",
      "  - 967: espresso (0.070)\n",
      "  - 849: teapot (0.065)\n",
      "  - 505: coffeepot (0.039)\n",
      "  - 725: pitcher (0.020)\n",
      "  - 605: iPod (0.014)\n",
      "  - 632: loudspeaker (0.009)\n",
      "  - 999: toilet tissue (0.007)\n",
      "  - 643: mask (0.007)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 6.63\n",
      "  - 861: toilet seat = 8.52\n",
      "  - 703: park bench = 2.04\n",
      "  - 620: laptop = 6.13\n",
      "  - 335: fox squirrel = -4.35\n",
      "  - 852: tennis ball = 2.99\n",
      "\n",
      "📌 dataset/images/ceramiccoffeemug__minimalist__001.png\n",
      "Prompt: A neutral ceramic coffee mug in a minimalist living-room corner background\n",
      "Top‑10 logits (softmax):\n",
      "  - 851: television (0.071)\n",
      "  - 605: iPod (0.059)\n",
      "  - 598: home theater (0.054)\n",
      "  - 846: table lamp (0.048)\n",
      "  - 831: studio couch (0.045)\n",
      "  - 632: loudspeaker (0.037)\n",
      "  - 619: lampshade (0.034)\n",
      "  - 782: screen (0.033)\n",
      "  - 681: notebook (0.027)\n",
      "  - 844: switch (0.025)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 0.95\n",
      "  - 861: toilet seat = 5.67\n",
      "  - 703: park bench = -0.16\n",
      "  - 620: laptop = 6.03\n",
      "  - 335: fox squirrel = -0.90\n",
      "  - 852: tennis ball = 3.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_topk(logits, k=10):\n",
    "    probs = torch.softmax(logits, dim=-1) ## corretto convertire in probabilità, motivare\n",
    "    top_p, top_i = torch.topk(probs, k)\n",
    "    return [(int(i), (idx2label[int(i)], float(p))) for p, i in zip(top_p.cpu(), top_i.cpu())]\n",
    "# Softmax is monotonic, so it can be used to rank logits, is more interpretable than raw logits for us and for LLM.\n",
    "\n",
    "def get_class_logits(logits, target_ids):\n",
    "    return {i: float(logits[i].cpu()) for i in target_ids}\n",
    "\n",
    "# load prompts from CSV\n",
    "prompts = {}\n",
    "with open(META_CSV, newline='') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        prompts[Path(row[\"file_name\"].strip()).name] = row[\"prompt\"]\n",
    "\n",
    "########### \n",
    "# target classes, for pt. 4 of the report  \n",
    "target_classes = TARGET_CLASSES\n",
    "labels_url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "imagenet_labels = urllib.request.urlopen(labels_url).read().decode().splitlines()\n",
    "idx2label = {i: l for i, l in enumerate(imagenet_labels)}\n",
    "label2idx = {l: i for i, l in enumerate(imagenet_labels)}\n",
    "target_ids = {label2idx[c]: c for c in target_classes}\n",
    "per_class_logit = defaultdict(list)\n",
    "#########\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "# Image analysis\n",
    "for img_path in tqdm(sorted(IMG_DIR.glob(\"*.png\"))):\n",
    "    prompt = prompts.get(img_path.name)\n",
    "    if not prompt:\n",
    "        continue\n",
    "\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    with torch.no_grad():\n",
    "        logits = model(transform(image).unsqueeze(0).to(device))[0]\n",
    "\n",
    "    # Softmax top‑10 logits\n",
    "    top_logits = get_topk(logits, k=10)\n",
    "\n",
    "    # Raw Logits of 6 target classes\n",
    "    selected_logits = get_class_logits(logits, target_ids.keys())\n",
    "\n",
    "    results.append({\n",
    "        \"file_name\": str(img_path),\n",
    "        \"prompt\": prompt,\n",
    "        \"top_logits\": top_logits,\n",
    "        \"class_logits\": selected_logits\n",
    "    })\n",
    "\n",
    "    # aggregate per class (for the dedicated report)\n",
    "    for cls_id, val in selected_logits.items():\n",
    "        per_class_logit[cls_id].append({\n",
    "            \"file_name\": str(img_path),\n",
    "            \"prompt\": prompt,\n",
    "            \"logit\": val\n",
    "        })\n",
    "\n",
    "# Debug/preview\n",
    "print(\"\\n✅ Esempi di top‑10 logits:\")\n",
    "for r in results[:10]:\n",
    "    print(f\"\\n📌 {r['file_name']}\")\n",
    "    print(f\"Prompt: {r['prompt']}\")\n",
    "    print(\"Top‑10 logits (softmax):\")\n",
    "    for i, (label, p) in r[\"top_logits\"]:\n",
    "        print(f\"  - {i}: {label} ({p:.3f})\")\n",
    "    print(\"Logits classi target:\")\n",
    "    for i, val in r[\"class_logits\"].items():\n",
    "        print(f\"  - {i}: {idx2label[i]} = {val:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d479795",
   "metadata": {},
   "source": [
    "### LLM Coherence Audit \n",
    "\n",
    "This script audits the coherence between a prompt and a vision model's top-10 predictions using an LLM.\n",
    "\n",
    "- **Canonical lists** (`OBJECTS`, `CONTEXTS`) are used to label prompts.\n",
    "- **`query_llm()`** sends the prompt and logits to an OpenAI model, which returns a JSON with a coherence `score`, a short `explanation`, and optional `confidence`.\n",
    "- A prediction is considered coherent if the score ≥ `COHERENCE_THRESHOLD` (default: 0.3).\n",
    "- Results are saved to `.jsonl` and `.txt` files.\n",
    "- The final report includes total examples, coherence rate, and breakdowns by object and context.\n",
    "\n",
    "This allows for automated semantic auditing of vision-language model outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0a408d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COHERENCE_THRESHOLD: 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM analysis: 100%|██████████| 91/91 [02:11<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== RIEPILOGO ==========\n",
      "Totale immagini:   91\n",
      "Incoerenti (<0.3): 38  (41.8 %)\n",
      "\n",
      "-- Incoerenza per *oggetto* --\n",
      "  ceramic coffee mug                 : 5/16  (31.2 %)\n",
      "  notebook with kraft cover          : 11/15  (73.3 %)\n",
      "  opaque metal water bottle          : 9/20  (45.0 %)\n",
      "  soft couch pillow                  : 10/20  (50.0 %)\n",
      "  table lamp with shade (off)        : 3/20  (15.0 %)\n",
      "\n",
      "-- Incoerenza per *contesto* --\n",
      "  bathroom vanity matte tiles        : 3/7  (42.9 %)\n",
      "  classroom row of desks daylight    : 3/8  (37.5 %)\n",
      "  garage workshop tools on pegboard  : 7/8  (87.5 %)\n",
      "  green park lawn afternoon light    : 2/9  (22.2 %)\n",
      "  hotel room desk area               : 3/10  (30.0 %)\n",
      "  kitchen countertop daylight        : 4/10  (40.0 %)\n",
      "  minimalist living-room corner      : 5/10  (50.0 %)\n",
      "  modern office desk                 : 4/10  (40.0 %)\n",
      "  plain white studio background      : 3/10  (30.0 %)\n",
      "  science lab bench                  : 4/9  (44.4 %)\n",
      "================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import openai, json, re, os, sys\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "from typing import List, Optional   \n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# ─── LISTE CANONICHE ──────────────────────────────────────────────────\n",
    "OBJECTS = [\n",
    "    \"ceramic coffee mug\", \"hardcover book (closed)\",  \"soft couch pillow\", \"opaque metal water bottle\",\n",
    "    \"table lamp with shade (off)\", \"apple\", \"notebook with kraft cover\"\n",
    "]\n",
    "\n",
    "CONTEXTS = [\n",
    "    \"plain white studio background\", \"minimalist living-room corner\",\n",
    "    \"modern office desk\", \"kitchen countertop daylight\",\n",
    "    \"green park lawn afternoon light\", \"science lab bench\",\n",
    "    \"garage workshop tools on pegboard\", \"hotel room desk area\",\n",
    "    \"bathroom vanity matte tiles\", \"classroom row of desks daylight\"\n",
    "] # è brutto hardcodare, vedere se si può fare meglio\n",
    "\n",
    "def find_match(text: str, phrases: List[str]) -> Optional[str]:\n",
    "    \"\"\"Restituisce la prima frase (più lunga) di 'phrases' trovata in 'text'.\"\"\"\n",
    "    text = text.lower()\n",
    "    for phrase in sorted(phrases, key=len, reverse=True):\n",
    "        if phrase.lower() in text:\n",
    "            return phrase\n",
    "    return None\n",
    "\n",
    "# ─── PARAMETERS ────────────────────────────────────────────────────────\n",
    "COHERENCE_THRESHOLD = float(os.getenv(\"COHERENCE_TH\", 0.3))\n",
    "print(f\"COHERENCE_THRESHOLD: {COHERENCE_THRESHOLD}\")\n",
    "\n",
    "LOG_JSONL_PATH = OUTPUT_DIR / \"llm_audit.jsonl\"\n",
    "LIVE_TXT_PATH  = OUTPUT_DIR / \"llm_live_output.txt\"\n",
    "\n",
    "\n",
    "def extract_json_from_text(text: str) -> dict:\n",
    "    m = re.search(r\"\\{.*?\\}\", text, re.DOTALL)\n",
    "    if not m:\n",
    "        raise ValueError(\"⚠️ No valid JSON found\")\n",
    "    return json.loads(m.group(0))\n",
    "\n",
    "def query_llm(prompt: str, top_logits, vision_model=VISION_MODEL) -> dict:\n",
    "    def safe_label_prob(item):\n",
    "        try:\n",
    "            label = str(item[0])\n",
    "            prob_raw = item[1]\n",
    "            prob = float(prob_raw[0]) if isinstance(prob_raw, (tuple, list)) else float(prob_raw)\n",
    "            return f\"{label} ({prob:.3f})\"\n",
    "        except Exception:\n",
    "            return f\"[MALFORMED: {item}]\"\n",
    "\n",
    "    top_str = \"; \".join([safe_label_prob(it) for it in top_logits])\n",
    "\n",
    "    user_msg = f\"\"\"\n",
    "You are auditing the output of **{vision_model}** to assess alignment with the prompt.\n",
    "\n",
    "Prompt:\n",
    "\\\"{prompt}\\\"\n",
    "\n",
    "Top-10 predictions with probabilities:\n",
    "{top_str}\n",
    "\n",
    "Return JSON only:\n",
    "{{\n",
    "  \"score\": <float 0-1>,\n",
    "  \"explanation\": <≤25 words>,\n",
    "  \"confidence\": <float 0-1 (optional)>\n",
    "}}\n",
    "Be lenient; score ≥ 0.3 is considered coherent.\n",
    "\"\"\"\n",
    "\n",
    "    res = openai.chat.completions.create(\n",
    "        model=LLM_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Return strict JSON only.\"},\n",
    "            {\"role\": \"user\",   \"content\": user_msg}\n",
    "        ],\n",
    "        temperature=0.0\n",
    "    )\n",
    "    return extract_json_from_text(res.choices[0].message.content.strip())\n",
    "\n",
    "tot = tot_incoh = 0\n",
    "per_obj_tot = Counter(); per_obj_incoh = Counter()\n",
    "per_ctx_tot = Counter(); per_ctx_incoh = Counter()\n",
    "incoherent_cases = []\n",
    "\n",
    "# ─── MAIN LOOP ──────────────────────────────────────────────────\n",
    "with open(LOG_JSONL_PATH, \"w\") as fout, open(LIVE_TXT_PATH, \"w\") as live:\n",
    "    for r in tqdm(results, desc=\"LLM analysis\"):\n",
    "        tot += 1\n",
    "        prompt_lc = r[\"prompt\"].lower()\n",
    "\n",
    "        obj = find_match(prompt_lc, OBJECTS)  or \"unknown-object\"\n",
    "        ctx = find_match(prompt_lc, CONTEXTS) or \"unknown-context\"\n",
    "\n",
    "        per_obj_tot[obj] += 1\n",
    "        per_ctx_tot[ctx] += 1\n",
    "\n",
    "        llm_out = query_llm(r[\"prompt\"], r[\"top_logits\"])\n",
    "        record  = {**r, **llm_out, \"subject\": obj, \"background\": ctx}\n",
    "\n",
    "        fout.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "        live.write(json.dumps({\n",
    "            \"id\": r.get(\"id\", tot),\n",
    "            \"score\": llm_out.get(\"score\"),\n",
    "            \"explanation\": llm_out.get(\"explanation\")\n",
    "        }, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "        if llm_out.get(\"score\", 0.0) < COHERENCE_THRESHOLD:\n",
    "            incoherent_cases.append(record)\n",
    "            tot_incoh += 1\n",
    "            per_obj_incoh[obj] += 1\n",
    "            per_ctx_incoh[ctx] += 1\n",
    "\n",
    "# ─── FINAL REPORT ────────────────────────────────────────────────────\n",
    "print(\"\\n========== SUMMARY ==========\")\n",
    "pct = 100 * tot_incoh / tot if tot else 0\n",
    "print(f\"Total images:   {tot}\")\n",
    "print(f\"Incoherent (<{COHERENCE_THRESHOLD}): {tot_incoh}  ({pct:.1f} %)\")\n",
    "\n",
    "print(\"\\n-- Incoherence by *object* --\")\n",
    "for o in sorted(per_obj_tot):\n",
    "    pct = 100 * per_obj_incoh[o] / per_obj_tot[o] if per_obj_tot[o] else 0\n",
    "    print(f\"  {o:35s}: {per_obj_incoh[o]}/{per_obj_tot[o]}  ({pct:.1f} %)\")\n",
    "\n",
    "print(\"\\n-- Incoherence by *context* --\")\n",
    "for c in sorted(per_ctx_tot):\n",
    "    pct = 100 * per_ctx_incoh[c] / per_ctx_tot[c] if per_ctx_tot[c] else 0\n",
    "    print(f\"  {c:35s}: {per_ctx_incoh[c]}/{per_ctx_tot[c]}  ({pct:.1f} %)\")\n",
    "print(\"================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaae9b7a",
   "metadata": {},
   "source": [
    "### Bias Report & Model Verdict (Uses Pre-computed Metrics)\n",
    "\n",
    "This cell generates a bias analysis and verdict for the vision model based on previously computed LLM coherence scores and raw logits.\n",
    "\n",
    "- Loads all results from the audit (`llm_audit.jsonl`) and filters incoherent cases (`score` < threshold).\n",
    "- Computes global statistics: total images, mean/median/stdev scores, incoherence rates by object and context.\n",
    "- Analyzes raw logits per target class: average activations, top-5 examples.\n",
    "- Constructs a structured prompt for the LLM including:\n",
    "  - (A) global metrics\n",
    "  - (B) incoherent examples\n",
    "  - (C) target class activation stats\n",
    "- The LLM returns a detailed Markdown report with six required sections, including bias patterns and an overall model verdict.\n",
    "- Final report is saved as `report.md`.\n",
    "\n",
    "This step automates bias evaluation and model reliability assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d1a650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## 🔍 Target Class Analysis (Raw Logits)\n",
      "\n",
      "### Class `pillow` (ImageNet #721)\n",
      "- Number of activations: 91\n",
      "- Average logit: 3.65 (std: 4.02)\n",
      "- Top‑5 activations:\n",
      "  - `dataset/images/softcouchpillow__modern__001.png` → logit=14.17\n",
      "  - `dataset/images/softcouchpillow__green__002.png` → logit=13.05\n",
      "  - `dataset/images/softcouchpillow__kitchen__002.png` → logit=12.28\n",
      "  - `dataset/images/softcouchpillow__modern__002.png` → logit=11.82\n",
      "  - `dataset/images/softcouchpillow__green__001.png` → logit=11.74\n",
      "\n",
      "### Class `toilet seat` (ImageNet #861)\n",
      "- Number of activations: 91\n",
      "- Average logit: 4.42 (std: 2.78)\n",
      "- Top‑5 activations:\n",
      "  - `dataset/images/softcouchpillow__minimalist__001.png` → logit=12.37\n",
      "  - `dataset/images/ceramiccoffeemug__bathroom__001.png` → logit=10.20\n",
      "  - `dataset/images/ceramiccoffeemug__hotel__001.png` → logit=9.65\n",
      "  - `dataset/images/softcouchpillow__classroom__001.png` → logit=9.57\n",
      "  - `dataset/images/tablelampwithshadeoff__bathroom__002.png` → logit=8.97\n",
      "\n",
      "### Class `park bench` (ImageNet #703)\n",
      "- Number of activations: 91\n",
      "- Average logit: 0.36 (std: 2.07)\n",
      "- Top‑5 activations:\n",
      "  - `dataset/images/tablelampwithshadeoff__classroom__002.png` → logit=9.02\n",
      "  - `dataset/images/tablelampwithshadeoff__green__001.png` → logit=5.06\n",
      "  - `dataset/images/ceramiccoffeemug__modern__002.png` → logit=4.34\n",
      "  - `dataset/images/opaquemetalwaterbottle__green__001.png` → logit=3.59\n",
      "  - `dataset/images/softcouchpillow__modern__001.png` → logit=3.50\n",
      "\n",
      "### Class `laptop` (ImageNet #620)\n",
      "- Number of activations: 91\n",
      "- Average logit: 5.10 (std: 2.56)\n",
      "- Top‑5 activations:\n",
      "  - `dataset/images/notebookwithkraftcover__science__001.png` → logit=13.48\n",
      "  - `dataset/images/notebookwithkraftcover__minimalist__002.png` → logit=12.49\n",
      "  - `dataset/images/notebookwithkraftcover__hotel__001.png` → logit=10.62\n",
      "  - `dataset/images/notebookwithkraftcover__hotel__002.png` → logit=9.17\n",
      "  - `dataset/images/softcouchpillow__modern__001.png` → logit=9.17\n",
      "\n",
      "### Class `fox squirrel` (ImageNet #335)\n",
      "- Number of activations: 91\n",
      "- Average logit: -3.06 (std: 1.74)\n",
      "- Top‑5 activations:\n",
      "  - `dataset/images/tablelampwithshadeoff__green__002.png` → logit=1.40\n",
      "  - `dataset/images/opaquemetalwaterbottle__green__002.png` → logit=0.63\n",
      "  - `dataset/images/ceramiccoffeemug__modern__002.png` → logit=0.34\n",
      "  - `dataset/images/opaquemetalwaterbottle__science__002.png` → logit=0.12\n",
      "  - `dataset/images/opaquemetalwaterbottle__kitchen__002.png` → logit=-0.28\n",
      "\n",
      "### Class `tennis ball` (ImageNet #852)\n",
      "- Number of activations: 91\n",
      "- Average logit: 2.97 (std: 2.44)\n",
      "- Top‑5 activations:\n",
      "  - `dataset/images/opaquemetalwaterbottle__green__002.png` → logit=9.01\n",
      "  - `dataset/images/opaquemetalwaterbottle__green__001.png` → logit=8.42\n",
      "  - `dataset/images/opaquemetalwaterbottle__kitchen__001.png` → logit=8.03\n",
      "  - `dataset/images/opaquemetalwaterbottle__classroom__001.png` → logit=7.58\n",
      "  - `dataset/images/opaquemetalwaterbottle__classroom__002.png` → logit=7.54\n",
      "\n",
      "✅ Report saved to: analysis_alexnet_1/report.md\n"
     ]
    }
   ],
   "source": [
    "import json, openai, statistics, os\n",
    "from pathlib import Path\n",
    "from statistics import mean, stdev\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# ── load all the records from previous cell ───────────────────\n",
    "with open(LOG_JSONL_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    records = [json.loads(l) for l in f]\n",
    "\n",
    "# Limit top_logits to 5 for each record\n",
    "for rec in records:\n",
    "    rec[\"top_logits\"] = rec.get(\"top_logits\", [])[:5]\n",
    "\n",
    "# List of incoherent records (those with score < COHERENCE_THRESHOLD)\n",
    "incoherent_recs = [\n",
    "    {k: rec[k] for k in (\"file_name\", \"prompt\", \"top_logits\", \"score\", \"explanation\")}\n",
    "    for rec in records if rec.get(\"score\", 0) < COHERENCE_THRESHOLD\n",
    "]\n",
    "\n",
    "# ── global metrics already computed in previous cell ─────────────────────────\n",
    "scores = [rec.get(\"score\", 0.0) for rec in records]\n",
    "metrics_summary = {\n",
    "    \"total_images\": tot,\n",
    "    \"mean_score\": statistics.mean(scores) if scores else 0.0,\n",
    "    \"median_score\": statistics.median(scores) if scores else 0.0,\n",
    "    \"stdev_score\": statistics.pstdev(scores) if len(scores) > 1 else 0.0,\n",
    "    \"percent_incoherent\": 100 * tot_incoh / tot if tot else 0.0,\n",
    "    \"object_stats\": {\n",
    "        obj: {\n",
    "            \"total\": per_obj_tot[obj],\n",
    "            \"incoherent\": per_obj_incoh[obj],\n",
    "            \"percent_incoherent\": 100 * per_obj_incoh[obj] / per_obj_tot[obj]\n",
    "            if per_obj_tot[obj] else 0.0\n",
    "        }\n",
    "        for obj in per_obj_tot\n",
    "    },\n",
    "    \"context_stats\": {\n",
    "        ctx: {\n",
    "            \"total\": per_ctx_tot[ctx],\n",
    "            \"incoherent\": per_ctx_incoh[ctx],\n",
    "            \"percent_incoherent\": 100 * per_ctx_incoh[ctx] / per_ctx_tot[ctx]\n",
    "            if per_ctx_tot[ctx] else 0.0\n",
    "        }\n",
    "        for ctx in per_ctx_tot\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save metrics to file (may be useful)\n",
    "Path(OUTPUT_DIR /  \"metrics.json\").write_text(json.dumps(metrics_summary, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "logit_report_section = \"\\n## Target Class Analysis (Raw Logits)\\n\"\n",
    "for cls_id, cls_name in target_ids.items():\n",
    "    values = [x[\"logit\"] for x in per_class_logit[cls_id]]\n",
    "    if not values:\n",
    "        continue\n",
    "\n",
    "    logit_report_section += f\"\\n### Class `{cls_name}` (ImageNet #{cls_id})\\n\"\n",
    "    logit_report_section += f\"- Number of activations: {len(values)}\\n\"\n",
    "    logit_report_section += f\"- Average logit: {mean(values):.2f} (std: {stdev(values):.2f})\\n\"\n",
    "    logit_report_section += \"- Top‑5 activations:\\n\"\n",
    "    top5 = sorted(per_class_logit[cls_id], key=lambda x: -x[\"logit\"])[:5]\n",
    "    for e in top5:\n",
    "       logit_report_section += f\"  - `{e['file_name']}` → logit={e['logit']:.2f}\\n\"\n",
    "\n",
    "print(logit_report_section)\n",
    "\n",
    "# ── Prompt for LLM ──────\n",
    "prompt_header = f\"\"\"\n",
    "You are an AI-bias auditor.  \n",
    "Below you will find **(A) pre-computed global metrics**, **(B) per-image data**, and **(C) target class logit analysis**.\n",
    "\n",
    "Use the provided metrics; do NOT recalsculate means or percentages yourself.\n",
    "Respond in **Markdown** with the requested sections.\n",
    "\n",
    "## Required sections\n",
    "### 1 Aggregate statistics\n",
    "Summarise the numbers from (A).\n",
    "\n",
    "### 2 Recurring error patterns\n",
    "Identify frequent error types and link them to biases in **{VISION_MODEL}**.\n",
    "\n",
    "### 3 Detailed list of incoherent images\n",
    "For every image in (B) (score < {COHERENCE_THRESHOLD}) list:\n",
    "• file_name  • ≤15-word prompt summary  • three worst labels  • explanation (≤2 sentences).\n",
    "\n",
    "### 4 Target class logit analysis (Full Details)\n",
    "Include the full details of the target class analysis from (C).\n",
    "\n",
    "### 5 Main biases of the model\n",
    "At least three systematic biases, with examples.\n",
    "\n",
    "### 6 Overall verdict\n",
    "Bullet strengths/weaknesses of **{VISION_MODEL}** + final reliability rating 1–5 (no mitigation advice).\n",
    "\n",
    "Respond **only** in Markdown, start each major section with '##'.\n",
    "\"\"\"\n",
    "\n",
    "payload = (\n",
    "    prompt_header\n",
    "    + \"\\n\\n### (A) Global metrics\\n```json\\n\"\n",
    "    + json.dumps(metrics_summary, ensure_ascii=False, indent=2)\n",
    "    + \"\\n```\\n\\n### (B) Incoherent images\\n```json\\n\"\n",
    "    + json.dumps(incoherent_recs, ensure_ascii=False)\n",
    "    + \"\\n```\\n\\n### (C) Target class logit analysis (Full Details)\\n\"\n",
    "    + logit_report_section\n",
    ")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=LLM_MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": \"You are a senior AI-bias analyst who MUST reply in Markdown headings.\"},\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": payload}\n",
    "    ],\n",
    "    temperature=0.25\n",
    ")\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "report_path = OUTPUT_DIR / \"report.md\"\n",
    "report_path.write_text(response.choices[0].message.content, encoding=\"utf-8\")\n",
    "print(\"✅ Report saved to:\", report_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81372111",
   "metadata": {},
   "source": [
    "📺 Visualizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "cfa58426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report salvato in: analysis_alex/report.md\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## 1 Aggregate statistics\n",
       "- **Total Images**: 282\n",
       "- **Mean Score**: 0.27\n",
       "- **Median Score**: 0.2\n",
       "- **Standard Deviation of Scores**: 0.19\n",
       "- **Percentage of Incoherent Images**: 34.4%\n",
       "  \n",
       "## 2 Recurring error patterns\n",
       "- **Misclassification of Objects**: The model frequently misclassifies objects, such as identifying apples as sports equipment or tools, indicating a lack of contextual understanding.\n",
       "- **Contextual Irrelevance**: Many predictions do not align with the provided context, such as identifying a book in a classroom as unrelated items like a marimba or window shade.\n",
       "- **Overgeneralization**: The model often generalizes categories too broadly, leading to incorrect predictions for specific prompts, such as mistaking a notebook for an envelope or binder.\n",
       "\n",
       "## 3 Detailed list of incoherent images\n",
       "| File Name | Prompt Summary | Worst Labels | Explanation |\n",
       "|-----------|----------------|--------------|-------------|\n",
       "| apple__classroom_row_of_desks_daylight__001.png | Neutral apple in classroom | tennis ball, screwdriver, printer | Predictions are unrelated to the prompt, indicating a lack of alignment. |\n",
       "| apple__classroom_row_of_desks_daylight__002.png | Neutral apple in classroom | screwdriver, ping-pong ball, rubber eraser | Predictions do not align with the prompt; items are unrelated to an apple or classroom setting. |\n",
       "| apple__classroom_row_of_desks_daylight__003.png | Neutral apple in classroom | sliding door, police van, turnstile | Predictions do not relate to an apple or classroom context. |\n",
       "| apple__garage_workshop_tools_on_pegboard__001.png | Neutral apple in garage | joystick, oscilloscope, bubble | Predictions are unrelated to the prompt, indicating a lack of alignment. |\n",
       "| apple__garage_workshop_tools_on_pegboard__003.png | Neutral apple in garage | joystick, remote control, traffic light | Predictions do not align with the prompt; no apple or workshop tools identified. |\n",
       "| apple__garage_workshop_tools_on_pegboard__004.png | Neutral apple in garage | croquet ball, hair slide, lemon | Predictions do not align with the prompt; items are unrelated to an apple or workshop tools. |\n",
       "| apple__garage_workshop_tools_on_pegboard__005.png | Neutral apple in garage | window screen, apron, loudspeaker | Predictions do not align with the prompt; items are unrelated to an apple or workshop tools. |\n",
       "| apple__green_park_lawn_afternoon_light__002.png | Neutral apple in park | golf ball, ping-pong ball, croquet ball | Predictions are unrelated to the prompt about an apple in a park. |\n",
       "| apple__green_park_lawn_afternoon_light__003.png | Neutral apple in park | croquet ball, golf ball, pool table | Predictions are unrelated to the prompt, focusing on sports equipment instead of an apple in a park. |\n",
       "| apple__green_park_lawn_afternoon_light__004.png | Neutral apple in park | croquet ball, golf ball, baseball | Predictions are unrelated to the prompt, focusing on sports balls instead of an apple. |\n",
       "| apple__hotel_room_desk_area__003.png | Neutral apple in hotel room | tennis ball, ping-pong ball, lemon | Predictions are unrelated to the prompt, indicating a lack of alignment. |\n",
       "| apple__hotel_room_desk_area__004.png | Neutral apple in hotel room | pool table, Granny Smith, joystick | Predictions do not align with the prompt; no apple or hotel room context present. |\n",
       "| apple__kitchen_countertop_daylight__001.png | Neutral apple in kitchen | candle, piggy bank, pomegranate | Predictions do not align with the prompt; no apple detected. |\n",
       "| apple__kitchen_countertop_daylight__003.png | Neutral apple in kitchen | hip, pomegranate, pool table | Predictions do not align with the prompt; items are unrelated to an apple or kitchen context. |\n",
       "| apple__minimalist_living-room_corner__001.png | Neutral apple in living room | cup, ping-pong ball, notebook | Predictions do not align with the prompt; items are unrelated to an apple or minimalist living-room. |\n",
       "| apple__modern_office_desk__001.png | Neutral apple in office | notebook, computer keyboard, iPod | Predictions focus on office equipment, not an apple or relevant context. |\n",
       "| apple__plain_white_studio_background__001.png | Neutral apple in studio | ping-pong ball, cup, mixing bowl | Predictions do not align with the prompt; items are unrelated to an apple or a plain background. |\n",
       "| apple__science_lab_bench__001.png | Neutral apple in lab | digital clock, joystick, ping-pong ball | Predictions do not align with the prompt; no apple or lab-related items are present. |\n",
       "| apple__science_lab_bench__002.png | Neutral apple in lab | pomegranate, abacus, soap dispenser | Predictions do not align with the prompt; apple is not present and other items are unrelated. |\n",
       "| ceramic_coffee_mug__bathroom_vanity_matte_tiles__003.png | Ceramic mug in bathroom | radio, punching bag, marimba | Predictions do not align with the prompt; none relate to a coffee mug or bathroom setting. |\n",
       "| ceramic_coffee_mug__classroom_row_of_desks_daylight__003.png | Ceramic mug in classroom | espresso, coffeepot, espresso maker | Predictions are unrelated to a coffee mug or classroom setting. |\n",
       "| ceramic_coffee_mug__garage_workshop_tools_on_pegboard__002.png | Ceramic mug in garage | pug, crossword puzzle, rule | Predictions do not align with the prompt about a coffee mug in a workshop. |\n",
       "| ceramic_coffee_mug__garage_workshop_tools_on_pegboard__003.png | Ceramic mug in garage | microphone, hammer, digital clock | Predictions focus on tools and unrelated items, lacking relevance to the coffee mug. |\n",
       "| ceramic_coffee_mug__kitchen_countertop_daylight__001.png | Ceramic mug in kitchen | monitor, screen, table lamp | Predictions are unrelated to a coffee mug or kitchen setting. |\n",
       "| hardcover_book_(closed)__bathroom_vanity_matte_tiles__001.png | Hardcover book in bathroom | window shade, shoji, sliding door | Predictions are unrelated to the prompt, indicating a significant misalignment. |\n",
       "| hardcover_book_(closed)__garage_workshop_tools_on_pegboard__002.png | Hardcover book in garage | handkerchief, window screen, shower curtain | Predictions do not align with the prompt; items are unrelated to a book or workshop context. |\n",
       "| hardcover_book_(closed)__garage_workshop_tools_on_pegboard__003.png | Hardcover book in garage | switch, loudspeaker, binder | Predictions do not align with the prompt; items are unrelated to a book or workshop context. |\n",
       "| hardcover_book_(closed)__green_park_lawn_afternoon_light__001.png | Hardcover book in park | window shade, binder, book jacket | Predictions do not align with the prompt; items are unrelated to a book in a park. |\n",
       "| hardcover_book_(closed)__hotel_room_desk_area__001.png | Hardcover book in hotel | envelope, rubber eraser, notebook | Predictions do not align with the prompt; items are unrelated to a book. |\n",
       "| hardcover_book_(closed)__modern_office_desk__001.png | Hardcover book in office | chime, radiator, organ | Predictions do not align with the prompt; items are unrelated to a book or office setting. |\n",
       "| matte_gray_sphere__bathroom_vanity_matte_tiles__003.png | Gray sphere in bathroom | washbasin, notebook, toilet tissue | Predictions do not align with the prompt's description of a gray sphere. |\n",
       "| matte_gray_sphere__classroom_row_of_desks_daylight__001.png | Gray sphere in classroom | pill bottle, pool table, joystick | Predictions do not align with the prompt; items are unrelated to a gray sphere in a classroom. |\n",
       "| matte_gray_sphere__garage_workshop_tools_on_pegboard__002.png | Gray sphere in garage | ping-pong ball, baseball, teapot | Predictions do not align with the prompt; items are unrelated to a gray sphere or workshop context. |\n",
       "| matte_gray_sphere__green_park_lawn_afternoon_light__003.png | Gray sphere in park | golf ball, rugby ball, baseball | Predictions are primarily sports balls, not aligning with the description of a gray sphere. |\n",
       "| notebook_with_kraft_cover__classroom_row_of_desks_daylight__004.png | Notebook in classroom | digital clock, binder, theater curtain | Predictions do not align with the prompt; items are unrelated to a notebook or classroom setting. |\n",
       "| notebook_with_kraft_cover__garage_workshop_tools_on_pegboard__004.png | Notebook in garage | dial telephone, reflex camera, pay-phone | Predictions do not align with the prompt about a notebook and workshop tools. |\n",
       "| notebook_with_kraft_cover__hotel_room_desk_area__001.png | Notebook in hotel room | envelope, binder, doormat | Predictions do not align with the prompt's description of a notebook in a hotel room. |\n",
       "| opaque_metal_water_bottle__bathroom_vanity_matte_tiles__002.png | Water bottle in bathroom | soap dispenser, coffeepot, lotion | Predictions do not align with the prompt; items are unrelated to a water bottle. |\n",
       "| opaque_metal_water_bottle__green_park_lawn_afternoon_light__004.png | Water bottle in park | sandal, buckle, can opener | Predictions do not relate to a water bottle or park setting. |\n",
       "| plain_cardboard_box__classroom_row_of_desks_daylight__001.png | Cardboard box in classroom | scabbard, fountain pen, flute | Predictions do not align with the prompt; items are unrelated to a cardboard box in a classroom. |\n",
       "| simple_wooden_chair__classroom_row_of_desks_daylight__003.png | Wooden chair in classroom | pier, dock, boathouse | Predictions are unrelated to the prompt about a wooden chair in a classroom. |\n",
       "\n",
       "## 4 Main biases of the model\n",
       "- **Object Recognition Bias**: The model struggles to accurately identify specific objects, often misclassifying them as unrelated items. For example, apples are frequently identified as sports equipment.\n",
       "- **Contextual Understanding Bias**: The model fails to maintain context, leading to predictions that do not align with the described setting. For instance, a book in a classroom is misidentified as a tool or furniture.\n",
       "- **Overgeneralization Bias**: The model tends to generalize categories too broadly, resulting in incorrect predictions. For example, it may classify a notebook as an envelope or binder, disregarding the specific context.\n",
       "\n",
       "## 5 Overall verdict\n",
       "- **Strengths**:\n",
       "  - Capable of identifying a wide range of objects.\n",
       "  - Provides predictions based on visual data.\n",
       "\n",
       "- **Weaknesses**:\n",
       "  - High rate of incoherence (34.4%).\n",
       "  - Frequent misclassification and lack of contextual understanding.\n",
       "  - Tendency to overgeneralize categories.\n",
       "\n",
       "- **Final Reliability Rating**: 2/5"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 7: Output finale\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "print(\"Report salvato in:\", OUTPUT_DIR / \"report.md\")\n",
    "report_md = report_path.read_text(encoding=\"utf-8\")\n",
    "display(Markdown(report_md))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
