{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "254a6f00",
   "metadata": {},
   "source": [
    "# Progetto XAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44d9906",
   "metadata": {},
   "source": [
    "Generazione del Dataset tramite Stable Diffusion\n",
    "\n",
    "Scelte progettuali: soggetti e contesti\n",
    "\n",
    "La generazione del dataset è stata eseguita tramite Stable Diffusion, con l’obiettivo di analizzare la presenza e l’impatto di indizi spuri nelle immagini. Gli indizi spuri sono elementi visivi non rilevanti rispetto alla classe target, ma che possono essere appresi dal modello come scorciatoie spurie per la classificazione. Analizzarli nel nostro contesto ci consente di valutare quanto i modelli neurali siano sensibili o robusti a queste correlazioni spurie durante il training.\n",
    "\n",
    "Motivazioni\n",
    "\n",
    "Le motivazioni alla base della scelta dei soggetti e dei contesti sono documentate anche nel nostro archivio interno (OneNote). In breve, abbiamo cercato di bilanciare soggetti neutri e contesti ad alto bias visivo, per osservare come i modelli discriminano tra il contenuto semanticamente rilevante e quello potenzialmente fuorviante.\n",
    "\n",
    "⸻\n",
    "\n",
    "Soggetti Neutri (10 oggetti)\n",
    "\n",
    "Questi soggetti sono stati scelti per la loro natura visivamente semplice e per la bassa probabilità che inducano bias nel modello:\n",
    "\t1.\tCuscino\n",
    "\t2.\tSedia semplice\n",
    "\t3.\tBottiglia trasparente\n",
    "\t4.\tCiotola vuota\n",
    "\t5.\tCubo grigio (astratto, geometrico)\n",
    "\t6.\tLampadina spenta\n",
    "\t7.\tLibro chiuso\n",
    "\t8.\tTazza vuota\n",
    "\t9.\tScatola di cartone anonima\n",
    "\t10.\tPersona con t-shirt neutra\n",
    "\n",
    "⸻\n",
    "\n",
    "Contesti Ad Alto Bias (inizialmente selezionati)\n",
    "\n",
    "I seguenti contesti presentano una forte impronta semantica o simbolica, e sono quindi considerati ad alto potenziale di bias:\n",
    "\t1.\tInterno ufficio moderno (scrivania, laptop, lampada)\n",
    "\t2.\tCucina con elettrodomestici\n",
    "\t3.\tPrato verde all’aperto (ambiente naturale)\n",
    "\t4.\tAmbiente militare (uniformi, elmetti)\n",
    "\t5.\tPubblicità con colori vivaci (rosso/blu, banner)\n",
    "\t6.\tSala conferenze con palco\n",
    "\t7.\tBagno domestico (piastrelle, lavabo)\n",
    "\t8.\tLaboratorio scientifico (tubi, beute, microscopi)\n",
    "\t9.\tGarage / officina (attrezzi, macchinari)\n",
    "\t10.\tCorridoio scolastico con banchi\n",
    "\n",
    "⸻\n",
    "\n",
    "Limitazioni Tecniche\n",
    "\n",
    "Tuttavia, la generazione fedele di questi contesti si è rivelata troppo complessa per i motori di Stable Diffusion attualmente a nostra disposizione. In particolare, contesti ricchi di oggetti strutturati e relazioni spaziali complesse hanno mostrato bassa coerenza visiva, ambiguità semantica e artefatti nei dettagli.\n",
    "\n",
    "Conclusione\n",
    "\n",
    "Di conseguenza, si è scelto di delimitare il set di contesti a quelli effettivamente generabili in modo coerente, riducendo la complessità ambientale per mantenere un dataset visivamente consistente e utile all’analisi sperimentale.\n",
    "\n",
    "⸻\n",
    "\n",
    "Da rivedere le classi, devono corrispondere a quelle di image net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0f2cc138",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'diffusers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdiffusers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StableDiffusionPipeline\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# --- Configurazione ---\u001b[39;00m\n\u001b[1;32m     12\u001b[0m objects \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mceramic coffee mug\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhardcover book (closed)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplain cardboard box\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimple wooden chair\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoft couch pillow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopaque metal water bottle\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable lamp with shade (off)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapple\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnotebook with kraft cover\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatte gray sphere\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m ]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'diffusers'"
     ]
    }
   ],
   "source": [
    "#ESEGUIRE SU KAGGLE O IN UN AMBIENTE CON GPU IN CUI SONO INSTALLATI DIFFUSERS E TORCH\n",
    "#da modificare che le nuove classi\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "# --- Configurazione ---\n",
    "objects = [\n",
    "    \"ceramic coffee mug\", \"hardcover book (closed)\", \"plain cardboard box\",\n",
    "    \"simple wooden chair\", \"soft couch pillow\", \"opaque metal water bottle\",\n",
    "    \"table lamp with shade (off)\", \"apple\", \"notebook with kraft cover\", \"matte gray sphere\"\n",
    "]\n",
    "contexts = [\n",
    "    \"plain white studio background\", \"minimalist living-room corner\", \"modern office desk\",\n",
    "    \"kitchen countertop daylight\", \"green park lawn afternoon light\",\n",
    "    \"science lab bench\", \"garage workshop tools on pegboard\",\n",
    "    \"hotel room desk area\", \"bathroom vanity matte tiles\", \"classroom row of desks daylight\"\n",
    "]\n",
    "\n",
    "# --- Output Directory ---\n",
    "base_dir = Path(\"/kaggle/working/dataset\")\n",
    "img_dir = base_dir / \"images\"\n",
    "img_dir.mkdir(parents=True, exist_ok=True)\n",
    "csv_meta = base_dir / \"dataset_metadata.csv\"\n",
    "\n",
    "# --- Inizializza pipeline Stable Diffusion ---\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16,\n",
    "    use_safetensors=True,\n",
    "    low_cpu_mem_usage=True\n",
    ").to(\"cuda\")\n",
    "pipe.enable_attention_slicing()\n",
    "\n",
    "# --- CSV setup ---\n",
    "csvfile = open(csv_meta, \"w\", newline=\"\")\n",
    "writer = csv.DictWriter(csvfile, fieldnames=[\"file_name\", \"prompt\", \"seed\", \"background\"])\n",
    "writer.writeheader()\n",
    "\n",
    "# --- Generazione immagini + metadati ---\n",
    "img_counter = 1\n",
    "for obj in objects:\n",
    "    for ctx in contexts:\n",
    "        prompt = f\"A neutral {obj} in a {ctx} background\"\n",
    "        obj_short = obj.replace(\" \", \"\").replace(\"(\", \"\").replace(\")\", \"\").lower()\n",
    "        ctx_short = ctx.split()[0].lower()  # solo la prima parola del contesto\n",
    "\n",
    "        for i in range(2):  # Numero immagini per combinazione\n",
    "            filename = f\"{obj_short}__{ctx_short}__{i+1:03}.png\"\n",
    "            file_path = img_dir / filename\n",
    "\n",
    "            # Generazione immagine\n",
    "            img = pipe(prompt, num_inference_steps=30, guidance_scale=11).images[0]\n",
    "            img.save(file_path)\n",
    "\n",
    "            # Scrittura riga CSV\n",
    "            writer.writerow({\n",
    "                \"file_name\": f\"images/{filename}\",\n",
    "                \"prompt\": prompt,\n",
    "                \"seed\": i + 1,\n",
    "                \"background\": ctx\n",
    "            })\n",
    "            img_counter += 1\n",
    "\n",
    "csvfile.close()\n",
    "print(\"✅ Immagini e metadati generati!\")\n",
    "\n",
    "# --- Creazione ZIP finale ---\n",
    "zip_path = \"/kaggle/working/dataset.zip\"\n",
    "with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for file_path in base_dir.rglob(\"*\"):\n",
    "        zipf.write(file_path, arcname=file_path.relative_to(base_dir.parent))\n",
    "\n",
    "print(\"✅ ZIP pronto per il download:\", zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae04aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n"
     ]
    }
   ],
   "source": [
    "! pip install -q openai pandas pyarrow pillow tqdm urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "08f0e271",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# --- Carica metadata e filtra per presenza oggetto/contesto + CLIP ---\u001b[39;00m\n\u001b[1;32m     37\u001b[0m cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpart_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcfg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampler\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 38\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMETA_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mprompt\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Applica filtro testuale\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parquet.py:274\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m _get_path_or_handle(\n\u001b[1;32m    268\u001b[0m     path,\n\u001b[1;32m    269\u001b[0m     filesystem,\n\u001b[1;32m    270\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    271\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    272\u001b[0m )\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m     result \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mto_pandas(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mto_pandas_kwargs)\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pyarrow/parquet/core.py:1843\u001b[0m, in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, binary_type, list_type, memory_map, buffer_size, partitioning, filesystem, filters, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification, arrow_extensions_enabled)\u001b[0m\n\u001b[1;32m   1831\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_table\u001b[39m(source, \u001b[38;5;241m*\u001b[39m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, use_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1832\u001b[0m                schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, use_pandas_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, read_dictionary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1833\u001b[0m                binary_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, list_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1839\u001b[0m                page_checksum_verification\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1840\u001b[0m                arrow_extensions_enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1842\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1843\u001b[0m         dataset \u001b[38;5;241m=\u001b[39m \u001b[43mParquetDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1844\u001b[0m \u001b[43m            \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1845\u001b[0m \u001b[43m            \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1846\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1847\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartitioning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1849\u001b[0m \u001b[43m            \u001b[49m\u001b[43mread_dictionary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_dictionary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1850\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbinary_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1851\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlist_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlist_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1852\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1853\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m            \u001b[49m\u001b[43mignore_prefixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_prefixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1855\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpre_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1856\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcoerce_int96_timestamp_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_int96_timestamp_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecryption_properties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecryption_properties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mthrift_string_size_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrift_string_size_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mthrift_container_size_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrift_container_size_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpage_checksum_verification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpage_checksum_verification\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m            \u001b[49m\u001b[43marrow_extensions_enabled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrow_extensions_enabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1863\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m   1864\u001b[0m         \u001b[38;5;66;03m# fall back on ParquetFile for simple cases when pyarrow.dataset\u001b[39;00m\n\u001b[1;32m   1865\u001b[0m         \u001b[38;5;66;03m# module is not available\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pyarrow/parquet/core.py:1413\u001b[0m, in \u001b[0;36mParquetDataset.__init__\u001b[0;34m(self, path_or_paths, filesystem, schema, filters, read_dictionary, binary_type, list_type, memory_map, buffer_size, partitioning, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification, arrow_extensions_enabled)\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m single_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1410\u001b[0m     fragment \u001b[38;5;241m=\u001b[39m parquet_format\u001b[38;5;241m.\u001b[39mmake_fragment(single_file, filesystem)\n\u001b[1;32m   1412\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mFileSystemDataset(\n\u001b[0;32m-> 1413\u001b[0m         [fragment], schema\u001b[38;5;241m=\u001b[39mschema \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mfragment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphysical_schema\u001b[49m,\n\u001b[1;32m   1414\u001b[0m         \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mparquet_format,\n\u001b[1;32m   1415\u001b[0m         filesystem\u001b[38;5;241m=\u001b[39mfragment\u001b[38;5;241m.\u001b[39mfilesystem\n\u001b[1;32m   1416\u001b[0m     )\n\u001b[1;32m   1417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;66;03m# check partitioning to enable dictionary encoding\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pyarrow/_dataset.pyx:1473\u001b[0m, in \u001b[0;36mpyarrow._dataset.Fragment.physical_schema.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pyarrow/error.pxi:155\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pyarrow/error.pxi:92\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file."
     ]
    }
   ],
   "source": [
    "#prendo le immagini da diffusiondb soluzione alternativa ma non realizzabile \n",
    "import os, pandas as pd, urllib.request, zipfile, csv\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import openai\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# --- CONFIGURAZIONE ---\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "OBJ_CTX_PAIRS = [(\"apple\", \"studio\")]\n",
    "CLIP_THRESH = 0.30\n",
    "COSINE_THRESH = 0.30\n",
    "MAX_IMAGES = 50\n",
    "MAX_PARTS = 5\n",
    "\n",
    "BASE = Path(\"./dataset_diffdb\")\n",
    "IMG_DIR = BASE / \"images\"; IMG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CSV_META = BASE / \"dataset_metadata.csv\"\n",
    "META_URL = \"https://huggingface.co/datasets/poloclub/diffusiondb/resolve/main/metadata.parquet\"\n",
    "META_FILE = BASE / \"metadata.parquet\"\n",
    "\n",
    "# --- Funzione generazione prompt coerente ---\n",
    "def make_prompt(obj, ctx):\n",
    "    return (\n",
    "        f\"A product shot photo of a red {obj}, close-up, \"\n",
    "        f\"on a clean {ctx} background, soft natural lighting, minimalistic composition\"\n",
    "    )\n",
    "\n",
    "# --- Scarica metadata.parquet se necessario ---\n",
    "if not META_FILE.exists():\n",
    "    print(\"⬇️ Scarico metadata.parquet…\")\n",
    "    urllib.request.urlretrieve(META_URL, META_FILE)\n",
    "\n",
    "# --- Carica metadata e filtra per presenza oggetto/contesto + CLIP ---\n",
    "cols = [\"image_name\", \"prompt\", \"part_id\", \"cfg\", \"seed\", \"clip\", \"sampler\"]\n",
    "df = pd.read_parquet(META_FILE, columns=cols)\n",
    "df[\"prompt\"] = df.prompt.str.lower()\n",
    "\n",
    "# Applica filtro testuale\n",
    "mask = df.prompt.apply(lambda t: any(o in t and ctx in t for o, ctx in OBJ_CTX_PAIRS)) & (df.clip >= CLIP_THRESH)\n",
    "df_f = df[mask].reset_index(drop=True)\n",
    "\n",
    "# Limita per numero parti e immagini\n",
    "parts = df_f.part_id.unique().tolist()[:MAX_PARTS]\n",
    "df_f = df_f[df_f.part_id.isin(parts)].head(MAX_IMAGES).reset_index(drop=True)\n",
    "\n",
    "# --- Embedding prompt migliorati ---\n",
    "print(\"🔍 Calcolo embedding dei prompt con OpenAI\")\n",
    "prompt_map = {make_prompt(o, c): (o, c) for o, c in OBJ_CTX_PAIRS}\n",
    "prompt_embeds = {p: np.array(openai.Embeddings.create(model=\"text-embedding-3-small\", input=p).data[0].embedding)\n",
    "                 for p in prompt_map.keys()}\n",
    "\n",
    "# --- Scarica immagini e confronta embedding ---\n",
    "to_keep = []\n",
    "parts_done = set()\n",
    "\n",
    "for _, r in tqdm(df_f.iterrows(), total=len(df_f), desc=\"Verifica embedding\"):\n",
    "    # Trova il prompt strutturato associato a questo record\n",
    "    matched = next((p for p, (o, c) in prompt_map.items() if o in r.prompt and c in r.prompt), None)\n",
    "    if matched is None:\n",
    "        continue\n",
    "\n",
    "    # Scarica il part.zip se necessario\n",
    "    if r.part_id not in parts_done:\n",
    "        zip_n = f\"part-{int(r.part_id):06}.zip\"\n",
    "        urllib.request.urlretrieve(f\"https://huggingface.co/datasets/poloclub/diffusiondb/resolve/main/images/{zip_n}\", zip_n)\n",
    "        zipfile.ZipFile(zip_n).extractall(f\"part-{int(r.part_id):06}\")\n",
    "        parts_done.add(r.part_id)\n",
    "\n",
    "    # Embedding immagine\n",
    "    img = Image.open(Path(f\"part-{int(r.part_id):06}\") / r.image_name)\n",
    "    img_bytes = open(img.fp.name, \"rb\").read()\n",
    "    resp = openai.Embeddings.create(model=\"text-embedding-ada-002\", input=img_bytes)\n",
    "    img_emb = np.array(resp.data[0].embedding)\n",
    "\n",
    "    # Confronto cosine\n",
    "    cosine = np.dot(prompt_embeds[matched], img_emb) / (norm(prompt_embeds[matched]) * norm(img_emb))\n",
    "    if cosine >= COSINE_THRESH:\n",
    "        r[\"prompt_structured\"] = matched\n",
    "        r[\"cosine\"] = cosine\n",
    "        to_keep.append(r)\n",
    "\n",
    "df_sel = pd.DataFrame(to_keep)\n",
    "\n",
    "# --- Salva immagini selezionate e CSV ---\n",
    "with open(CSV_META, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"file\", \"prompt\", \"prompt_structured\", \"cfg\", \"seed\", \"sampler\", \"clip\", \"cosine\"])\n",
    "    writer.writeheader()\n",
    "    for _, r in df_sel.iterrows():\n",
    "        src = Path(f\"part-{int(r.part_id):06}\") / r.image_name\n",
    "        Image.open(src).save(IMG_DIR / r.image_name)\n",
    "        writer.writerow({\n",
    "            \"file\": f\"images/{r.image_name}\",\n",
    "            \"prompt\": r.prompt,\n",
    "            \"prompt_structured\": r.prompt_structured,\n",
    "            \"cfg\": float(r.cfg),\n",
    "            \"seed\": int(r.seed),\n",
    "            \"sampler\": int(r.sampler),\n",
    "            \"clip\": float(r.clip),\n",
    "            \"cosine\": round(float(r.cosine), 4)\n",
    "        })\n",
    "\n",
    "print(\"✅ Dataset finale creato:\", len(df_sel), \"immagini.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9e78e416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pycocotools in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (2.0.10)\n",
      "Requirement already satisfied: requests in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (2.32.3)\n",
      "Requirement already satisfied: pillow in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (11.1.0)\n",
      "Requirement already satisfied: pandas in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (2.2.3)\n",
      "Requirement already satisfied: tqdm in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (from pycocotools) (2.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (from requests) (1.26.20)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip3 install pycocotools requests pillow pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0cec3b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⬇️ Sto scaricando le annotazioni COCO 2017…\n",
      "  🗃️ Estraggo annotations/captions_val2017.json\n",
      "✅ Annotations pronte in annotations/captions_val2017.json\n"
     ]
    }
   ],
   "source": [
    "# Prendo immagini casuali da COCO 2017 analizzando questa soluzione ci siamo resi conto che non è possibile fare un dataset di immagini casuali \n",
    "# servono soggetti specifici presenti in ImageNet-1k\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# Percorsi e URL\n",
    "ANNOT_DIR = Path(\"annotations\")\n",
    "ANNOT_DIR.mkdir(exist_ok=True)\n",
    "url = \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"\n",
    "zip_path = ANNOT_DIR / \"annotations_trainval2017.zip\"\n",
    "\n",
    "# Scarica lo zip se manca\n",
    "if not (ANNOT_DIR / \"captions_val2017.json\").exists():\n",
    "    print(\"⬇️ Sto scaricando le annotazioni COCO 2017…\")\n",
    "    resp = requests.get(url, stream=True)\n",
    "    with open(zip_path, \"wb\") as f:\n",
    "        for chunk in resp.iter_content(1024*1024):\n",
    "            f.write(chunk)\n",
    "    # Estrai solo i file di interesse\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "        for fname in [\"annotations/captions_val2017.json\"]:\n",
    "            print(\"  🗃️ Estraggo\", fname)\n",
    "            z.extract(fname, \".\")\n",
    "    os.remove(zip_path)\n",
    "    print(\"✅ Annotations pronte in\", ANNOT_DIR / \"captions_val2017.json\")\n",
    "else:\n",
    "    print(\"✅ File annotations/captions_val2017.json già presente, non scarico.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b78c0adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scarico immagini: 100%|██████████| 50/50 [00:35<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fatto! 50 immagini salvate in dataset_coco/images e metadata in dataset_coco/dataset_metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "\n",
    "# --- CONFIGURAZIONE ---\n",
    "BASE = Path(\"./dataset_coco\")\n",
    "ANNOT_DIR = Path(\"./annotations\")\n",
    "ANNOT_FILE = ANNOT_DIR / \"captions_val2017.json\"\n",
    "IMG_DIR = BASE / \"images\"; IMG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CSV_META = BASE / \"dataset_metadata.csv\"\n",
    "\n",
    "# Controlla presenza file JSON\n",
    "if not ANNOT_FILE.exists():\n",
    "    raise FileNotFoundError(f\"File annotazioni mancante: {ANNOT_FILE}\")\n",
    "\n",
    "# Carica annotazioni COCO\n",
    "coco = COCO(str(ANNOT_FILE))\n",
    "\n",
    "# Seleziona 50 immagini casuali\n",
    "img_ids = coco.getImgIds()\n",
    "sel_ids = random.sample(img_ids, 50)\n",
    "\n",
    "rows = []\n",
    "for img_id in tqdm(sel_ids, desc=\"Scarico immagini\"):\n",
    "    info = coco.loadImgs(img_id)[0]\n",
    "    url = info[\"coco_url\"]\n",
    "    fname = info[\"file_name\"]\n",
    "\n",
    "    # Scarica l'immagine\n",
    "    resp = requests.get(url, timeout=10)\n",
    "    img_path = IMG_DIR / fname\n",
    "    img_path.write_bytes(resp.content)\n",
    "\n",
    "    # Carica didascalie\n",
    "    ann_ids = coco.getAnnIds(imgIds=[img_id])\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "    captions = [ann[\"caption\"] for ann in anns]\n",
    "    prompt = captions[0] if captions else \"\"\n",
    "\n",
    "    rows.append({\n",
    "        \"file\": f\"images/{fname}\",\n",
    "        \"prompt\": prompt\n",
    "    })\n",
    "\n",
    "# Salva CSV finale\n",
    "pd.DataFrame(rows).to_csv(CSV_META, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ Fatto! 50 immagini salvate in {IMG_DIR} e metadata in {CSV_META}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "bee6a7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Copied 282 images to dataset/images\n",
      "✅ metadata.csv written → dataset/dataset_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "#BLOCCO UTILE SOLO AD ADATTARE VECCHIA STRUTTURA DELLA CARTELLA ALLA NUOVA\n",
    "\n",
    "import csv, re, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "SRC_ROOT = Path(\"all_images/generated_images\")      # cartelle esistenti\n",
    "DEST_ROOT = Path(\"dataset\")                         # nuova struttura\n",
    "IMG_DIR   = DEST_ROOT / \"images\"; IMG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "META_CSV  = DEST_ROOT / \"dataset_metadata.csv\"\n",
    "\n",
    "objects = [\n",
    "    \"ceramic coffee mug\", \"hardcover book (closed)\", \"plain cardboard box\",\n",
    "    \"simple wooden chair\", \"soft couch pillow\", \"opaque metal water bottle\",\n",
    "    \"table lamp with shade (off)\", \"apple\", \"notebook with kraft cover\",\n",
    "    \"matte gray sphere\"\n",
    "]\n",
    "\n",
    "contexts = [\n",
    "    \"plain white studio background\", \"minimalist living-room corner\",\n",
    "    \"modern office desk\", \"kitchen countertop daylight\",\n",
    "    \"green park lawn afternoon light\", \"science lab bench\",\n",
    "    \"garage workshop tools on pegboard\", \"hotel room desk area\",\n",
    "    \"bathroom vanity matte tiles\", \"classroom row of desks daylight\"\n",
    "]\n",
    "\n",
    "prompt_map = {\n",
    "    f\"{obj.replace(' ', '_').lower()}__{ctx.replace(' ', '_').replace('/', '_').lower()}\":\n",
    "    f\"A neutral {obj} in a {ctx} background\"\n",
    "    for obj in objects\n",
    "    for ctx in contexts\n",
    "}\n",
    "\n",
    "def normalize(name: str) -> str:\n",
    "    n = name.lower().replace(\"/\", \"_\").replace(\" \", \"_\")\n",
    "    n = re.sub(r\"__+\", \"__\", n).strip(\"_\")\n",
    "    return n\n",
    "\n",
    "def build_filename(obj_ctx: str, idx: int) -> str:\n",
    "    obj_part, ctx_part = obj_ctx.split(\"__\", 1)\n",
    "    return f\"{obj_part}__{ctx_part}__{idx:03}.png\"\n",
    "\n",
    "rows = []\n",
    "for folder in sorted(SRC_ROOT.iterdir()):\n",
    "    if not folder.is_dir():\n",
    "        continue\n",
    "    key = normalize(folder.name)\n",
    "    prompt = prompt_map.get(key)\n",
    "    if prompt is None:\n",
    "        print(f\"⚠️  Skip un-recognised folder: {folder.name}\")\n",
    "        continue\n",
    "\n",
    "    for i, img_path in enumerate(sorted(folder.glob(\"*.png\")), start=1):\n",
    "        new_name = build_filename(key, i)\n",
    "        shutil.copy(img_path, IMG_DIR / new_name)\n",
    "\n",
    "        seed = re.search(r\"(\\d+)\", img_path.stem)\n",
    "        rows.append({\n",
    "            \"file_name\": f\"images/{new_name}\",\n",
    "            \"prompt\": prompt,\n",
    "            \"seed\": int(seed.group(1)) if seed else \"\",\n",
    "            \"background\": key\n",
    "        })\n",
    "\n",
    "print(f\"✅ Copied {len(rows)} images to {IMG_DIR}\")\n",
    "\n",
    "with META_CSV.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"file_name\",\"prompt\",\"seed\",\"background\"])\n",
    "    writer.writeheader(); writer.writerows(rows)\n",
    "\n",
    "print(\"✅ metadata.csv written →\", META_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3ba049",
   "metadata": {},
   "source": [
    "## Analizzo un modello a partire dal DataSet di Immagini\n",
    "\n",
    "A questo punto del notebook si deve avere un DataSet di immagini coerenti, con il DataSet Metadata. Bisogna stare attenti alla successive configurazioni, le cartelle devono essere quelle che si voglio analizzare ecc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "830dd71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Installazione pacchetti (esegui una volta)\n",
    "! pip3 install -q torch torchvision openai python-dotenv pillow tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ec18c1",
   "metadata": {},
   "source": [
    "📁 Configurazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2f68a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VISION_MODEL: alexnet\n",
      "LLM_MODEL: gpt-4o-mini\n",
      "OPENAI_API_KEY: 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\n",
      "IMG_DIR: dataset/images\n",
      "META_CSV: dataset/dataset_metadata.csv\n",
      "OUTPUT_DIR: analysis_alexnet_1\n",
      "COHERENCE_THRESHOLD: 0.3\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Configurazione variabili e caricamento ambiente\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carica da file .env se presente\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Variabili configurabili\n",
    "VISION_MODEL = os.getenv(\"VISION_MODEL\", \"alexnet\")\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"gpt-4o-mini\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "IMG_DIR = Path(os.getenv(\"IMG_DIR\", \"dataset_/images\"))\n",
    "META_CSV = Path(os.getenv(\"META_CSV\", \"dataset_/dataset_metadata.csv\"))\n",
    "OUTPUT_DIR = Path(os.getenv(\"OUTPUT_DIR\", \"analysis_out_\"))\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "COHERENCE_THRESHOLD = float(os.getenv(\"COHERENCE_TH\", 0.5))\n",
    "\n",
    "print(f\"VISION_MODEL: {VISION_MODEL}\")\n",
    "print(f\"LLM_MODEL: {LLM_MODEL}\")\n",
    "print(f\"OPENAI_API_KEY: {OPENAI_API_KEY}\")\n",
    "print(f\"IMG_DIR: {IMG_DIR}\")\n",
    "print(f\"META_CSV: {META_CSV}\")\n",
    "print(f\"OUTPUT_DIR: {OUTPUT_DIR}\")\n",
    "print(f\"COHERENCE_THRESHOLD: {COHERENCE_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9334f0b1",
   "metadata": {},
   "source": [
    "🧠 Caricamento modello visivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bd4a2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Carica modello vision e classi ImageNet\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Caricamento modello dinamico\n",
    "model = getattr(models, VISION_MODEL)(pretrained=True).eval().to(device)\n",
    "\n",
    "# Etichette ImageNet\n",
    "import urllib.request\n",
    "labels_url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "imagenet_labels = urllib.request.urlopen(labels_url).read().decode().splitlines()\n",
    "idx2label = {i: l for i, l in enumerate(imagenet_labels)}\n",
    "\n",
    "# Trasformazioni immagine\n",
    "transform = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6111376e",
   "metadata": {},
   "source": [
    "📊 Estrazione top-10 \n",
    "10 non è scelto a caso.\n",
    "Studi su ImageNet mostrano che i primi dieci logit spiegano in media oltre il 95 % della massa di probabilità soft-max per modelli come ResNet-50 o ViT-B/16.  Questo significa che, nella maggior parte dei casi, i concetti residui oltre il decimo posto contribuiscono poco alla descrizione semantica globale.\n",
    "https://arxiv.org/pdf/2206.07290\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7db62bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:01<00:00, 96.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Esempi di top‑10 logits:\n",
      "\n",
      "📌 dataset/images/ceramiccoffeemug__bathroom__001.png\n",
      "Prompt: A neutral ceramic coffee mug in a bathroom vanity matte tiles background\n",
      "Top‑10 logits (softmax):\n",
      "  - 804: soap dispenser (0.484)\n",
      "  - 896: washbasin (0.101)\n",
      "  - 876: tub (0.074)\n",
      "  - 861: toilet seat (0.064)\n",
      "  - 435: bathtub (0.055)\n",
      "  - 794: shower curtain (0.037)\n",
      "  - 999: toilet tissue (0.034)\n",
      "  - 897: washer (0.019)\n",
      "  - 453: bookcase (0.013)\n",
      "  - 731: plunger (0.008)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 4.73\n",
      "  - 861: toilet seat = 10.20\n",
      "  - 703: park bench = -2.80\n",
      "  - 620: laptop = 3.73\n",
      "  - 335: fox squirrel = -3.53\n",
      "  - 852: tennis ball = 2.47\n",
      "\n",
      "📌 dataset/images/ceramiccoffeemug__classroom__001.png\n",
      "Prompt: A neutral ceramic coffee mug in a classroom row of desks daylight background\n",
      "Top‑10 logits (softmax):\n",
      "  - 967: espresso (0.934)\n",
      "  - 504: coffee mug (0.043)\n",
      "  - 968: cup (0.016)\n",
      "  - 925: consomme (0.004)\n",
      "  - 969: eggnog (0.001)\n",
      "  - 809: soup bowl (0.001)\n",
      "  - 960: chocolate sauce (0.000)\n",
      "  - 901: whiskey jug (0.000)\n",
      "  - 666: mortar (0.000)\n",
      "  - 725: pitcher (0.000)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 0.64\n",
      "  - 861: toilet seat = 6.99\n",
      "  - 703: park bench = -1.75\n",
      "  - 620: laptop = 1.88\n",
      "  - 335: fox squirrel = -4.87\n",
      "  - 852: tennis ball = 3.68\n",
      "\n",
      "📌 dataset/images/ceramiccoffeemug__classroom__002.png\n",
      "Prompt: A neutral ceramic coffee mug in a classroom row of desks daylight background\n",
      "Top‑10 logits (softmax):\n",
      "  - 968: cup (0.229)\n",
      "  - 618: ladle (0.077)\n",
      "  - 632: loudspeaker (0.062)\n",
      "  - 745: projector (0.061)\n",
      "  - 772: safety pin (0.053)\n",
      "  - 605: iPod (0.043)\n",
      "  - 504: coffee mug (0.038)\n",
      "  - 999: toilet tissue (0.033)\n",
      "  - 418: ballpoint (0.021)\n",
      "  - 771: safe (0.016)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 2.29\n",
      "  - 861: toilet seat = 4.30\n",
      "  - 703: park bench = 0.44\n",
      "  - 620: laptop = 5.39\n",
      "  - 335: fox squirrel = -2.62\n",
      "  - 852: tennis ball = 5.08\n",
      "\n",
      "📌 dataset/images/ceramiccoffeemug__garage__001.png\n",
      "Prompt: A neutral ceramic coffee mug in a garage workshop tools on pegboard background\n",
      "Top‑10 logits (softmax):\n",
      "  - 587: hammer (0.126)\n",
      "  - 784: screwdriver (0.086)\n",
      "  - 721: pillow (0.074)\n",
      "  - 918: crossword puzzle (0.053)\n",
      "  - 921: book jacket (0.044)\n",
      "  - 539: doormat (0.025)\n",
      "  - 695: padlock (0.020)\n",
      "  - 662: modem (0.018)\n",
      "  - 720: pill bottle (0.018)\n",
      "  - 427: barrel (0.016)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 7.30\n",
      "  - 861: toilet seat = -0.30\n",
      "  - 703: park bench = -0.92\n",
      "  - 620: laptop = 2.19\n",
      "  - 335: fox squirrel = -1.61\n",
      "  - 852: tennis ball = 1.71\n",
      "\n",
      "📌 dataset/images/ceramiccoffeemug__green__002.png\n",
      "Prompt: A neutral ceramic coffee mug in a green park lawn afternoon light background\n",
      "Top‑10 logits (softmax):\n",
      "  - 504: coffee mug (0.866)\n",
      "  - 968: cup (0.064)\n",
      "  - 967: espresso (0.035)\n",
      "  - 725: pitcher (0.024)\n",
      "  - 809: soup bowl (0.002)\n",
      "  - 666: mortar (0.001)\n",
      "  - 899: water jug (0.001)\n",
      "  - 647: measuring cup (0.001)\n",
      "  - 505: coffeepot (0.001)\n",
      "  - 849: teapot (0.001)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 4.50\n",
      "  - 861: toilet seat = 8.60\n",
      "  - 703: park bench = 1.37\n",
      "  - 620: laptop = 3.19\n",
      "  - 335: fox squirrel = -3.96\n",
      "  - 852: tennis ball = 6.00\n",
      "\n",
      "📌 dataset/images/ceramiccoffeemug__hotel__001.png\n",
      "Prompt: A neutral ceramic coffee mug in a hotel room desk area background\n",
      "Top‑10 logits (softmax):\n",
      "  - 504: coffee mug (0.632)\n",
      "  - 968: cup (0.309)\n",
      "  - 725: pitcher (0.041)\n",
      "  - 505: coffeepot (0.008)\n",
      "  - 899: water jug (0.003)\n",
      "  - 999: toilet tissue (0.001)\n",
      "  - 849: teapot (0.001)\n",
      "  - 773: saltshaker (0.001)\n",
      "  - 647: measuring cup (0.001)\n",
      "  - 901: whiskey jug (0.001)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 8.44\n",
      "  - 861: toilet seat = 9.65\n",
      "  - 703: park bench = -0.76\n",
      "  - 620: laptop = 3.85\n",
      "  - 335: fox squirrel = -5.75\n",
      "  - 852: tennis ball = 5.46\n",
      "\n",
      "📌 dataset/images/ceramiccoffeemug__hotel__002.png\n",
      "Prompt: A neutral ceramic coffee mug in a hotel room desk area background\n",
      "Top‑10 logits (softmax):\n",
      "  - 846: table lamp (0.104)\n",
      "  - 527: desktop computer (0.080)\n",
      "  - 526: desk (0.072)\n",
      "  - 664: monitor (0.070)\n",
      "  - 681: notebook (0.070)\n",
      "  - 782: screen (0.067)\n",
      "  - 968: cup (0.066)\n",
      "  - 851: television (0.066)\n",
      "  - 626: lighter (0.050)\n",
      "  - 598: home theater (0.024)\n",
      "Logits classi target:\n",
      "  - 721: pillow = -1.30\n",
      "  - 861: toilet seat = 4.79\n",
      "  - 703: park bench = 0.33\n",
      "  - 620: laptop = 8.88\n",
      "  - 335: fox squirrel = -0.58\n",
      "  - 852: tennis ball = 1.38\n",
      "\n",
      "📌 dataset/images/ceramiccoffeemug__kitchen__001.png\n",
      "Prompt: A neutral ceramic coffee mug in a kitchen countertop daylight background\n",
      "Top‑10 logits (softmax):\n",
      "  - 648: medicine chest (0.462)\n",
      "  - 550: espresso maker (0.069)\n",
      "  - 631: lotion (0.038)\n",
      "  - 651: microwave (0.035)\n",
      "  - 859: toaster (0.033)\n",
      "  - 504: coffee mug (0.024)\n",
      "  - 849: teapot (0.024)\n",
      "  - 844: switch (0.019)\n",
      "  - 551: face powder (0.017)\n",
      "  - 505: coffeepot (0.015)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 3.89\n",
      "  - 861: toilet seat = 6.36\n",
      "  - 703: park bench = 0.50\n",
      "  - 620: laptop = 4.06\n",
      "  - 335: fox squirrel = -1.91\n",
      "  - 852: tennis ball = -0.12\n",
      "\n",
      "📌 dataset/images/ceramiccoffeemug__kitchen__002.png\n",
      "Prompt: A neutral ceramic coffee mug in a kitchen countertop daylight background\n",
      "Top‑10 logits (softmax):\n",
      "  - 968: cup (0.411)\n",
      "  - 504: coffee mug (0.287)\n",
      "  - 967: espresso (0.070)\n",
      "  - 849: teapot (0.065)\n",
      "  - 505: coffeepot (0.039)\n",
      "  - 725: pitcher (0.020)\n",
      "  - 605: iPod (0.014)\n",
      "  - 632: loudspeaker (0.009)\n",
      "  - 999: toilet tissue (0.007)\n",
      "  - 643: mask (0.007)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 6.63\n",
      "  - 861: toilet seat = 8.52\n",
      "  - 703: park bench = 2.04\n",
      "  - 620: laptop = 6.13\n",
      "  - 335: fox squirrel = -4.35\n",
      "  - 852: tennis ball = 2.99\n",
      "\n",
      "📌 dataset/images/ceramiccoffeemug__minimalist__001.png\n",
      "Prompt: A neutral ceramic coffee mug in a minimalist living-room corner background\n",
      "Top‑10 logits (softmax):\n",
      "  - 851: television (0.071)\n",
      "  - 605: iPod (0.059)\n",
      "  - 598: home theater (0.054)\n",
      "  - 846: table lamp (0.048)\n",
      "  - 831: studio couch (0.045)\n",
      "  - 632: loudspeaker (0.037)\n",
      "  - 619: lampshade (0.034)\n",
      "  - 782: screen (0.033)\n",
      "  - 681: notebook (0.027)\n",
      "  - 844: switch (0.025)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 0.95\n",
      "  - 861: toilet seat = 5.67\n",
      "  - 703: park bench = -0.16\n",
      "  - 620: laptop = 6.03\n",
      "  - 335: fox squirrel = -0.90\n",
      "  - 852: tennis ball = 3.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 - Estrazione logits: top‑10 + logit grezzi per classi target\n",
    "import csv\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_topk(logits, k=10):\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    top_p, top_i = torch.topk(probs, k)\n",
    "    return [(int(i), (idx2label[int(i)], float(p))) for p, i in zip(top_p.cpu(), top_i.cpu())]\n",
    "\n",
    "def get_class_logits(logits, target_ids):\n",
    "    return {i: float(logits[i].cpu()) for i in target_ids}\n",
    "\n",
    "# Carica prompt da CSV\n",
    "prompts = {}\n",
    "with open(META_CSV, newline='') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        prompts[Path(row[\"file_name\"].strip()).name] = row[\"prompt\"]\n",
    "\n",
    "###########\n",
    "# Classi target (nome → ID)\n",
    "target_classes = [\"pillow\", \"toilet seat\", \"park bench\", \"laptop\", \"fox squirrel\",\"tennis ball\"]\n",
    "labels_url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "imagenet_labels = urllib.request.urlopen(labels_url).read().decode().splitlines()\n",
    "idx2label = {i: l for i, l in enumerate(imagenet_labels)}\n",
    "label2idx = {l: i for i, l in enumerate(imagenet_labels)}\n",
    "target_ids = {label2idx[c]: c for c in target_classes}\n",
    "per_class_logit = defaultdict(list)\n",
    "#####\n",
    "\n",
    "# Risultati globali\n",
    "results = []\n",
    "\n",
    "# Analisi immagini\n",
    "for img_path in tqdm(sorted(IMG_DIR.glob(\"*.png\"))):\n",
    "    prompt = prompts.get(img_path.name)\n",
    "    if not prompt:\n",
    "        continue\n",
    "\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    with torch.no_grad():\n",
    "        logits = model(transform(image).unsqueeze(0).to(device))[0]\n",
    "\n",
    "    # Softmax top‑10 logits\n",
    "    top_logits = get_topk(logits, k=10)\n",
    "\n",
    "    # Logit grezzi delle 6 classi target\n",
    "    selected_logits = get_class_logits(logits, target_ids.keys())\n",
    "\n",
    "    # Salva entrambi\n",
    "    results.append({\n",
    "        \"file_name\": str(img_path),\n",
    "        \"prompt\": prompt,\n",
    "        \"top_logits\": top_logits,\n",
    "        \"class_logits\": selected_logits\n",
    "    })\n",
    "\n",
    "    # Aggrega per classe (per il report dedicato)\n",
    "    for cls_id, val in selected_logits.items():\n",
    "        per_class_logit[cls_id].append({\n",
    "            \"file_name\": str(img_path),\n",
    "            \"prompt\": prompt,\n",
    "            \"logit\": val\n",
    "        })\n",
    "\n",
    "# Debug/preview\n",
    "print(\"\\n✅ Esempi di top‑10 logits:\")\n",
    "for r in results[:10]:\n",
    "    print(f\"\\n📌 {r['file_name']}\")\n",
    "    print(f\"Prompt: {r['prompt']}\")\n",
    "    print(\"Top‑10 logits (softmax):\")\n",
    "    for i, (label, p) in r[\"top_logits\"]:\n",
    "        print(f\"  - {i}: {label} ({p:.3f})\")\n",
    "    print(\"Logits classi target:\")\n",
    "    for i, val in r[\"class_logits\"].items():\n",
    "        print(f\"  - {i}: {idx2label[i]} = {val:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d479795",
   "metadata": {},
   "source": [
    "🤖 Valutazione coerenza con LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc0a408d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COHERENCE_THRESHOLD: 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM analysis: 100%|██████████| 91/91 [02:11<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== RIEPILOGO ==========\n",
      "Totale immagini:   91\n",
      "Incoerenti (<0.3): 38  (41.8 %)\n",
      "\n",
      "-- Incoerenza per *oggetto* --\n",
      "  ceramic coffee mug                 : 5/16  (31.2 %)\n",
      "  notebook with kraft cover          : 11/15  (73.3 %)\n",
      "  opaque metal water bottle          : 9/20  (45.0 %)\n",
      "  soft couch pillow                  : 10/20  (50.0 %)\n",
      "  table lamp with shade (off)        : 3/20  (15.0 %)\n",
      "\n",
      "-- Incoerenza per *contesto* --\n",
      "  bathroom vanity matte tiles        : 3/7  (42.9 %)\n",
      "  classroom row of desks daylight    : 3/8  (37.5 %)\n",
      "  garage workshop tools on pegboard  : 7/8  (87.5 %)\n",
      "  green park lawn afternoon light    : 2/9  (22.2 %)\n",
      "  hotel room desk area               : 3/10  (30.0 %)\n",
      "  kitchen countertop daylight        : 4/10  (40.0 %)\n",
      "  minimalist living-room corner      : 5/10  (50.0 %)\n",
      "  modern office desk                 : 4/10  (40.0 %)\n",
      "  plain white studio background      : 3/10  (30.0 %)\n",
      "  science lab bench                  : 4/9  (44.4 %)\n",
      "================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 – LLM coherence audit • compatibile con Python < 3.10\n",
    "import openai, json, re, os, sys\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "from typing import List, Optional          # <— NEW\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# ─── LISTE CANONICHE ──────────────────────────────────────────────────\n",
    "OBJECTS = [\n",
    "    \"ceramic coffee mug\", \"hardcover book (closed)\",  \"soft couch pillow\", \"opaque metal water bottle\",\n",
    "    \"table lamp with shade (off)\", \"apple\", \"notebook with kraft cover\"\n",
    "]\n",
    "\n",
    "CONTEXTS = [\n",
    "    \"plain white studio background\", \"minimalist living-room corner\",\n",
    "    \"modern office desk\", \"kitchen countertop daylight\",\n",
    "    \"green park lawn afternoon light\", \"science lab bench\",\n",
    "    \"garage workshop tools on pegboard\", \"hotel room desk area\",\n",
    "    \"bathroom vanity matte tiles\", \"classroom row of desks daylight\"\n",
    "]\n",
    "\n",
    "def find_match(text: str, phrases: List[str]) -> Optional[str]:\n",
    "    \"\"\"Restituisce la prima frase (più lunga) di 'phrases' trovata in 'text'.\"\"\"\n",
    "    text = text.lower()\n",
    "    for phrase in sorted(phrases, key=len, reverse=True):\n",
    "        if phrase.lower() in text:\n",
    "            return phrase\n",
    "    return None\n",
    "\n",
    "# ─── PARAMETRI ────────────────────────────────────────────────────────\n",
    "COHERENCE_THRESHOLD = float(os.getenv(\"COHERENCE_TH\", 0.3))\n",
    "print(f\"COHERENCE_THRESHOLD: {COHERENCE_THRESHOLD}\")\n",
    "\n",
    "LOG_JSONL_PATH = OUTPUT_DIR / \"llm_audit.jsonl\"\n",
    "LIVE_TXT_PATH  = OUTPUT_DIR / \"llm_live_output.txt\"\n",
    "\n",
    "# ─── FUNZIONI DI SUPPORTO ─────────────────────────────────────────────\n",
    "def extract_json_from_text(text: str) -> dict:\n",
    "    m = re.search(r\"\\{.*?\\}\", text, re.DOTALL)\n",
    "    if not m:\n",
    "        raise ValueError(\"⚠️ No valid JSON found\")\n",
    "    return json.loads(m.group(0))\n",
    "\n",
    "def query_llm(prompt: str, top_logits, vision_model=VISION_MODEL) -> dict:\n",
    "    def safe_label_prob(item):\n",
    "        try:\n",
    "            label = str(item[0])\n",
    "            prob_raw = item[1]\n",
    "            prob = float(prob_raw[0]) if isinstance(prob_raw, (tuple, list)) else float(prob_raw)\n",
    "            return f\"{label} ({prob:.3f})\"\n",
    "        except Exception:\n",
    "            return f\"[MALFORMED: {item}]\"\n",
    "\n",
    "    top_str = \"; \".join([safe_label_prob(it) for it in top_logits])\n",
    "\n",
    "    user_msg = f\"\"\"\n",
    "You are auditing the output of **{vision_model}** to assess alignment with the prompt.\n",
    "\n",
    "Prompt:\n",
    "\\\"{prompt}\\\"\n",
    "\n",
    "Top-10 predictions with probabilities:\n",
    "{top_str}\n",
    "\n",
    "Return JSON only:\n",
    "{{\n",
    "  \"score\": <float 0-1>,\n",
    "  \"explanation\": <≤25 words>,\n",
    "  \"confidence\": <float 0-1 (optional)>\n",
    "}}\n",
    "Be lenient; score ≥ 0.3 is considered coherent.\n",
    "\"\"\"\n",
    "\n",
    "    res = openai.chat.completions.create(\n",
    "        model=LLM_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Return strict JSON only.\"},\n",
    "            {\"role\": \"user\",   \"content\": user_msg}\n",
    "        ],\n",
    "        temperature=0.0\n",
    "    )\n",
    "    return extract_json_from_text(res.choices[0].message.content.strip())\n",
    "\n",
    "# ─── CONTATORI ────────────────────────────────────────────────────────\n",
    "tot = tot_incoh = 0\n",
    "per_obj_tot = Counter(); per_obj_incoh = Counter()\n",
    "per_ctx_tot = Counter(); per_ctx_incoh = Counter()\n",
    "incoherent_cases = []\n",
    "\n",
    "# ─── LOOP PRINCIPALE ──────────────────────────────────────────────────\n",
    "with open(LOG_JSONL_PATH, \"w\") as fout, open(LIVE_TXT_PATH, \"w\") as live:\n",
    "    for r in tqdm(results, desc=\"LLM analysis\"):\n",
    "        tot += 1\n",
    "        prompt_lc = r[\"prompt\"].lower()\n",
    "\n",
    "        obj = find_match(prompt_lc, OBJECTS)  or \"unknown-object\"\n",
    "        ctx = find_match(prompt_lc, CONTEXTS) or \"unknown-context\"\n",
    "\n",
    "        per_obj_tot[obj] += 1\n",
    "        per_ctx_tot[ctx] += 1\n",
    "\n",
    "        llm_out = query_llm(r[\"prompt\"], r[\"top_logits\"])\n",
    "        record  = {**r, **llm_out, \"subject\": obj, \"background\": ctx}\n",
    "\n",
    "        fout.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "        live.write(json.dumps({\n",
    "            \"id\": r.get(\"id\", tot),\n",
    "            \"score\": llm_out.get(\"score\"),\n",
    "            \"explanation\": llm_out.get(\"explanation\")\n",
    "        }, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "        if llm_out.get(\"score\", 0.0) < COHERENCE_THRESHOLD:\n",
    "            incoherent_cases.append(record)\n",
    "            tot_incoh += 1\n",
    "            per_obj_incoh[obj] += 1\n",
    "            per_ctx_incoh[ctx] += 1\n",
    "\n",
    "# ─── REPORT FINALE ────────────────────────────────────────────────────\n",
    "print(\"\\n========== RIEPILOGO ==========\")\n",
    "pct = 100 * tot_incoh / tot if tot else 0\n",
    "print(f\"Totale immagini:   {tot}\")\n",
    "print(f\"Incoerenti (<{COHERENCE_THRESHOLD}): {tot_incoh}  ({pct:.1f} %)\")\n",
    "\n",
    "print(\"\\n-- Incoerenza per *oggetto* --\")\n",
    "for o in sorted(per_obj_tot):\n",
    "    pct = 100 * per_obj_incoh[o] / per_obj_tot[o] if per_obj_tot[o] else 0\n",
    "    print(f\"  {o:35s}: {per_obj_incoh[o]}/{per_obj_tot[o]}  ({pct:.1f} %)\")\n",
    "\n",
    "print(\"\\n-- Incoerenza per *contesto* --\")\n",
    "for c in sorted(per_ctx_tot):\n",
    "    pct = 100 * per_ctx_incoh[c] / per_ctx_tot[c] if per_ctx_tot[c] else 0\n",
    "    print(f\"  {c:35s}: {per_ctx_incoh[c]}/{per_ctx_tot[c]}  ({pct:.1f} %)\")\n",
    "\n",
    "print(\"================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaae9b7a",
   "metadata": {},
   "source": [
    "📝 Generazione report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1d1a650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## 🔍 Target Class Analysis (Raw Logits)\n",
      "\n",
      "### Class `pillow` (ImageNet #721)\n",
      "- Number of activations: 91\n",
      "- Average logit: 3.65 (std: 4.02)\n",
      "- Top‑5 activations:\n",
      "  - `dataset/images/softcouchpillow__modern__001.png` → logit=14.17\n",
      "  - `dataset/images/softcouchpillow__green__002.png` → logit=13.05\n",
      "  - `dataset/images/softcouchpillow__kitchen__002.png` → logit=12.28\n",
      "  - `dataset/images/softcouchpillow__modern__002.png` → logit=11.82\n",
      "  - `dataset/images/softcouchpillow__green__001.png` → logit=11.74\n",
      "\n",
      "### Class `toilet seat` (ImageNet #861)\n",
      "- Number of activations: 91\n",
      "- Average logit: 4.42 (std: 2.78)\n",
      "- Top‑5 activations:\n",
      "  - `dataset/images/softcouchpillow__minimalist__001.png` → logit=12.37\n",
      "  - `dataset/images/ceramiccoffeemug__bathroom__001.png` → logit=10.20\n",
      "  - `dataset/images/ceramiccoffeemug__hotel__001.png` → logit=9.65\n",
      "  - `dataset/images/softcouchpillow__classroom__001.png` → logit=9.57\n",
      "  - `dataset/images/tablelampwithshadeoff__bathroom__002.png` → logit=8.97\n",
      "\n",
      "### Class `park bench` (ImageNet #703)\n",
      "- Number of activations: 91\n",
      "- Average logit: 0.36 (std: 2.07)\n",
      "- Top‑5 activations:\n",
      "  - `dataset/images/tablelampwithshadeoff__classroom__002.png` → logit=9.02\n",
      "  - `dataset/images/tablelampwithshadeoff__green__001.png` → logit=5.06\n",
      "  - `dataset/images/ceramiccoffeemug__modern__002.png` → logit=4.34\n",
      "  - `dataset/images/opaquemetalwaterbottle__green__001.png` → logit=3.59\n",
      "  - `dataset/images/softcouchpillow__modern__001.png` → logit=3.50\n",
      "\n",
      "### Class `laptop` (ImageNet #620)\n",
      "- Number of activations: 91\n",
      "- Average logit: 5.10 (std: 2.56)\n",
      "- Top‑5 activations:\n",
      "  - `dataset/images/notebookwithkraftcover__science__001.png` → logit=13.48\n",
      "  - `dataset/images/notebookwithkraftcover__minimalist__002.png` → logit=12.49\n",
      "  - `dataset/images/notebookwithkraftcover__hotel__001.png` → logit=10.62\n",
      "  - `dataset/images/notebookwithkraftcover__hotel__002.png` → logit=9.17\n",
      "  - `dataset/images/softcouchpillow__modern__001.png` → logit=9.17\n",
      "\n",
      "### Class `fox squirrel` (ImageNet #335)\n",
      "- Number of activations: 91\n",
      "- Average logit: -3.06 (std: 1.74)\n",
      "- Top‑5 activations:\n",
      "  - `dataset/images/tablelampwithshadeoff__green__002.png` → logit=1.40\n",
      "  - `dataset/images/opaquemetalwaterbottle__green__002.png` → logit=0.63\n",
      "  - `dataset/images/ceramiccoffeemug__modern__002.png` → logit=0.34\n",
      "  - `dataset/images/opaquemetalwaterbottle__science__002.png` → logit=0.12\n",
      "  - `dataset/images/opaquemetalwaterbottle__kitchen__002.png` → logit=-0.28\n",
      "\n",
      "### Class `tennis ball` (ImageNet #852)\n",
      "- Number of activations: 91\n",
      "- Average logit: 2.97 (std: 2.44)\n",
      "- Top‑5 activations:\n",
      "  - `dataset/images/opaquemetalwaterbottle__green__002.png` → logit=9.01\n",
      "  - `dataset/images/opaquemetalwaterbottle__green__001.png` → logit=8.42\n",
      "  - `dataset/images/opaquemetalwaterbottle__kitchen__001.png` → logit=8.03\n",
      "  - `dataset/images/opaquemetalwaterbottle__classroom__001.png` → logit=7.58\n",
      "  - `dataset/images/opaquemetalwaterbottle__classroom__002.png` → logit=7.54\n",
      "\n",
      "✅ Report saved to: analysis_alexnet_1/report.md\n"
     ]
    }
   ],
   "source": [
    "# 📊 Cell 6 – Bias report & model verdict  (uses pre-computed metrics)\n",
    "import json, openai, statistics, os\n",
    "from pathlib import Path\n",
    "from statistics import mean, stdev\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# ── 1. Carica tutti i record prodotti nella cella Y ───────────────────\n",
    "with open(LOG_JSONL_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    records = [json.loads(l) for l in f]\n",
    "\n",
    "# Limita i top-logits a 5 etichette per risparmiare token\n",
    "for rec in records:\n",
    "    rec[\"top_logits\"] = rec.get(\"top_logits\", [])[:5]\n",
    "\n",
    "# Lista dei soli record incoerenti\n",
    "incoherent_recs = [\n",
    "    {k: rec[k] for k in (\"file_name\", \"prompt\", \"top_logits\", \"score\", \"explanation\")}\n",
    "    for rec in records if rec.get(\"score\", 0) < COHERENCE_THRESHOLD\n",
    "]\n",
    "\n",
    "# ── 2. Metriche globali (già calcolate a runtime nella cella Y) ───────\n",
    "scores = [rec.get(\"score\", 0.0) for rec in records]\n",
    "metrics_summary = {\n",
    "    \"total_images\": tot,\n",
    "    \"mean_score\": statistics.mean(scores) if scores else 0.0,\n",
    "    \"median_score\": statistics.median(scores) if scores else 0.0,\n",
    "    \"stdev_score\": statistics.pstdev(scores) if len(scores) > 1 else 0.0,\n",
    "    \"percent_incoherent\": 100 * tot_incoh / tot if tot else 0.0,\n",
    "    \"object_stats\": {\n",
    "        obj: {\n",
    "            \"total\": per_obj_tot[obj],\n",
    "            \"incoherent\": per_obj_incoh[obj],\n",
    "            \"percent_incoherent\": 100 * per_obj_incoh[obj] / per_obj_tot[obj]\n",
    "            if per_obj_tot[obj] else 0.0\n",
    "        }\n",
    "        for obj in per_obj_tot\n",
    "    },\n",
    "    \"context_stats\": {\n",
    "        ctx: {\n",
    "            \"total\": per_ctx_tot[ctx],\n",
    "            \"incoherent\": per_ctx_incoh[ctx],\n",
    "            \"percent_incoherent\": 100 * per_ctx_incoh[ctx] / per_ctx_tot[ctx]\n",
    "            if per_ctx_tot[ctx] else 0.0\n",
    "        }\n",
    "        for ctx in per_ctx_tot\n",
    "    }\n",
    "}\n",
    "\n",
    "# Salva le metriche su file (può tornare utile)\n",
    "Path(OUTPUT_DIR /  \"metrics.json\").write_text(json.dumps(metrics_summary, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "# ── 3. Analisi delle classi target (logits grezzi) ────────────────────\n",
    "logit_report_section = \"\\n## 🔍 Target Class Analysis (Raw Logits)\\n\"\n",
    "for cls_id, cls_name in target_ids.items():\n",
    "    values = [x[\"logit\"] for x in per_class_logit[cls_id]]\n",
    "    if not values:\n",
    "        continue\n",
    "\n",
    "    logit_report_section += f\"\\n### Class `{cls_name}` (ImageNet #{cls_id})\\n\"\n",
    "    logit_report_section += f\"- Number of activations: {len(values)}\\n\"\n",
    "    logit_report_section += f\"- Average logit: {mean(values):.2f} (std: {stdev(values):.2f})\\n\"\n",
    "    logit_report_section += \"- Top‑5 activations:\\n\"\n",
    "    top5 = sorted(per_class_logit[cls_id], key=lambda x: -x[\"logit\"])[:5]\n",
    "    for e in top5:\n",
    "       logit_report_section += f\"  - `{e['file_name']}` → logit={e['logit']:.2f}\\n\"\n",
    "\n",
    "print(logit_report_section)\n",
    "\n",
    "# ── 4. Prompt per l’LLM – passiamo già le metriche pre-calcolate ──────\n",
    "prompt_header = f\"\"\"\n",
    "You are an AI-bias auditor.  \n",
    "Below you will find **(A) pre-computed global metrics**, **(B) per-image data**, and **(C) target class logit analysis**.\n",
    "\n",
    "Use the provided metrics; do NOT recalculate means or percentages yourself.\n",
    "Respond in **Markdown** with the requested sections.\n",
    "\n",
    "## Required sections\n",
    "### 1 Aggregate statistics\n",
    "Summarise the numbers from (A).\n",
    "\n",
    "### 2 Recurring error patterns\n",
    "Identify frequent error types and link them to biases in **{VISION_MODEL}**.\n",
    "\n",
    "### 3 Detailed list of incoherent images\n",
    "For every image in (B) (score < {COHERENCE_THRESHOLD}) list:\n",
    "• file_name  • ≤15-word prompt summary  • three worst labels  • explanation (≤2 sentences).\n",
    "\n",
    "### 4 Target class logit analysis (Full Details)\n",
    "Include the full details of the target class analysis from (C).\n",
    "\n",
    "### 5 Main biases of the model\n",
    "At least three systematic biases, with examples.\n",
    "\n",
    "### 6 Overall verdict\n",
    "Bullet strengths/weaknesses of **{VISION_MODEL}** + final reliability rating 1–5 (no mitigation advice).\n",
    "\n",
    "Respond **only** in Markdown, start each major section with '##'.\n",
    "\"\"\"\n",
    "\n",
    "payload = (\n",
    "    prompt_header\n",
    "    + \"\\n\\n### (A) Global metrics\\n```json\\n\"\n",
    "    + json.dumps(metrics_summary, ensure_ascii=False, indent=2)\n",
    "    + \"\\n```\\n\\n### (B) Incoherent images\\n```json\\n\"\n",
    "    + json.dumps(incoherent_recs, ensure_ascii=False)\n",
    "    + \"\\n```\\n\\n### (C) Target class logit analysis (Full Details)\\n\"\n",
    "    + logit_report_section\n",
    ")\n",
    "\n",
    "# ── 5. Chiamata all’LLM ───────────────────────────────────────────────\n",
    "response = openai.chat.completions.create(\n",
    "    model=LLM_MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": \"You are a senior AI-bias analyst who MUST reply in Markdown headings.\"},\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": payload}\n",
    "    ],\n",
    "    temperature=0.25\n",
    ")\n",
    "\n",
    "# ── 6. Salvataggio del report ─────────────────────────────────────────\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "report_path = OUTPUT_DIR / \"report.md\"\n",
    "report_path.write_text(response.choices[0].message.content, encoding=\"utf-8\")\n",
    "print(\"✅ Report saved to:\", report_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81372111",
   "metadata": {},
   "source": [
    "📺 Visualizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "cfa58426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report salvato in: analysis_alex/report.md\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## 1 Aggregate statistics\n",
       "- **Total Images**: 282\n",
       "- **Mean Score**: 0.27\n",
       "- **Median Score**: 0.2\n",
       "- **Standard Deviation of Scores**: 0.19\n",
       "- **Percentage of Incoherent Images**: 34.4%\n",
       "  \n",
       "## 2 Recurring error patterns\n",
       "- **Misclassification of Objects**: The model frequently misclassifies objects, such as identifying apples as sports equipment or tools, indicating a lack of contextual understanding.\n",
       "- **Contextual Irrelevance**: Many predictions do not align with the provided context, such as identifying a book in a classroom as unrelated items like a marimba or window shade.\n",
       "- **Overgeneralization**: The model often generalizes categories too broadly, leading to incorrect predictions for specific prompts, such as mistaking a notebook for an envelope or binder.\n",
       "\n",
       "## 3 Detailed list of incoherent images\n",
       "| File Name | Prompt Summary | Worst Labels | Explanation |\n",
       "|-----------|----------------|--------------|-------------|\n",
       "| apple__classroom_row_of_desks_daylight__001.png | Neutral apple in classroom | tennis ball, screwdriver, printer | Predictions are unrelated to the prompt, indicating a lack of alignment. |\n",
       "| apple__classroom_row_of_desks_daylight__002.png | Neutral apple in classroom | screwdriver, ping-pong ball, rubber eraser | Predictions do not align with the prompt; items are unrelated to an apple or classroom setting. |\n",
       "| apple__classroom_row_of_desks_daylight__003.png | Neutral apple in classroom | sliding door, police van, turnstile | Predictions do not relate to an apple or classroom context. |\n",
       "| apple__garage_workshop_tools_on_pegboard__001.png | Neutral apple in garage | joystick, oscilloscope, bubble | Predictions are unrelated to the prompt, indicating a lack of alignment. |\n",
       "| apple__garage_workshop_tools_on_pegboard__003.png | Neutral apple in garage | joystick, remote control, traffic light | Predictions do not align with the prompt; no apple or workshop tools identified. |\n",
       "| apple__garage_workshop_tools_on_pegboard__004.png | Neutral apple in garage | croquet ball, hair slide, lemon | Predictions do not align with the prompt; items are unrelated to an apple or workshop tools. |\n",
       "| apple__garage_workshop_tools_on_pegboard__005.png | Neutral apple in garage | window screen, apron, loudspeaker | Predictions do not align with the prompt; items are unrelated to an apple or workshop tools. |\n",
       "| apple__green_park_lawn_afternoon_light__002.png | Neutral apple in park | golf ball, ping-pong ball, croquet ball | Predictions are unrelated to the prompt about an apple in a park. |\n",
       "| apple__green_park_lawn_afternoon_light__003.png | Neutral apple in park | croquet ball, golf ball, pool table | Predictions are unrelated to the prompt, focusing on sports equipment instead of an apple in a park. |\n",
       "| apple__green_park_lawn_afternoon_light__004.png | Neutral apple in park | croquet ball, golf ball, baseball | Predictions are unrelated to the prompt, focusing on sports balls instead of an apple. |\n",
       "| apple__hotel_room_desk_area__003.png | Neutral apple in hotel room | tennis ball, ping-pong ball, lemon | Predictions are unrelated to the prompt, indicating a lack of alignment. |\n",
       "| apple__hotel_room_desk_area__004.png | Neutral apple in hotel room | pool table, Granny Smith, joystick | Predictions do not align with the prompt; no apple or hotel room context present. |\n",
       "| apple__kitchen_countertop_daylight__001.png | Neutral apple in kitchen | candle, piggy bank, pomegranate | Predictions do not align with the prompt; no apple detected. |\n",
       "| apple__kitchen_countertop_daylight__003.png | Neutral apple in kitchen | hip, pomegranate, pool table | Predictions do not align with the prompt; items are unrelated to an apple or kitchen context. |\n",
       "| apple__minimalist_living-room_corner__001.png | Neutral apple in living room | cup, ping-pong ball, notebook | Predictions do not align with the prompt; items are unrelated to an apple or minimalist living-room. |\n",
       "| apple__modern_office_desk__001.png | Neutral apple in office | notebook, computer keyboard, iPod | Predictions focus on office equipment, not an apple or relevant context. |\n",
       "| apple__plain_white_studio_background__001.png | Neutral apple in studio | ping-pong ball, cup, mixing bowl | Predictions do not align with the prompt; items are unrelated to an apple or a plain background. |\n",
       "| apple__science_lab_bench__001.png | Neutral apple in lab | digital clock, joystick, ping-pong ball | Predictions do not align with the prompt; no apple or lab-related items are present. |\n",
       "| apple__science_lab_bench__002.png | Neutral apple in lab | pomegranate, abacus, soap dispenser | Predictions do not align with the prompt; apple is not present and other items are unrelated. |\n",
       "| ceramic_coffee_mug__bathroom_vanity_matte_tiles__003.png | Ceramic mug in bathroom | radio, punching bag, marimba | Predictions do not align with the prompt; none relate to a coffee mug or bathroom setting. |\n",
       "| ceramic_coffee_mug__classroom_row_of_desks_daylight__003.png | Ceramic mug in classroom | espresso, coffeepot, espresso maker | Predictions are unrelated to a coffee mug or classroom setting. |\n",
       "| ceramic_coffee_mug__garage_workshop_tools_on_pegboard__002.png | Ceramic mug in garage | pug, crossword puzzle, rule | Predictions do not align with the prompt about a coffee mug in a workshop. |\n",
       "| ceramic_coffee_mug__garage_workshop_tools_on_pegboard__003.png | Ceramic mug in garage | microphone, hammer, digital clock | Predictions focus on tools and unrelated items, lacking relevance to the coffee mug. |\n",
       "| ceramic_coffee_mug__kitchen_countertop_daylight__001.png | Ceramic mug in kitchen | monitor, screen, table lamp | Predictions are unrelated to a coffee mug or kitchen setting. |\n",
       "| hardcover_book_(closed)__bathroom_vanity_matte_tiles__001.png | Hardcover book in bathroom | window shade, shoji, sliding door | Predictions are unrelated to the prompt, indicating a significant misalignment. |\n",
       "| hardcover_book_(closed)__garage_workshop_tools_on_pegboard__002.png | Hardcover book in garage | handkerchief, window screen, shower curtain | Predictions do not align with the prompt; items are unrelated to a book or workshop context. |\n",
       "| hardcover_book_(closed)__garage_workshop_tools_on_pegboard__003.png | Hardcover book in garage | switch, loudspeaker, binder | Predictions do not align with the prompt; items are unrelated to a book or workshop context. |\n",
       "| hardcover_book_(closed)__green_park_lawn_afternoon_light__001.png | Hardcover book in park | window shade, binder, book jacket | Predictions do not align with the prompt; items are unrelated to a book in a park. |\n",
       "| hardcover_book_(closed)__hotel_room_desk_area__001.png | Hardcover book in hotel | envelope, rubber eraser, notebook | Predictions do not align with the prompt; items are unrelated to a book. |\n",
       "| hardcover_book_(closed)__modern_office_desk__001.png | Hardcover book in office | chime, radiator, organ | Predictions do not align with the prompt; items are unrelated to a book or office setting. |\n",
       "| matte_gray_sphere__bathroom_vanity_matte_tiles__003.png | Gray sphere in bathroom | washbasin, notebook, toilet tissue | Predictions do not align with the prompt's description of a gray sphere. |\n",
       "| matte_gray_sphere__classroom_row_of_desks_daylight__001.png | Gray sphere in classroom | pill bottle, pool table, joystick | Predictions do not align with the prompt; items are unrelated to a gray sphere in a classroom. |\n",
       "| matte_gray_sphere__garage_workshop_tools_on_pegboard__002.png | Gray sphere in garage | ping-pong ball, baseball, teapot | Predictions do not align with the prompt; items are unrelated to a gray sphere or workshop context. |\n",
       "| matte_gray_sphere__green_park_lawn_afternoon_light__003.png | Gray sphere in park | golf ball, rugby ball, baseball | Predictions are primarily sports balls, not aligning with the description of a gray sphere. |\n",
       "| notebook_with_kraft_cover__classroom_row_of_desks_daylight__004.png | Notebook in classroom | digital clock, binder, theater curtain | Predictions do not align with the prompt; items are unrelated to a notebook or classroom setting. |\n",
       "| notebook_with_kraft_cover__garage_workshop_tools_on_pegboard__004.png | Notebook in garage | dial telephone, reflex camera, pay-phone | Predictions do not align with the prompt about a notebook and workshop tools. |\n",
       "| notebook_with_kraft_cover__hotel_room_desk_area__001.png | Notebook in hotel room | envelope, binder, doormat | Predictions do not align with the prompt's description of a notebook in a hotel room. |\n",
       "| opaque_metal_water_bottle__bathroom_vanity_matte_tiles__002.png | Water bottle in bathroom | soap dispenser, coffeepot, lotion | Predictions do not align with the prompt; items are unrelated to a water bottle. |\n",
       "| opaque_metal_water_bottle__green_park_lawn_afternoon_light__004.png | Water bottle in park | sandal, buckle, can opener | Predictions do not relate to a water bottle or park setting. |\n",
       "| plain_cardboard_box__classroom_row_of_desks_daylight__001.png | Cardboard box in classroom | scabbard, fountain pen, flute | Predictions do not align with the prompt; items are unrelated to a cardboard box in a classroom. |\n",
       "| simple_wooden_chair__classroom_row_of_desks_daylight__003.png | Wooden chair in classroom | pier, dock, boathouse | Predictions are unrelated to the prompt about a wooden chair in a classroom. |\n",
       "\n",
       "## 4 Main biases of the model\n",
       "- **Object Recognition Bias**: The model struggles to accurately identify specific objects, often misclassifying them as unrelated items. For example, apples are frequently identified as sports equipment.\n",
       "- **Contextual Understanding Bias**: The model fails to maintain context, leading to predictions that do not align with the described setting. For instance, a book in a classroom is misidentified as a tool or furniture.\n",
       "- **Overgeneralization Bias**: The model tends to generalize categories too broadly, resulting in incorrect predictions. For example, it may classify a notebook as an envelope or binder, disregarding the specific context.\n",
       "\n",
       "## 5 Overall verdict\n",
       "- **Strengths**:\n",
       "  - Capable of identifying a wide range of objects.\n",
       "  - Provides predictions based on visual data.\n",
       "\n",
       "- **Weaknesses**:\n",
       "  - High rate of incoherence (34.4%).\n",
       "  - Frequent misclassification and lack of contextual understanding.\n",
       "  - Tendency to overgeneralize categories.\n",
       "\n",
       "- **Final Reliability Rating**: 2/5"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 7: Output finale\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "print(\"Report salvato in:\", OUTPUT_DIR / \"report.md\")\n",
    "report_md = report_path.read_text(encoding=\"utf-8\")\n",
    "display(Markdown(report_md))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
