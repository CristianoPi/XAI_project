{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a44d9906",
   "metadata": {},
   "source": [
    "## Project Overview: *Static Images Network Analyzer*\n",
    "\n",
    "This is the final project for the Cognitive Learning course, titled *Static Images Network Analyzer*.  \n",
    "The goal is to analyze **cognitive biases** in image classification models, focusing on **spurious correlations**â€”for example, when the model is influenced more by background context than by the actual object in the image.\n",
    "\n",
    "The project has two main phases:\n",
    "1. **Controlled dataset generation**: we created artificial images combining neutral objects with potentially bias-inducing visual contexts, using *Stable Diffusion v1.5*.  \n",
    "   > The image generation code is located in the file: `generate_dataset_diff_v1_5.py.py`.\n",
    "2. **Model analysis**: we evaluated how three pretrained classifiers (AlexNet, ResNet-18, ViT-18) responded to these images and measured whether their predictions aligned with the original prompt or were misled by context.  \n",
    "   > All analysis and evaluation steps are implemented in this notebook.\n",
    "\n",
    "We extract the **top-10 logits** for each image-model pair, and send both the original prompt and the predictions to a **language model (LLM)** for semantic auditing. The LLM provides a coherence score (0â€“1), a short explanation, and optional confidence. These evaluations are stored in a `.jsonl` file.\n",
    "\n",
    "Finally, we build an aggregated **bias report** using precomputed statistics and LLM-generated justifications. This final Markdown report includes:\n",
    "- Aggregate performance metrics\n",
    "- Recurring error patterns\n",
    "- Detailed list of incoherent predictions\n",
    "- Class-specific logit behavior\n",
    "- Overall model verdict\n",
    "\n",
    "This workflow allows us to systematically study the effect of **spurious visual cues** and assess the **robustness and reliability** of vision models through a cognitively informed pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ae04aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip3 install -q openai pandas pyarrow pillow tqdm urllib3 pycocotools requests torch torchvision python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ec18c1",
   "metadata": {},
   "source": [
    "### CONFIGURATION: load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f2f68a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VISION_MODEL: alexnet\n",
      "LLM_MODEL: gpt-4o-mini\n",
      "OPENAI_API_KEY: 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\n",
      "IMG_DIR: dataset/images\n",
      "META_CSV: dataset/dataset_metadata.csv\n",
      "OUTPUT_DIR: analysis_alexnet_1\n",
      "COHERENCE_THRESHOLD: 0.3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carica da file .env se presente\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Variabili configurabili\n",
    "VISION_MODEL = os.getenv(\"VISION_MODEL\", \"alexnet\")\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"gpt-4o-mini\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "IMG_DIR = Path(os.getenv(\"IMG_DIR\", \"dataset_/images\"))\n",
    "META_CSV = Path(os.getenv(\"META_CSV\", \"dataset_/dataset_metadata.csv\"))\n",
    "OUTPUT_DIR = Path(os.getenv(\"OUTPUT_DIR\", \"analysis_out_\"))\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "COHERENCE_THRESHOLD = float(os.getenv(\"COHERENCE_TH\", 0.5))\n",
    "TARGET_CLASSES = os.getenv(\"TARGET_CLASSES\", \"pillow,toilet seat,park bench,laptop,fox squirrel,tennis ball\").split(\",\")\n",
    "\n",
    "print(f\"VISION_MODEL: {VISION_MODEL}\")\n",
    "print(f\"LLM_MODEL: {LLM_MODEL}\")\n",
    "print(f\"OPENAI_API_KEY: {OPENAI_API_KEY}\")\n",
    "print(f\"IMG_DIR: {IMG_DIR}\")\n",
    "print(f\"META_CSV: {META_CSV}\")\n",
    "print(f\"OUTPUT_DIR: {OUTPUT_DIR}\")\n",
    "print(f\"COHERENCE_THRESHOLD: {COHERENCE_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9334f0b1",
   "metadata": {},
   "source": [
    "### Load view model and ImageNet classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd4a2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model dynamic loading\n",
    "model = getattr(models, VISION_MODEL)(pretrained=True).eval().to(device)\n",
    "\n",
    "#  ImageNet labels\n",
    "import urllib.request\n",
    "labels_url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "imagenet_labels = urllib.request.urlopen(labels_url).read().decode().splitlines()\n",
    "idx2label = {i: l for i, l in enumerate(imagenet_labels)}\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize(256),\n",
    "    #T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6111376e",
   "metadata": {},
   "source": [
    "### Top-10 Extraction\n",
    "\n",
    "The choice of 10 is not arbitrary.  \n",
    "Studies on ImageNet show that the **top ten logits** account for, on average, **over 95% of the softmax probability mass** in models such as **ResNet-50** or **ViT-B/16**.  \n",
    "This means that, in most cases, the remaining classes beyond the 10th position **contribute minimally to the overall semantic representation**.\n",
    "\n",
    "> Source: [arXiv:2206.07290](https://arxiv.org/pdf/2206.07290)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7db62bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121/121 [00:01<00:00, 79.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¾ Risultati salvati in: analysis_alexnet_1/logits.json\n",
      "\n",
      "âœ… Esempi di topâ€‘10 logits:\n",
      "\n",
      "ðŸ“Œ dataset/images/bookjacket__classroom__001.png\n",
      "Prompt: A neutral bookjacket in a classroom background\n",
      "Topâ€‘10 logits (softmax):\n",
      "  - 549: envelope (0.234)\n",
      "  - 696: paintbrush (0.070)\n",
      "  - 605: iPod (0.067)\n",
      "  - 620: laptop (0.047)\n",
      "  - 813: spatula (0.036)\n",
      "  - 692: packet (0.035)\n",
      "  - 831: studio couch (0.035)\n",
      "  - 767: rubber eraser (0.034)\n",
      "  - 418: ballpoint (0.034)\n",
      "  - 446: binder (0.034)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 3.52\n",
      "  - 861: toilet seat = 5.36\n",
      "  - 703: park bench = 3.45\n",
      "  - 620: laptop = 8.96\n",
      "  - 335: fox squirrel = -5.22\n",
      "  - 852: tennis ball = 2.74\n",
      "\n",
      "ðŸ“Œ dataset/images/bookjacket__classroom__002.png\n",
      "Prompt: A neutral bookjacket in a classroom background\n",
      "Topâ€‘10 logits (softmax):\n",
      "  - 910: wooden spoon (0.392)\n",
      "  - 605: iPod (0.129)\n",
      "  - 642: marimba (0.055)\n",
      "  - 868: tray (0.041)\n",
      "  - 620: laptop (0.027)\n",
      "  - 823: stethoscope (0.025)\n",
      "  - 813: spatula (0.025)\n",
      "  - 681: notebook (0.023)\n",
      "  - 767: rubber eraser (0.022)\n",
      "  - 563: fountain pen (0.019)\n",
      "Logits classi target:\n",
      "  - 721: pillow = -1.64\n",
      "  - 861: toilet seat = 5.68\n",
      "  - 703: park bench = 3.30\n",
      "  - 620: laptop = 11.38\n",
      "  - 335: fox squirrel = -5.61\n",
      "  - 852: tennis ball = 0.04\n",
      "\n",
      "ðŸ“Œ dataset/images/bookjacket__garage__002.png\n",
      "Prompt: A neutral bookjacket in a garage background\n",
      "Topâ€‘10 logits (softmax):\n",
      "  - 563: fountain pen (0.084)\n",
      "  - 763: revolver (0.053)\n",
      "  - 754: radio (0.043)\n",
      "  - 418: ballpoint (0.041)\n",
      "  - 587: hammer (0.030)\n",
      "  - 877: turnstile (0.029)\n",
      "  - 592: hard disc (0.028)\n",
      "  - 848: tape player (0.026)\n",
      "  - 798: slide rule (0.025)\n",
      "  - 784: screwdriver (0.020)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 1.42\n",
      "  - 861: toilet seat = 1.07\n",
      "  - 703: park bench = 1.64\n",
      "  - 620: laptop = 5.86\n",
      "  - 335: fox squirrel = -2.05\n",
      "  - 852: tennis ball = 1.14\n",
      "\n",
      "ðŸ“Œ dataset/images/bookjacket__green__001.png\n",
      "Prompt: A neutral bookjacket in a green background\n",
      "Topâ€‘10 logits (softmax):\n",
      "  - 605: iPod (0.659)\n",
      "  - 620: laptop (0.072)\n",
      "  - 592: hard disc (0.056)\n",
      "  - 681: notebook (0.040)\n",
      "  - 446: binder (0.031)\n",
      "  - 921: book jacket (0.029)\n",
      "  - 549: envelope (0.016)\n",
      "  - 487: cellular telephone (0.013)\n",
      "  - 748: purse (0.011)\n",
      "  - 902: whistle (0.010)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 5.25\n",
      "  - 861: toilet seat = 5.39\n",
      "  - 703: park bench = -0.20\n",
      "  - 620: laptop = 15.80\n",
      "  - 335: fox squirrel = -5.58\n",
      "  - 852: tennis ball = 3.69\n",
      "\n",
      "ðŸ“Œ dataset/images/bookjacket__green__002.png\n",
      "Prompt: A neutral bookjacket in a green background\n",
      "Topâ€‘10 logits (softmax):\n",
      "  - 549: envelope (0.706)\n",
      "  - 620: laptop (0.081)\n",
      "  - 446: binder (0.052)\n",
      "  - 893: wallet (0.051)\n",
      "  - 868: tray (0.010)\n",
      "  - 692: packet (0.010)\n",
      "  - 605: iPod (0.009)\n",
      "  - 767: rubber eraser (0.009)\n",
      "  - 478: carton (0.007)\n",
      "  - 499: cleaver (0.007)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 7.18\n",
      "  - 861: toilet seat = 5.66\n",
      "  - 703: park bench = 3.79\n",
      "  - 620: laptop = 13.10\n",
      "  - 335: fox squirrel = -4.80\n",
      "  - 852: tennis ball = 3.43\n",
      "\n",
      "ðŸ“Œ dataset/images/bookjacket__hotel__001.png\n",
      "Prompt: A neutral bookjacket in a hotel background\n",
      "Topâ€‘10 logits (softmax):\n",
      "  - 846: table lamp (0.120)\n",
      "  - 831: studio couch (0.095)\n",
      "  - 619: lampshade (0.057)\n",
      "  - 742: printer (0.048)\n",
      "  - 750: quilt (0.040)\n",
      "  - 681: notebook (0.026)\n",
      "  - 713: photocopier (0.022)\n",
      "  - 894: wardrobe (0.021)\n",
      "  - 605: iPod (0.021)\n",
      "  - 782: screen (0.021)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 3.25\n",
      "  - 861: toilet seat = 4.71\n",
      "  - 703: park bench = -0.13\n",
      "  - 620: laptop = 5.19\n",
      "  - 335: fox squirrel = -3.46\n",
      "  - 852: tennis ball = 1.75\n",
      "\n",
      "ðŸ“Œ dataset/images/bookjacket__hotel__002.png\n",
      "Prompt: A neutral bookjacket in a hotel background\n",
      "Topâ€‘10 logits (softmax):\n",
      "  - 446: binder (0.153)\n",
      "  - 789: shoji (0.149)\n",
      "  - 749: quill (0.055)\n",
      "  - 619: lampshade (0.042)\n",
      "  - 905: window shade (0.033)\n",
      "  - 564: four-poster (0.030)\n",
      "  - 894: wardrobe (0.026)\n",
      "  - 681: notebook (0.021)\n",
      "  - 882: vacuum (0.020)\n",
      "  - 620: laptop (0.018)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 2.21\n",
      "  - 861: toilet seat = 4.12\n",
      "  - 703: park bench = 1.84\n",
      "  - 620: laptop = 6.74\n",
      "  - 335: fox squirrel = -2.68\n",
      "  - 852: tennis ball = 4.95\n",
      "\n",
      "ðŸ“Œ dataset/images/bookjacket__kitchen__002.png\n",
      "Prompt: A neutral bookjacket in a kitchen background\n",
      "Topâ€‘10 logits (softmax):\n",
      "  - 446: binder (0.096)\n",
      "  - 681: notebook (0.081)\n",
      "  - 620: laptop (0.061)\n",
      "  - 418: ballpoint (0.051)\n",
      "  - 789: shoji (0.049)\n",
      "  - 673: mouse (0.039)\n",
      "  - 549: envelope (0.035)\n",
      "  - 605: iPod (0.032)\n",
      "  - 696: paintbrush (0.028)\n",
      "  - 921: book jacket (0.028)\n",
      "Logits classi target:\n",
      "  - 721: pillow = -1.17\n",
      "  - 861: toilet seat = 2.90\n",
      "  - 703: park bench = 0.93\n",
      "  - 620: laptop = 7.74\n",
      "  - 335: fox squirrel = -0.38\n",
      "  - 852: tennis ball = 0.17\n",
      "\n",
      "ðŸ“Œ dataset/images/bookjacket__minimalist__001.png\n",
      "Prompt: A neutral bookjacket in a minimalist background\n",
      "Topâ€‘10 logits (softmax):\n",
      "  - 598: home theater (0.114)\n",
      "  - 556: fire screen (0.109)\n",
      "  - 851: television (0.073)\n",
      "  - 846: table lamp (0.051)\n",
      "  - 799: sliding door (0.045)\n",
      "  - 632: loudspeaker (0.043)\n",
      "  - 789: shoji (0.037)\n",
      "  - 681: notebook (0.031)\n",
      "  - 921: book jacket (0.031)\n",
      "  - 553: file (0.028)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 2.08\n",
      "  - 861: toilet seat = 3.37\n",
      "  - 703: park bench = -3.14\n",
      "  - 620: laptop = 7.45\n",
      "  - 335: fox squirrel = -2.30\n",
      "  - 852: tennis ball = 1.24\n",
      "\n",
      "ðŸ“Œ dataset/images/bookjacket__minimalist__002.png\n",
      "Prompt: A neutral bookjacket in a minimalist background\n",
      "Topâ€‘10 logits (softmax):\n",
      "  - 534: dishwasher (0.098)\n",
      "  - 760: refrigerator (0.092)\n",
      "  - 700: paper towel (0.058)\n",
      "  - 846: table lamp (0.058)\n",
      "  - 897: washer (0.057)\n",
      "  - 859: toaster (0.040)\n",
      "  - 651: microwave (0.030)\n",
      "  - 598: home theater (0.024)\n",
      "  - 619: lampshade (0.021)\n",
      "  - 789: shoji (0.019)\n",
      "Logits classi target:\n",
      "  - 721: pillow = 4.10\n",
      "  - 861: toilet seat = 4.65\n",
      "  - 703: park bench = -1.07\n",
      "  - 620: laptop = 5.72\n",
      "  - 335: fox squirrel = -1.49\n",
      "  - 852: tennis ball = -0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "import os \n",
    "\n",
    "def get_topk(logits, k=10):\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    top_p, top_i = torch.topk(probs, k)\n",
    "    return [(int(i), (idx2label[int(i)], float(p))) for p, i in zip(top_p.cpu(), top_i.cpu())]\n",
    "# Softmax is monotonic, so it can be used to rank logits, is more interpretable than raw logits for us and for LLM.\n",
    "\n",
    "def get_class_logits(logits, target_ids):\n",
    "    return {i: float(logits[i].cpu()) for i in target_ids}\n",
    "\n",
    "# load prompts from CSV\n",
    "prompts = {}\n",
    "with open(META_CSV, newline='') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        prompts[Path(row[\"file_name\"].strip()).name] = row[\"prompt\"]\n",
    "\n",
    "########### \n",
    "# target classes, for pt. 4 of the report  \n",
    "target_classes = TARGET_CLASSES\n",
    "labels_url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "imagenet_labels = urllib.request.urlopen(labels_url).read().decode().splitlines()\n",
    "idx2label = {i: l for i, l in enumerate(imagenet_labels)}\n",
    "label2idx = {l: i for i, l in enumerate(imagenet_labels)}\n",
    "target_ids = {label2idx[c]: c for c in target_classes}\n",
    "per_class_logit = defaultdict(list)\n",
    "#########\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "# Image analysis\n",
    "for img_path in tqdm(sorted(IMG_DIR.glob(\"*.png\"))):\n",
    "    prompt = prompts.get(img_path.name)\n",
    "    if not prompt:\n",
    "        continue\n",
    "\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    with torch.no_grad():\n",
    "        logits = model(transform(image).unsqueeze(0).to(device))[0]\n",
    "\n",
    "    # Softmax topâ€‘10 logits\n",
    "    top_logits = get_topk(logits, k=10)\n",
    "\n",
    "    # Raw Logits of 6 target classes\n",
    "    selected_logits = get_class_logits(logits, target_ids.keys())\n",
    "\n",
    "    results.append({\n",
    "        \"file_name\": str(img_path),\n",
    "        \"prompt\": prompt,\n",
    "        \"top_logits\": top_logits,\n",
    "        \"class_logits\": selected_logits\n",
    "    })\n",
    "\n",
    "    # aggregate per class (for the dedicated report)\n",
    "    for cls_id, val in selected_logits.items():\n",
    "        per_class_logit[cls_id].append({\n",
    "            \"file_name\": str(img_path),\n",
    "            \"prompt\": prompt,\n",
    "            \"logit\": val\n",
    "        })\n",
    "\n",
    "\n",
    "# Percorso del file in cui salvare i risultati\n",
    "LOGIT_RESULTS = Path(os.getenv(\"OUTPUT_DIR\", \"analysis_out\")) / \"logits.json\"\n",
    "\n",
    "# Salva i risultati in JSON\n",
    "with open(LOGIT_RESULTS, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nðŸ’¾ Risultati salvati in: {LOGIT_RESULTS}\")\n",
    "# Debug/preview\n",
    "print(\"\\nâœ… Esempi di topâ€‘10 logits:\")\n",
    "for r in results[:10]:\n",
    "    print(f\"\\nðŸ“Œ {r['file_name']}\")\n",
    "    print(f\"Prompt: {r['prompt']}\")\n",
    "    print(\"Topâ€‘10 logits (softmax):\")\n",
    "    for i, (label, p) in r[\"top_logits\"]:\n",
    "        print(f\"  - {i}: {label} ({p:.3f})\")\n",
    "    print(\"Logits classi target:\")\n",
    "    for i, val in r[\"class_logits\"].items():\n",
    "        print(f\"  - {i}: {idx2label[i]} = {val:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d479795",
   "metadata": {},
   "source": [
    "### LLM Coherence Audit \n",
    "\n",
    "This script audits the coherence between a prompt and a vision model's top-10 predictions using an LLM.\n",
    "\n",
    "- **`query_llm()`** sends the prompt and logits to an OpenAI model, which returns a JSON with a coherence `score`, a short `explanation`, and optional `confidence`.\n",
    "- A prediction is considered coherent if the score â‰¥ `COHERENCE_THRESHOLD` (default: 0.3).\n",
    "- Results are saved to `.jsonl` and `.txt` files.\n",
    "- The final report includes total examples, coherence rate, and breakdowns by object and context.\n",
    "\n",
    "This allows for automated semantic auditing of vision-language model outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fc0a408d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COHERENCE_THRESHOLD: 0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM analysis: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121/121 [03:09<00:00,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== SUMMARY ==========\n",
      "Total images:   121\n",
      "Incoherent (<0.3): 59  (48.8 %)\n",
      "\n",
      "-- Incoherence by *object* --\n",
      "  bookjacket                         : 12/15  (80.0 %)\n",
      "  ceramiccoffeemug                   : 5/16  (31.2 %)\n",
      "  grannysmith                        : 11/15  (73.3 %)\n",
      "  notebookwithkraftcover             : 9/15  (60.0 %)\n",
      "  opaquemetalwaterbottle             : 8/20  (40.0 %)\n",
      "  softcouchpillow                    : 11/20  (55.0 %)\n",
      "  tablelampwithshadeoff              : 3/20  (15.0 %)\n",
      "\n",
      "-- Incoherence by *context* --\n",
      "  bathroom                           : 4/8  (50.0 %)\n",
      "  classroom                          : 7/12  (58.3 %)\n",
      "  garage                             : 9/10  (90.0 %)\n",
      "  green                              : 4/12  (33.3 %)\n",
      "  hotel                              : 7/14  (50.0 %)\n",
      "  kitchen                            : 5/12  (41.7 %)\n",
      "  minimalist                         : 5/14  (35.7 %)\n",
      "  modern                             : 8/14  (57.1 %)\n",
      "  plain                              : 5/14  (35.7 %)\n",
      "  science                            : 5/11  (45.5 %)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import openai, json, re, os, sys\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "from typing import List, Optional\n",
    "import csv\n",
    "from pathlib import Path \n",
    "\n",
    "# OpenAI API configuration\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Parameters\n",
    "COHERENCE_THRESHOLD = float(os.getenv(\"COHERENCE_TH\", 0.3))\n",
    "META_CSV = Path(os.getenv(\"META_CSV\", \"dataset/dataset_metadata.csv\"))\n",
    "LOG_JSONL_PATH = Path(os.getenv(\"OUTPUT_DIR\", \"analysis_out\")) / \"llm_audit.jsonl\"\n",
    "LIVE_TXT_PATH = Path(os.getenv(\"OUTPUT_DIR\", \"analysis_out\")) / \"llm_live_output.txt\"\n",
    "LOGIT_RESULTS = Path(os.getenv(\"OUTPUT_DIR\", \"analysis_out\")) / \"logits.json\"\n",
    "\n",
    "print(f\"COHERENCE_THRESHOLD: {COHERENCE_THRESHOLD}\")\n",
    "\n",
    "# Load logits JSON file\n",
    "with open(LOGIT_RESULTS, \"r\", encoding=\"utf-8\") as f:\n",
    "    logits_data = json.load(f)\n",
    "\n",
    "# Normalize file names to match those in metadata CSV\n",
    "def normalize_filename(path: str) -> str:\n",
    "    return Path(path).name  # estrae solo \"bookjacket__classroom__001.png\"\n",
    "\n",
    "logits_lookup = {\n",
    "    normalize_filename(entry[\"file_name\"]): entry[\"top_logits\"]\n",
    "    for entry in logits_data\n",
    "}\n",
    "\n",
    "# Function to extract JSON from text\n",
    "def extract_json_from_text(text: str) -> dict:\n",
    "    m = re.search(r\"\\{.*?\\}\", text, re.DOTALL)\n",
    "    if not m:\n",
    "        raise ValueError(\"âš ï¸ No valid JSON found\")\n",
    "    return json.loads(m.group(0))\n",
    "\n",
    "# Function to query the LLM\n",
    "def query_llm(prompt: str, top_logits, vision_model: str) -> dict:\n",
    "    def safe_label_prob(item):\n",
    "        try:\n",
    "            label = str(item[0])\n",
    "            prob_raw = item[1]\n",
    "            prob = float(prob_raw[0]) if isinstance(prob_raw, (tuple, list)) else float(prob_raw)\n",
    "            return f\"{label} ({prob:.3f})\"\n",
    "        except Exception:\n",
    "            return f\"[MALFORMED: {item}]\"\n",
    "\n",
    "    top_str = \"; \".join([safe_label_prob(it) for it in top_logits])\n",
    "\n",
    "    user_msg = f\"\"\"\n",
    "You are auditing the output of **{vision_model}** to assess alignment with the prompt.\n",
    "\n",
    "Prompt:\n",
    "\\\"{prompt}\\\"\n",
    "\n",
    "Top-10 predictions with probabilities:\n",
    "{top_str}\n",
    "\n",
    "Return JSON only:\n",
    "{{\n",
    "  \"score\": <float 0-1>,\n",
    "  \"explanation\": <â‰¤25 words>,\n",
    "  \"confidence\": <float 0-1 (optional)>\n",
    "}}\n",
    "Be lenient; score â‰¥ 0.3 is considered coherent.\n",
    "\"\"\"\n",
    "\n",
    "    res = openai.chat.completions.create(\n",
    "        model=os.getenv(\"LLM_MODEL\", \"gpt-4o-mini\"),\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Return strict JSON only.\"},\n",
    "            {\"role\": \"user\", \"content\": user_msg}\n",
    "        ],\n",
    "        temperature=0.0\n",
    "    )\n",
    "    return extract_json_from_text(res.choices[0].message.content.strip())\n",
    "\n",
    "# Load dataset_metadata.csv\n",
    "metadata = []\n",
    "with open(META_CSV, newline='', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        metadata.append(row)\n",
    "\n",
    "# Variables for counting\n",
    "tot = tot_incoh = 0\n",
    "per_obj_tot = Counter()\n",
    "per_obj_incoh = Counter()\n",
    "per_ctx_tot = Counter()\n",
    "per_ctx_incoh = Counter()\n",
    "incoherent_cases = []\n",
    "\n",
    "# Main loop\n",
    "with open(LOG_JSONL_PATH, \"w\") as fout, open(LIVE_TXT_PATH, \"w\") as live:\n",
    "    for row in tqdm(metadata, desc=\"LLM analysis\"):\n",
    "        tot += 1\n",
    "        prompt = row[\"prompt\"]\n",
    "        obj = row[\"object\"]\n",
    "        ctx = row[\"background\"]\n",
    "\n",
    "        file_key = Path(row[\"file_name\"]).name\n",
    "        top_logits = logits_lookup.get(file_key, [])\n",
    "\n",
    "        per_obj_tot[obj] += 1\n",
    "        per_ctx_tot[ctx] += 1\n",
    "\n",
    "        # Query LLM\n",
    "        llm_out = query_llm(prompt, top_logits, os.getenv(\"VISION_MODEL\", \"alexnet\"))\n",
    "        record = {\n",
    "            **row,\n",
    "            **llm_out,\n",
    "            \"subject\": obj,\n",
    "            \"background\": ctx,\n",
    "            \"top_logits\": top_logits \n",
    "        }\n",
    "\n",
    "        fout.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "        live.write(json.dumps({\n",
    "            \"id\": tot,\n",
    "            \"score\": llm_out.get(\"score\"),\n",
    "            \"explanation\": llm_out.get(\"explanation\")\n",
    "        }, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "        if llm_out.get(\"score\", 0.0) < COHERENCE_THRESHOLD:\n",
    "            incoherent_cases.append(record)\n",
    "            tot_incoh += 1\n",
    "            per_obj_incoh[obj] += 1\n",
    "            per_ctx_incoh[ctx] += 1\n",
    "\n",
    "# Final report\n",
    "print(\"\\n========== SUMMARY ==========\")\n",
    "pct = 100 * tot_incoh / tot if tot else 0\n",
    "print(f\"Total images:   {tot}\")\n",
    "print(f\"Incoherent (<{COHERENCE_THRESHOLD}): {tot_incoh}  ({pct:.1f} %)\")\n",
    "\n",
    "print(\"\\n-- Incoherence by *object* --\")\n",
    "for o in sorted(per_obj_tot):\n",
    "    pct = 100 * per_obj_incoh[o] / per_obj_tot[o] if per_obj_tot[o] else 0\n",
    "    print(f\"  {o:35s}: {per_obj_incoh[o]}/{per_obj_tot[o]}  ({pct:.1f} %)\")\n",
    "\n",
    "print(\"\\n-- Incoherence by *context* --\")\n",
    "for c in sorted(per_ctx_tot):\n",
    "    pct = 100 * per_ctx_incoh[c] / per_ctx_tot[c] if per_ctx_tot[c] else 0\n",
    "    print(f\"  {c:35s}: {per_ctx_incoh[c]}/{per_ctx_tot[c]}  ({pct:.1f} %)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaae9b7a",
   "metadata": {},
   "source": [
    "### Bias Report & Model Verdict (Uses Pre-computed Metrics)\n",
    "\n",
    "This cell generates a bias analysis and verdict for the vision model based on previously computed LLM coherence scores and raw logits.\n",
    "\n",
    "- Loads all results from the audit (`llm_audit.jsonl`) and filters incoherent cases (`score` < threshold).\n",
    "- Computes global statistics: total images, mean/median/stdev scores, incoherence rates by object and context.\n",
    "- Analyzes raw logits per target class: average activations, top-5 examples.\n",
    "- Constructs a structured prompt for the LLM including:\n",
    "  - (A) global metrics\n",
    "  - (B) incoherent examples\n",
    "  - (C) target class activation stats\n",
    "- The LLM returns a detailed Markdown report with six required sections, including bias patterns and an overall model verdict.\n",
    "- Final report is saved as `report.md`.\n",
    "\n",
    "This step automates bias evaluation and model reliability assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1d1a650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Target Class Analysis (Raw Logits)\n",
      "\n",
      "### Class `pillow` (ImageNet #721)\n",
      "- Average logit: 3.35 (std: 3.70)\n",
      "- Topâ€‘5 activations:\n",
      "  - `dataset/images/softcouchpillow__modern__001.png` â†’ logit=14.17\n",
      "  - `dataset/images/softcouchpillow__green__002.png` â†’ logit=13.05\n",
      "  - `dataset/images/softcouchpillow__kitchen__002.png` â†’ logit=12.28\n",
      "  - `dataset/images/softcouchpillow__modern__002.png` â†’ logit=11.82\n",
      "  - `dataset/images/softcouchpillow__green__001.png` â†’ logit=11.74\n",
      "\n",
      "### Class `toilet seat` (ImageNet #861)\n",
      "- Average logit: 4.16 (std: 2.71)\n",
      "- Topâ€‘5 activations:\n",
      "  - `dataset/images/softcouchpillow__minimalist__001.png` â†’ logit=12.37\n",
      "  - `dataset/images/ceramiccoffeemug__bathroom__001.png` â†’ logit=10.20\n",
      "  - `dataset/images/ceramiccoffeemug__hotel__001.png` â†’ logit=9.65\n",
      "  - `dataset/images/softcouchpillow__classroom__001.png` â†’ logit=9.57\n",
      "  - `dataset/images/tablelampwithshadeoff__bathroom__002.png` â†’ logit=8.97\n",
      "\n",
      "### Class `park bench` (ImageNet #703)\n",
      "- Average logit: 0.28 (std: 2.10)\n",
      "- Topâ€‘5 activations:\n",
      "  - `dataset/images/tablelampwithshadeoff__classroom__002.png` â†’ logit=9.02\n",
      "  - `dataset/images/grannysmith__minimalist__002.png` â†’ logit=5.27\n",
      "  - `dataset/images/tablelampwithshadeoff__green__001.png` â†’ logit=5.06\n",
      "  - `dataset/images/ceramiccoffeemug__modern__002.png` â†’ logit=4.34\n",
      "  - `dataset/images/bookjacket__green__002.png` â†’ logit=3.79\n",
      "\n",
      "### Class `laptop` (ImageNet #620)\n",
      "- Average logit: 5.29 (std: 2.96)\n",
      "- Topâ€‘5 activations:\n",
      "  - `dataset/images/bookjacket__green__001.png` â†’ logit=15.80\n",
      "  - `dataset/images/notebookwithkraftcover__science__001.png` â†’ logit=13.48\n",
      "  - `dataset/images/bookjacket__green__002.png` â†’ logit=13.10\n",
      "  - `dataset/images/notebookwithkraftcover__minimalist__002.png` â†’ logit=12.49\n",
      "  - `dataset/images/bookjacket__classroom__002.png` â†’ logit=11.38\n",
      "\n",
      "### Class `fox squirrel` (ImageNet #335)\n",
      "- Average logit: -3.04 (std: 1.80)\n",
      "- Topâ€‘5 activations:\n",
      "  - `dataset/images/grannysmith__minimalist__002.png` â†’ logit=1.41\n",
      "  - `dataset/images/tablelampwithshadeoff__green__002.png` â†’ logit=1.40\n",
      "  - `dataset/images/grannysmith__green__002.png` â†’ logit=1.39\n",
      "  - `dataset/images/opaquemetalwaterbottle__green__002.png` â†’ logit=0.63\n",
      "  - `dataset/images/ceramiccoffeemug__modern__002.png` â†’ logit=0.34\n",
      "\n",
      "### Class `tennis ball` (ImageNet #852)\n",
      "- Average logit: 3.44 (std: 3.08)\n",
      "- Topâ€‘5 activations:\n",
      "  - `dataset/images/grannysmith__plain__002.png` â†’ logit=17.15\n",
      "  - `dataset/images/grannysmith__classroom__001.png` â†’ logit=12.90\n",
      "  - `dataset/images/grannysmith__plain__001.png` â†’ logit=11.18\n",
      "  - `dataset/images/grannysmith__minimalist__001.png` â†’ logit=9.71\n",
      "  - `dataset/images/grannysmith__hotel__001.png` â†’ logit=9.10\n",
      "\n",
      "âœ… Report saved to: analysis_alexnet_1/report.md\n"
     ]
    }
   ],
   "source": [
    "import json, openai, statistics, os\n",
    "from pathlib import Path\n",
    "from statistics import mean, stdev\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# â”€â”€ load all the records from previous cell â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "with open(LOG_JSONL_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    records = [json.loads(l) for l in f]\n",
    "\n",
    "# Limit top_logits to 5 for each record\n",
    "for rec in records:\n",
    "    rec[\"top_logits\"] = rec.get(\"top_logits\", [])[:5]\n",
    "\n",
    "# List of incoherent records (those with score < COHERENCE_THRESHOLD)\n",
    "incoherent_recs = [\n",
    "    {k: rec[k] for k in (\"file_name\", \"prompt\", \"top_logits\", \"score\", \"explanation\")}\n",
    "    for rec in records if rec.get(\"score\", 0) < COHERENCE_THRESHOLD\n",
    "]\n",
    "\n",
    "# â”€â”€ global metrics already computed in previous cell â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "scores = [rec.get(\"score\", 0.0) for rec in records]\n",
    "metrics_summary = {\n",
    "    \"total_images\": tot,\n",
    "    \"mean_score\": statistics.mean(scores) if scores else 0.0,\n",
    "    \"median_score\": statistics.median(scores) if scores else 0.0,\n",
    "    \"stdev_score\": statistics.pstdev(scores) if len(scores) > 1 else 0.0,\n",
    "    \"percent_incoherent\": 100 * tot_incoh / tot if tot else 0.0,\n",
    "    \"object_stats\": {\n",
    "        obj: {\n",
    "            \"total\": per_obj_tot[obj],\n",
    "            \"incoherent\": per_obj_incoh[obj],\n",
    "            \"percent_incoherent\": 100 * per_obj_incoh[obj] / per_obj_tot[obj]\n",
    "            if per_obj_tot[obj] else 0.0\n",
    "        }\n",
    "        for obj in per_obj_tot\n",
    "    },\n",
    "    \"context_stats\": {\n",
    "        ctx: {\n",
    "            \"total\": per_ctx_tot[ctx],\n",
    "            \"incoherent\": per_ctx_incoh[ctx],\n",
    "            \"percent_incoherent\": 100 * per_ctx_incoh[ctx] / per_ctx_tot[ctx]\n",
    "            if per_ctx_tot[ctx] else 0.0\n",
    "        }\n",
    "        for ctx in per_ctx_tot\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save metrics to file (may be useful)\n",
    "Path(OUTPUT_DIR /  \"metrics.json\").write_text(json.dumps(metrics_summary, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "logit_report_section = \"\\n## Target Class Analysis (Raw Logits)\\n\"\n",
    "for cls_id, cls_name in target_ids.items():\n",
    "    values = [x[\"logit\"] for x in per_class_logit[cls_id]]\n",
    "    if not values:\n",
    "        continue\n",
    "\n",
    "    logit_report_section += f\"\\n### Class `{cls_name}` (ImageNet #{cls_id})\\n\"\n",
    "    logit_report_section += f\"- Average logit: {mean(values):.2f} (std: {stdev(values):.2f})\\n\"\n",
    "    logit_report_section += \"- Topâ€‘5 activations:\\n\"\n",
    "    top5 = sorted(per_class_logit[cls_id], key=lambda x: -x[\"logit\"])[:5]\n",
    "    for e in top5:\n",
    "       logit_report_section += f\"  - `{e['file_name']}` â†’ logit={e['logit']:.2f}\\n\"\n",
    "\n",
    "print(logit_report_section)\n",
    "\n",
    "# â”€â”€ Prompt for LLM â”€â”€â”€â”€â”€â”€\n",
    "prompt_header = f\"\"\"\n",
    "You are an AI-bias auditor.  \n",
    "Below you will find **(A) pre-computed global metrics**, **(B) per-image data**, and **(C) target class logit analysis**.\n",
    "\n",
    "Use the provided metrics; do NOT recalsculate means or percentages yourself.\n",
    "Respond in **Markdown** with the requested sections.\n",
    "\n",
    "## Required sections\n",
    "### 1 Aggregate statistics\n",
    "Summarise the numbers from (A).\n",
    "\n",
    "### 2 Recurring error patterns\n",
    "Identify frequent error types and link them to biases in **{VISION_MODEL}**.\n",
    "\n",
    "### 3 Detailed list of incoherent images\n",
    "For every image in (B) (score < {COHERENCE_THRESHOLD}) list:\n",
    "â€¢ file_name  â€¢ â‰¤15-word prompt summary  â€¢ three worst labels  â€¢ explanation (â‰¤2 sentences).\n",
    "\n",
    "### 4 Target class logit analysis (Full Details)\n",
    "Include the full details of the target class analysis from (C).\n",
    "\n",
    "### 5 Main biases of the model\n",
    "At least three systematic biases, with examples.\n",
    "\n",
    "### 6 Overall verdict\n",
    "Bullet strengths/weaknesses of **{VISION_MODEL}** + final reliability rating 1â€“5 (no mitigation advice).\n",
    "\n",
    "Respond **only** in Markdown, start each major section with '##'.\n",
    "\"\"\"\n",
    "\n",
    "payload = (\n",
    "    prompt_header\n",
    "    + \"\\n\\n### (A) Global metrics\\n```json\\n\"\n",
    "    + json.dumps(metrics_summary, ensure_ascii=False, indent=2)\n",
    "    + \"\\n```\\n\\n### (B) Incoherent images\\n```json\\n\"\n",
    "    + json.dumps(incoherent_recs, ensure_ascii=False)\n",
    "    + \"\\n```\\n\\n### (C) Target class logit analysis (Full Details)\\n\"\n",
    "    + logit_report_section\n",
    ")\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=LLM_MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": \"You are a senior AI-bias analyst who MUST reply in Markdown headings.\"},\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": payload}\n",
    "    ],\n",
    "    temperature=0.25\n",
    ")\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "report_path = OUTPUT_DIR / \"report.md\"\n",
    "report_path.write_text(response.choices[0].message.content, encoding=\"utf-8\")\n",
    "print(\"âœ… Report saved to:\", report_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81372111",
   "metadata": {},
   "source": [
    "ðŸ“º Visualizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cfa58426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report salvato in: analysis_alexnet_1/report.md\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## 1 Aggregate statistics\n",
       "- **Total Images**: 121\n",
       "- **Mean Score**: 0.31\n",
       "- **Median Score**: 0.33\n",
       "- **Standard Deviation of Score**: 0.21\n",
       "- **Percentage of Incoherent Images**: 48.76%\n",
       "- **Object Incoherence**:\n",
       "  - Bookjacket: 80%\n",
       "  - Ceramic Coffee Mug: 31.25%\n",
       "  - Granny Smith: 73.33%\n",
       "  - Notebook with Kraft Cover: 60%\n",
       "  - Opaque Metal Water Bottle: 40%\n",
       "  - Soft Couch Pillow: 55%\n",
       "  - Table Lamp with Shade Off: 15%\n",
       "- **Context Incoherence**:\n",
       "  - Classroom: 58.33%\n",
       "  - Garage: 90%\n",
       "  - Green: 33.33%\n",
       "  - Hotel: 50%\n",
       "  - Kitchen: 41.67%\n",
       "  - Minimalist: 35.71%\n",
       "  - Modern: 57.14%\n",
       "  - Plain: 35.71%\n",
       "  - Science: 45.45%\n",
       "  - Bathroom: 50%\n",
       "\n",
       "## 2 Recurring error patterns\n",
       "- **Misalignment with Prompts**: Many images scored below 0.3 show predictions that do not correlate with the provided prompts, indicating a lack of contextual understanding.\n",
       "- **Object Confusion**: The model often confuses similar objects, such as mistaking a bookjacket for unrelated items like a laptop or envelope.\n",
       "- **Contextual Misinterpretation**: The model struggles to relate objects to their specified contexts (e.g., a bookjacket in a classroom), leading to incoherent predictions.\n",
       "\n",
       "## 3 Detailed list of incoherent images\n",
       "1. **File Name**: images/bookjacket__classroom__001.png  \n",
       "   **Prompt Summary**: A neutral bookjacket in a classroom background  \n",
       "   **Three Worst Labels**: envelope, paintbrush, iPod  \n",
       "   **Explanation**: Predictions do not align with the prompt; items are unrelated to a bookjacket or classroom.\n",
       "\n",
       "2. **File Name**: images/bookjacket__classroom__002.png  \n",
       "   **Prompt Summary**: A neutral bookjacket in a classroom background  \n",
       "   **Three Worst Labels**: wooden spoon, iPod, marimba  \n",
       "   **Explanation**: Predictions do not align with the prompt about a bookjacket in a classroom.\n",
       "\n",
       "3. **File Name**: images/bookjacket__garage__002.png  \n",
       "   **Prompt Summary**: A neutral bookjacket in a garage background  \n",
       "   **Three Worst Labels**: fountain pen, revolver, radio  \n",
       "   **Explanation**: Predictions are unrelated to a bookjacket or garage context.\n",
       "\n",
       "4. **File Name**: images/bookjacket__green__002.png  \n",
       "   **Prompt Summary**: A neutral bookjacket in a green background  \n",
       "   **Three Worst Labels**: envelope, laptop, binder  \n",
       "   **Explanation**: Predictions do not align with the prompt about a bookjacket.\n",
       "\n",
       "5. **File Name**: images/bookjacket__hotel__001.png  \n",
       "   **Prompt Summary**: A neutral bookjacket in a hotel background  \n",
       "   **Three Worst Labels**: table lamp, studio couch, lampshade  \n",
       "   **Explanation**: Predictions focus on furniture and electronics, not a bookjacket or hotel context.\n",
       "\n",
       "6. **File Name**: images/bookjacket__hotel__002.png  \n",
       "   **Prompt Summary**: A neutral bookjacket in a hotel background  \n",
       "   **Three Worst Labels**: binder, shoji, quill  \n",
       "   **Explanation**: Predictions do not align with the prompt about a bookjacket in a hotel background.\n",
       "\n",
       "7. **File Name**: images/bookjacket__minimalist__002.png  \n",
       "   **Prompt Summary**: A neutral bookjacket in a minimalist background  \n",
       "   **Three Worst Labels**: dishwasher, refrigerator, paper towel  \n",
       "   **Explanation**: Predictions are unrelated to a bookjacket or minimalist background.\n",
       "\n",
       "8. **File Name**: images/bookjacket__modern__001.png  \n",
       "   **Prompt Summary**: A neutral bookjacket in a modern background  \n",
       "   **Three Worst Labels**: lighter, binder, medicine chest  \n",
       "   **Explanation**: Predictions do not align with the concept of a bookjacket or modern background.\n",
       "\n",
       "9. **File Name**: images/bookjacket__modern__002.png  \n",
       "   **Prompt Summary**: A neutral bookjacket in a modern background  \n",
       "   **Three Worst Labels**: fountain pen, binder, violin  \n",
       "   **Explanation**: Predictions do not align with the prompt about a bookjacket.\n",
       "\n",
       "10. **File Name**: images/bookjacket__plain__001.png  \n",
       "    **Prompt Summary**: A neutral bookjacket in a plain background  \n",
       "    **Three Worst Labels**: switch, iPod, loudspeaker  \n",
       "    **Explanation**: Predictions do not align with the concept of a neutral bookjacket.\n",
       "\n",
       "11. **File Name**: images/bookjacket__plain__002.png  \n",
       "    **Prompt Summary**: A neutral bookjacket in a plain background  \n",
       "    **Three Worst Labels**: lampshade, table lamp, ping-pong ball  \n",
       "    **Explanation**: Predictions are unrelated to a bookjacket or plain background.\n",
       "\n",
       "12. **File Name**: images/bookjacket__science__001.png  \n",
       "    **Prompt Summary**: A neutral bookjacket in a science background  \n",
       "    **Three Worst Labels**: cleaver, letter opener, envelope  \n",
       "    **Explanation**: Predictions do not align with the prompt about a bookjacket in a science background.\n",
       "\n",
       "13. **File Name**: images/ceramiccoffeemug__bathroom__001.png  \n",
       "    **Prompt Summary**: A neutral ceramiccoffeemug in a bathroom background  \n",
       "    **Three Worst Labels**: soap dispenser, washbasin, tub  \n",
       "    **Explanation**: Predictions focus on bathroom items, lacking relevance to a coffee mug.\n",
       "\n",
       "14. **File Name**: images/ceramiccoffeemug__garage__001.png  \n",
       "    **Prompt Summary**: A neutral ceramiccoffeemug in a garage background  \n",
       "    **Three Worst Labels**: hammer, screwdriver, pillow  \n",
       "    **Explanation**: Predictions do not align with the prompt; items are unrelated to a coffee mug or garage.\n",
       "\n",
       "15. **File Name**: images/ceramiccoffeemug__kitchen__001.png  \n",
       "    **Prompt Summary**: A neutral ceramiccoffeemug in a kitchen background  \n",
       "    **Three Worst Labels**: medicine chest, espresso maker, lotion  \n",
       "    **Explanation**: Predictions mostly include kitchen items but lack a clear match to a neutral ceramic coffee mug.\n",
       "\n",
       "16. **File Name**: images/ceramiccoffeemug__minimalist__001.png  \n",
       "    **Prompt Summary**: A neutral ceramiccoffeemug in a minimalist background  \n",
       "    **Three Worst Labels**: television, iPod, home theater  \n",
       "    **Explanation**: Predictions are unrelated to the prompt about a coffee mug.\n",
       "\n",
       "17. **File Name**: images/ceramiccoffeemug__modern__002.png  \n",
       "    **Prompt Summary**: A neutral ceramiccoffeemug in a modern background  \n",
       "    **Three Worst Labels**: loudspeaker, Polaroid camera, CD player  \n",
       "    **Explanation**: Predictions do not align with the prompt about a coffee mug.\n",
       "\n",
       "18. **File Name**: images/grannysmith__bathroom__002.png  \n",
       "    **Prompt Summary**: A neutral grannysmith in a bathroom background  \n",
       "    **Three Worst Labels**: washbasin, bathtub, tub  \n",
       "    **Explanation**: Predictions focus on bathroom objects, not a Granny Smith apple.\n",
       "\n",
       "19. **File Name**: images/grannysmith__classroom__001.png  \n",
       "    **Prompt Summary**: A neutral grannysmith in a classroom background  \n",
       "    **Three Worst Labels**: ping-pong ball, pool table, tennis ball  \n",
       "    **Explanation**: Predictions are unrelated to a Granny Smith or classroom context.\n",
       "\n",
       "20. **File Name**: images/grannysmith__classroom__002.png  \n",
       "    **Prompt Summary**: A neutral grannysmith in a classroom background  \n",
       "    **Three Worst Labels**: ping-pong ball, computer keyboard, croquet ball  \n",
       "    **Explanation**: Predictions do not align with the prompt; no mention of a grannysmith or classroom.\n",
       "\n",
       "21. **File Name**: images/grannysmith__garage__001.png  \n",
       "    **Prompt Summary**: A neutral grannysmith in a garage background  \n",
       "    **Three Worst Labels**: hammer, croquet ball, paintbrush  \n",
       "    **Explanation**: Predictions do not align with the prompt; no mention of a grannysmith or garage.\n",
       "\n",
       "22. **File Name**: images/grannysmith__green__002.png  \n",
       "    **Prompt Summary**: A neutral grannysmith in a green background  \n",
       "    **Three Worst Labels**: croquet ball, golf ball, baseball  \n",
       "    **Explanation**: Predictions are unrelated to a Granny Smith apple or green background.\n",
       "\n",
       "23. **File Name**: images/grannysmith__hotel__001.png  \n",
       "    **Prompt Summary**: A neutral grannysmith in a hotel background  \n",
       "    **Three Worst Labels**: hip, rubber eraser, pomegranate  \n",
       "    **Explanation**: Predictions do not align with the prompt; no relevant items identified.\n",
       "\n",
       "24. **File Name**: images/grannysmith__kitchen__002.png  \n",
       "    **Prompt Summary**: A neutral grannysmith in a kitchen background  \n",
       "    **Three Worst Labels**: pomegranate, croquet ball, maraca  \n",
       "    **Explanation**: Predictions do not align with the prompt; no relevant kitchen or Granny Smith apple identified.\n",
       "\n",
       "25. **File Name**: images/grannysmith__minimalist__002.png  \n",
       "    **Prompt Summary**: A neutral grannysmith in a minimalist background  \n",
       "    **Three Worst Labels**: desk, home theater, television  \n",
       "    **Explanation**: Predictions do not relate to a neutral grannysmith or minimalist background.\n",
       "\n",
       "26. **File Name**: images/grannysmith__modern__001.png  \n",
       "    **Prompt Summary**: A neutral grannysmith in a modern background  \n",
       "    **Three Worst Labels**: hook, table lamp, lampshade  \n",
       "    **Explanation**: Predictions do not relate to a Granny Smith apple or modern background.\n",
       "\n",
       "27. **File Name**: images/grannysmith__modern__002.png  \n",
       "    **Prompt Summary**: A neutral grannysmith in a modern background  \n",
       "    **Three Worst Labels**: ping-pong ball, puck, wall clock  \n",
       "    **Explanation**: Predictions are unrelated to a Granny Smith apple or modern background.\n",
       "\n",
       "28. **File Name**: images/grannysmith__science__002.png  \n",
       "    **Prompt Summary**: A neutral grannysmith in a science background  \n",
       "    **Three Worst Labels**: computer keyboard, scoreboard, ping-pong ball  \n",
       "    **Explanation**: Predictions are unrelated to the prompt about a neutral grannysmith in a science background.\n",
       "\n",
       "29. **File Name**: images/notebookwithkraftcover__garage__001.png  \n",
       "    **Prompt Summary**: A neutral notebookwithkraftcover in a garage background  \n",
       "    **Three Worst Labels**: hammer, carpenter's kit, pencil sharpener  \n",
       "    **Explanation**: Predictions do not align with the prompt about a notebook in a garage.\n",
       "\n",
       "30. **File Name**: images/notebookwithkraftcover__green__001.png  \n",
       "    **Prompt Summary**: A neutral notebookwithkraftcover in a green background  \n",
       "    **Three Worst Labels**: binder, lighter, book jacket  \n",
       "    **Explanation**: Predictions do not align with the prompt; items are unrelated to a notebook.\n",
       "\n",
       "31. **File Name**: images/notebookwithkraftcover__green__002.png  \n",
       "    **Prompt Summary**: A neutral notebookwithkraftcover in a green background  \n",
       "    **Three Worst Labels**: hatchet, hard disc, necklace  \n",
       "    **Explanation**: Predictions do not relate to a notebook or kraft cover.\n",
       "\n",
       "32. **File Name**: images/notebookwithkraftcover__hotel__002.png  \n",
       "    **Prompt Summary**: A neutral notebookwithkraftcover in a hotel background  \n",
       "    **Three Worst Labels**: loudspeaker, home theater, cleaver  \n",
       "    **Explanation**: Predictions do not align with the prompt; items are unrelated to a notebook or hotel setting.\n",
       "\n",
       "33. **File Name**: images/notebookwithkraftcover__kitchen__002.png  \n",
       "    **Prompt Summary**: A neutral notebookwithkraftcover in a kitchen background  \n",
       "    **Three Worst Labels**: television, screen, monitor  \n",
       "    **Explanation**: Predictions are unrelated to the prompt about a notebook in a kitchen.\n",
       "\n",
       "34. **File Name**: images/notebookwithkraftcover__modern__001.png  \n",
       "    **Prompt Summary**: A neutral notebookwithkraftcover in a modern background  \n",
       "    **Three Worst Labels**: binder, rule, cleaver  \n",
       "    **Explanation**: Predictions do not align with the prompt about a notebook.\n",
       "\n",
       "35. **File Name**: images/notebookwithkraftcover__modern__002.png  \n",
       "    **Prompt Summary**: A neutral notebookwithkraftcover in a modern background  \n",
       "    **Three Worst Labels**: hatchet, paintbrush, spatula  \n",
       "    **Explanation**: Predictions do not align with the prompt about a notebook.\n",
       "\n",
       "36. **File Name**: images/notebookwithkraftcover__plain__001.png  \n",
       "    **Prompt Summary**: A neutral notebookwithkraftcover in a plain background  \n",
       "    **Three Worst Labels**: binder, modem, envelope  \n",
       "    **Explanation**: Predictions do not align with the prompt describing a notebook.\n",
       "\n",
       "37. **File Name**: images/notebookwithkraftcover__science__002.png  \n",
       "    **Prompt Summary**: A neutral notebookwithkraftcover in a science background  \n",
       "    **Three Worst Labels**: binder, ballpoint, rule  \n",
       "    **Explanation**: Predictions do not align with the prompt about a notebook in a science background.\n",
       "\n",
       "38. **File Name**: images/opaquemetalwaterbottle__bathroom__001.png  \n",
       "    **Prompt Summary**: A neutral opaquemetalwaterbottle in a bathroom background  \n",
       "    **Three Worst Labels**: soap dispenser, washbasin, tub  \n",
       "    **Explanation**: Predictions do not align with the prompt; items are unrelated to a water bottle.\n",
       "\n",
       "39. **File Name**: images/opaquemetalwaterbottle__bathroom__002.png  \n",
       "    **Prompt Summary**: A neutral opaquemetalwaterbottle in a bathroom background  \n",
       "    **Three Worst Labels**: soap dispenser, combination lock, corkscrew  \n",
       "    **Explanation**: Predictions do not align with the prompt; items are unrelated to a water bottle.\n",
       "\n",
       "40. **File Name**: images/opaquemetalwaterbottle__garage__001.png  \n",
       "    **Prompt Summary**: A neutral opaquemetalwaterbottle in a garage background  \n",
       "    **Three Worst Labels**: carpenter's kit, screwdriver, pencil box  \n",
       "    **Explanation**: Predictions do not align with the prompt; items are unrelated to a water bottle or garage.\n",
       "\n",
       "41. **File Name**: images/opaquemetalwaterbottle__garage__002.png  \n",
       "    **Prompt Summary**: A neutral opaquemetalwaterbottle in a garage background  \n",
       "    **Three Worst Labels**: cocktail shaker, hourglass, saltshaker  \n",
       "    **Explanation**: Predictions do not align with the prompt; items are unrelated to a water bottle.\n",
       "\n",
       "42. **File Name**: images/opaquemetalwaterbottle__hotel__002.png  \n",
       "    **Prompt Summary**: A neutral opaquemetalwaterbottle in a hotel background  \n",
       "    **Three Worst Labels**: cocktail shaker, saltshaker, soap dispenser  \n",
       "    **Explanation**: Predictions do not align with the prompt; items are unrelated to a neutral opaque metal water bottle.\n",
       "\n",
       "43. **File Name**: images/opaquemetalwaterbottle__kitchen__002.png  \n",
       "    **Prompt Summary**: A neutral opaquemetalwaterbottle in a kitchen background  \n",
       "    **Three Worst Labels**: soap dispenser, coffeepot, perfume  \n",
       "    **Explanation**: Predictions do not align with the prompt; items are unrelated to a metal water bottle.\n",
       "\n",
       "44. **File Name**: images/opaquemetalwaterbottle__modern__002.png  \n",
       "    **Prompt Summary**: A neutral opaquemetalwaterbottle in a modern background  \n",
       "    **Three Worst Labels**: monitor, notebook, table lamp  \n",
       "    **Explanation**: Predictions do not align with the prompt; items are unrelated to a water bottle.\n",
       "\n",
       "45. **File Name**: images/opaquemetalwaterbottle__science__001.png  \n",
       "    **Prompt Summary**: A neutral opaquemetalwaterbottle in a science background  \n",
       "    **Three Worst Labels**: fountain pen, stethoscope, sewing machine  \n",
       "    **Explanation**: Predictions do not align with the prompt; items are unrelated to a water bottle or science background.\n",
       "\n",
       "46. **File Name**: images/softcouchpillow__classroom__001.png  \n",
       "    **Prompt Summary**: A neutral softcouchpillow in a classroom background  \n",
       "    **Three Worst Labels**: mouse, studio couch, bathtub  \n",
       "    **Explanation**: Predictions do not align with the prompt; items are unrelated to a soft couch pillow in a classroom.\n",
       "\n",
       "47. **File Name**: images/softcouchpillow__classroom__002.png  \n",
       "    **Prompt Summary**: A neutral softcouchpillow in a classroom background  \n",
       "    **Three Worst Labels**: paper towel, studio couch, home theater  \n",
       "    **Explanation**: Predictions do not align with the prompt; items are unrelated to a neutral soft couch pillow in a classroom.\n",
       "\n",
       "48. **File Name**: images/softcouchpillow__garage__001.png  \n",
       "    **Prompt Summary**: A neutral softcouchpillow in a garage background  \n",
       "    **Three Worst Labels**: pillow, paper towel, brassiere  \n",
       "    **Explanation**: Predictions do not align with the prompt; only 'pillow' is relevant.\n",
       "\n",
       "49. **File Name**: images/softcouchpillow__hotel__001.png  \n",
       "    **Prompt Summary**: A neutral softcouchpillow in a hotel background  \n",
       "    **Three Worst Labels**: dough, butternut squash, wooden spoon  \n",
       "    **Explanation**: Predictions do not align with the prompt; items are unrelated to a soft couch pillow.\n",
       "\n",
       "50. **File Name**: images/softcouchpillow__hotel__002.png  \n",
       "    **Prompt Summary**: A neutral softcouchpillow in a hotel background  \n",
       "    **Three Worst Labels**: pillow, carton, toilet tissue  \n",
       "    **Explanation**: Predictions include 'pillow' but lack context of a hotel background.\n",
       "\n",
       "51. **File Name**: images/softcouchpillow__kitchen__001.png  \n",
       "    **Prompt Summary**: A neutral softcouchpillow in a kitchen background  \n",
       "    **Three Worst Labels**: coffee mug, cup, mortar  \n",
       "    **Explanation**: Predictions focus on kitchen items, not a soft couch pillow.\n",
       "\n",
       "52. **File Name**: images/softcouchpillow__minimalist__001.png  \n",
       "    **Prompt Summary**: A neutral softcouchpillow in a minimalist background  \n",
       "    **Three Worst Labels**: mortar, toilet seat, cup  \n",
       "    **Explanation**: Predictions do not align with the prompt; items are unrelated to a soft couch pillow.\n",
       "\n",
       "53. **File Name**: images/softcouchpillow__minimalist__002.png  \n",
       "    **Prompt Summary**: A neutral softcouchpillow in a minimalist background  \n",
       "    **Three Worst Labels**: studio couch, toilet tissue, bathtub  \n",
       "    **Explanation**: Predictions do not align with the prompt; items are unrelated to a soft couch pillow.\n",
       "\n",
       "54. **File Name**: images/softcouchpillow__plain__001.png  \n",
       "    **Prompt Summary**: A neutral softcouchpillow in a plain background  \n",
       "    **Three Worst Labels**: mortar, lampshade, cup  \n",
       "    **Explanation**: Predictions do not align with the prompt; items are unrelated to a soft couch pillow.\n",
       "\n",
       "55. **File Name**: images/softcouchpillow__plain__002.png  \n",
       "    **Prompt Summary**: A neutral softcouchpillow in a plain background  \n",
       "    **Three Worst Labels**: home theater, laptop, iPod  \n",
       "    **Explanation**: Predictions do not align with the prompt; items are unrelated to a soft couch pillow.\n",
       "\n",
       "56. **File Name**: images/softcouchpillow__science__001.png  \n",
       "    **Prompt Summary**: A neutral softcouchpillow in a science background  \n",
       "    **Three Worst Labels**: tub, studio couch, carton  \n",
       "    **Explanation**: Predictions do not align with the prompt; items are unrelated to a neutral soft couch pillow.\n",
       "\n",
       "57. **File Name**: images/tablelampwithshadeoff__classroom__002.png  \n",
       "    **Prompt Summary**: A neutral tablelampwithshadeoff in a classroom background  \n",
       "    **Three Worst Labels**: marimba, crib, prison  \n",
       "    **Explanation**: Predictions do not align with the prompt; none relate to a table lamp.\n",
       "\n",
       "58. **File Name**: images/tablelampwithshadeoff__garage__001.png  \n",
       "    **Prompt Summary**: A neutral tablelampwithshadeoff in a garage background  \n",
       "    **Three Worst Labels**: syringe, screwdriver, lipstick  \n",
       "    **Explanation**: Predictions do not align with the prompt; items are unrelated to a table lamp.\n",
       "\n",
       "59. **File Name**: images/tablelampwithshadeoff__garage__002.png  \n",
       "    **Prompt Summary**: A neutral tablelampwithshadeoff in a garage background  \n",
       "    **Three Worst Labels**: lens cap, digital clock, loudspeaker  \n",
       "    **Explanation**: Predictions do not align with the prompt; items are unrelated to a table lamp.\n",
       "\n",
       "## 4 Target class logit analysis (Full Details)\n",
       "### Class `pillow` (ImageNet #721)\n",
       "- **Average logit**: 3.35 (std: 3.70)\n",
       "- **Topâ€‘5 activations**:\n",
       "  - `dataset/images/softcouchpillow__modern__001.png` â†’ logit=14.17\n",
       "  - `dataset/images/softcouchpillow__green__002.png` â†’ logit=13.05\n",
       "  - `dataset/images/softcouchpillow__kitchen__002.png` â†’ logit=12.28\n",
       "  - `dataset/images/softcouchpillow__modern__002.png` â†’ logit=11.82\n",
       "  - `dataset/images/softcouchpillow__green__001.png` â†’ logit=11.74\n",
       "\n",
       "### Class `toilet seat` (ImageNet #861)\n",
       "- **Average logit**: 4.16 (std: 2.71)\n",
       "- **Topâ€‘5 activations**:\n",
       "  - `dataset/images/softcouchpillow__minimalist__001.png` â†’ logit=12.37\n",
       "  - `dataset/images/ceramiccoffeemug__bathroom__001.png` â†’ logit=10.20\n",
       "  - `dataset/images/ceramiccoffeemug__hotel__001.png` â†’ logit=9.65\n",
       "  - `dataset/images/softcouchpillow__classroom__001.png` â†’ logit=9.57\n",
       "  - `dataset/images/tablelampwithshadeoff__bathroom__002.png` â†’ logit=8.97\n",
       "\n",
       "### Class `park bench` (ImageNet #703)\n",
       "- **Average logit**: 0.28 (std: 2.10)\n",
       "- **Topâ€‘5 activations**:\n",
       "  - `dataset/images/tablelampwithshadeoff__classroom__002.png` â†’ logit=9.02\n",
       "  - `dataset/images/grannysmith__minimalist__002.png` â†’ logit=5.27\n",
       "  - `dataset/images/tablelampwithshadeoff__green__001.png` â†’ logit=5.06\n",
       "  - `dataset/images/ceramiccoffeemug__modern__002.png` â†’ logit=4.34\n",
       "  - `dataset/images/bookjacket__green__002.png` â†’ logit=3.79\n",
       "\n",
       "### Class `laptop` (ImageNet #620)\n",
       "- **Average logit**: 5.29 (std: 2.96)\n",
       "- **Topâ€‘5 activations**:\n",
       "  - `dataset/images/bookjacket__green__001.png` â†’ logit=15.80\n",
       "  - `dataset/images/notebookwithkraftcover__science__001.png` â†’ logit=13.48\n",
       "  - `dataset/images/bookjacket__green__002.png` â†’ logit=13.10\n",
       "  - `dataset/images/notebookwithkraftcover__minimalist__002.png` â†’ logit=12.49\n",
       "  - `dataset/images/bookjacket__classroom__002.png` â†’ logit=11.38\n",
       "\n",
       "### Class `fox squirrel` (ImageNet #335)\n",
       "- **Average logit**: -3.04 (std: 1.80)\n",
       "- **Topâ€‘5 activations**:\n",
       "  - `dataset/images/grannysmith__minimalist__002.png` â†’ logit=1.41\n",
       "  - `dataset/images/tablelampwithshadeoff__green__002.png` â†’ logit=1.40\n",
       "  - `dataset/images/grannysmith__green__002.png` â†’ logit=1.39\n",
       "  - `dataset/images/opaquemetalwaterbottle__green__002.png` â†’ logit=0.63\n",
       "  - `dataset/images/ceramiccoffeemug__modern__002.png` â†’ logit=0.34\n",
       "\n",
       "### Class `tennis ball` (ImageNet #852)\n",
       "- **Average logit**: 3.44 (std: 3.08)\n",
       "- **Topâ€‘5 activations**:\n",
       "  - `dataset/images/grannysmith__plain__002.png` â†’ logit=17.15\n",
       "  - `dataset/images/grannysmith__classroom__001.png` â†’ logit=12.90\n",
       "  - `dataset/images/grannysmith__plain__001.png` â†’ logit=11.18\n",
       "  - `dataset/images/grannysmith__minimalist__001.png` â†’ logit=9.71\n",
       "  - `dataset/images/grannysmith__hotel__001.png` â†’ logit=9.10\n",
       "\n",
       "## 5 Main biases of the model\n",
       "1. **Contextual Bias**: The model often fails to associate objects with their correct contexts, leading to incoherent predictions. For example, it misidentifies a bookjacket in a classroom as unrelated items like a laptop or envelope.\n",
       "2. **Object Confusion**: The model frequently confuses similar objects, such as mistaking a Granny Smith apple for a croquet ball or a pillow for a couch.\n",
       "3. **Cultural Bias**: The model may reflect biases present in the training data, leading to skewed predictions based on cultural contexts that are not universally applicable.\n",
       "\n",
       "## 6 Overall verdict\n",
       "- **Strengths**:\n",
       "  - Capable of identifying certain objects accurately in ideal contexts.\n",
       "  - Demonstrates some level of understanding of object categories.\n",
       "  \n",
       "- **Weaknesses**:\n",
       "  - High incoherence rate (48.76%) indicates significant misalignment with prompts.\n",
       "  - Frequent contextual and object confusion leads to unreliable predictions.\n",
       "\n",
       "- **Final Reliability Rating**: 2/5"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 7: Output finale\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "print(\"Report salvato in:\", OUTPUT_DIR / \"report.md\")\n",
    "report_md = report_path.read_text(encoding=\"utf-8\")\n",
    "display(Markdown(report_md))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
