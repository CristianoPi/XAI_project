{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "254a6f00",
   "metadata": {},
   "source": [
    "# Progetto XAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44d9906",
   "metadata": {},
   "source": [
    "Generazione del Dataset tramite Stable Diffusion\n",
    "\n",
    "Scelte progettuali: soggetti e contesti\n",
    "\n",
    "La generazione del dataset √® stata eseguita tramite Stable Diffusion, con l‚Äôobiettivo di analizzare la presenza e l‚Äôimpatto di indizi spuri nelle immagini. Gli indizi spuri sono elementi visivi non rilevanti rispetto alla classe target, ma che possono essere appresi dal modello come scorciatoie spurie per la classificazione. Analizzarli nel nostro contesto ci consente di valutare quanto i modelli neurali siano sensibili o robusti a queste correlazioni spurie durante il training.\n",
    "\n",
    "Motivazioni\n",
    "\n",
    "Le motivazioni alla base della scelta dei soggetti e dei contesti sono documentate anche nel nostro archivio interno (OneNote). In breve, abbiamo cercato di bilanciare soggetti neutri e contesti ad alto bias visivo, per osservare come i modelli discriminano tra il contenuto semanticamente rilevante e quello potenzialmente fuorviante.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "Soggetti Neutri (10 oggetti)\n",
    "\n",
    "Questi soggetti sono stati scelti per la loro natura visivamente semplice e per la bassa probabilit√† che inducano bias nel modello:\n",
    "\t1.\tCuscino\n",
    "\t2.\tSedia semplice\n",
    "\t3.\tBottiglia trasparente\n",
    "\t4.\tCiotola vuota\n",
    "\t5.\tCubo grigio (astratto, geometrico)\n",
    "\t6.\tLampadina spenta\n",
    "\t7.\tLibro chiuso\n",
    "\t8.\tTazza vuota\n",
    "\t9.\tScatola di cartone anonima\n",
    "\t10.\tPersona con t-shirt neutra\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "Contesti Ad Alto Bias (inizialmente selezionati)\n",
    "\n",
    "I seguenti contesti presentano una forte impronta semantica o simbolica, e sono quindi considerati ad alto potenziale di bias:\n",
    "\t1.\tInterno ufficio moderno (scrivania, laptop, lampada)\n",
    "\t2.\tCucina con elettrodomestici\n",
    "\t3.\tPrato verde all‚Äôaperto (ambiente naturale)\n",
    "\t4.\tAmbiente militare (uniformi, elmetti)\n",
    "\t5.\tPubblicit√† con colori vivaci (rosso/blu, banner)\n",
    "\t6.\tSala conferenze con palco\n",
    "\t7.\tBagno domestico (piastrelle, lavabo)\n",
    "\t8.\tLaboratorio scientifico (tubi, beute, microscopi)\n",
    "\t9.\tGarage / officina (attrezzi, macchinari)\n",
    "\t10.\tCorridoio scolastico con banchi\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "Limitazioni Tecniche\n",
    "\n",
    "Tuttavia, la generazione fedele di questi contesti si √® rivelata troppo complessa per i motori di Stable Diffusion attualmente a nostra disposizione. In particolare, contesti ricchi di oggetti strutturati e relazioni spaziali complesse hanno mostrato bassa coerenza visiva, ambiguit√† semantica e artefatti nei dettagli.\n",
    "\n",
    "Conclusione\n",
    "\n",
    "Di conseguenza, si √® scelto di delimitare il set di contesti a quelli effettivamente generabili in modo coerente, riducendo la complessit√† ambientale per mantenere un dataset visivamente consistente e utile all‚Äôanalisi sperimentale.\n",
    "\n",
    "‚∏ª\n",
    "\n",
    "Da rivedere le classi, devono corrispondere a quelle di image net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2cc138",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'diffusers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdiffusers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StableDiffusionPipeline\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# --- Configurazione ---\u001b[39;00m\n\u001b[1;32m     12\u001b[0m objects \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mceramic coffee mug\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhardcover book (closed)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplain cardboard box\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimple wooden chair\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoft couch pillow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopaque metal water bottle\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable lamp with shade (off)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapple\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnotebook with kraft cover\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatte gray sphere\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m ]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'diffusers'"
     ]
    }
   ],
   "source": [
    "#ESEGUIRE SU KAGGLE O IN UN AMBIENTE CON GPU IN CUI SONO INSTALLATI DIFFUSERS E TORCH\n",
    "#da modificare che le nuove classi\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "# --- Configurazione ---\n",
    "objects = [\n",
    "    \"ceramic coffee mug\", \"hardcover book (closed)\", \"plain cardboard box\",\n",
    "    \"simple wooden chair\", \"soft couch pillow\", \"opaque metal water bottle\",\n",
    "    \"table lamp with shade (off)\", \"apple\", \"notebook with kraft cover\", \"matte gray sphere\"\n",
    "]\n",
    "contexts = [\n",
    "    \"plain white studio background\", \"minimalist living-room corner\", \"modern office desk\",\n",
    "    \"kitchen countertop daylight\", \"green park lawn afternoon light\",\n",
    "    \"science lab bench\", \"garage workshop tools on pegboard\",\n",
    "    \"hotel room desk area\", \"bathroom vanity matte tiles\", \"classroom row of desks daylight\"\n",
    "]\n",
    "\n",
    "# --- Output Directory ---\n",
    "base_dir = Path(\"/kaggle/working/dataset\")\n",
    "img_dir = base_dir / \"images\"\n",
    "img_dir.mkdir(parents=True, exist_ok=True)\n",
    "csv_meta = base_dir / \"dataset_metadata.csv\"\n",
    "\n",
    "# --- Inizializza pipeline Stable Diffusion ---\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16,\n",
    "    use_safetensors=True,\n",
    "    low_cpu_mem_usage=True\n",
    ").to(\"cuda\")\n",
    "pipe.enable_attention_slicing()\n",
    "\n",
    "# --- CSV setup ---\n",
    "csvfile = open(csv_meta, \"w\", newline=\"\")\n",
    "writer = csv.DictWriter(csvfile, fieldnames=[\"file_name\", \"prompt\", \"seed\", \"background\"])\n",
    "writer.writeheader()\n",
    "\n",
    "# --- Generazione immagini + metadati ---\n",
    "img_counter = 1\n",
    "for obj in objects:\n",
    "    for ctx in contexts:\n",
    "        prompt = f\"A neutral {obj} in a {ctx} background\"\n",
    "        obj_short = obj.replace(\" \", \"\").replace(\"(\", \"\").replace(\")\", \"\").lower()\n",
    "        ctx_short = ctx.split()[0].lower()  # solo la prima parola del contesto\n",
    "\n",
    "        for i in range(2):  # Numero immagini per combinazione\n",
    "            filename = f\"{obj_short}__{ctx_short}__{i+1:03}.png\"\n",
    "            file_path = img_dir / filename\n",
    "\n",
    "            # Generazione immagine\n",
    "            img = pipe(prompt, num_inference_steps=30, guidance_scale=11).images[0]\n",
    "            img.save(file_path)\n",
    "\n",
    "            # Scrittura riga CSV\n",
    "            writer.writerow({\n",
    "                \"file_name\": f\"images/{filename}\",\n",
    "                \"prompt\": prompt,\n",
    "                \"seed\": i + 1,\n",
    "                \"background\": ctx\n",
    "            })\n",
    "            img_counter += 1\n",
    "\n",
    "csvfile.close()\n",
    "print(\"‚úÖ Immagini e metadati generati!\")\n",
    "\n",
    "# --- Creazione ZIP finale ---\n",
    "zip_path = \"/kaggle/working/dataset.zip\"\n",
    "with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for file_path in base_dir.rglob(\"*\"):\n",
    "        zipf.write(file_path, arcname=file_path.relative_to(base_dir.parent))\n",
    "\n",
    "print(\"‚úÖ ZIP pronto per il download:\", zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae04aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n"
     ]
    }
   ],
   "source": [
    "! pip install -q openai pandas pyarrow pillow tqdm urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f0e271",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# --- Carica metadata e filtra per presenza oggetto/contesto + CLIP ---\u001b[39;00m\n\u001b[1;32m     37\u001b[0m cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpart_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcfg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampler\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 38\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMETA_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mprompt\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Applica filtro testuale\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parquet.py:274\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m _get_path_or_handle(\n\u001b[1;32m    268\u001b[0m     path,\n\u001b[1;32m    269\u001b[0m     filesystem,\n\u001b[1;32m    270\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    271\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    272\u001b[0m )\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m     result \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mto_pandas(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mto_pandas_kwargs)\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pyarrow/parquet/core.py:1843\u001b[0m, in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, binary_type, list_type, memory_map, buffer_size, partitioning, filesystem, filters, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification, arrow_extensions_enabled)\u001b[0m\n\u001b[1;32m   1831\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_table\u001b[39m(source, \u001b[38;5;241m*\u001b[39m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, use_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1832\u001b[0m                schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, use_pandas_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, read_dictionary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1833\u001b[0m                binary_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, list_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1839\u001b[0m                page_checksum_verification\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1840\u001b[0m                arrow_extensions_enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1842\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1843\u001b[0m         dataset \u001b[38;5;241m=\u001b[39m \u001b[43mParquetDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1844\u001b[0m \u001b[43m            \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1845\u001b[0m \u001b[43m            \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1846\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1847\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartitioning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1849\u001b[0m \u001b[43m            \u001b[49m\u001b[43mread_dictionary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_dictionary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1850\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbinary_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1851\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlist_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlist_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1852\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1853\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1854\u001b[0m \u001b[43m            \u001b[49m\u001b[43mignore_prefixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_prefixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1855\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpre_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1856\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcoerce_int96_timestamp_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_int96_timestamp_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecryption_properties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecryption_properties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mthrift_string_size_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrift_string_size_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mthrift_container_size_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrift_container_size_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpage_checksum_verification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpage_checksum_verification\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m            \u001b[49m\u001b[43marrow_extensions_enabled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrow_extensions_enabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1863\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m   1864\u001b[0m         \u001b[38;5;66;03m# fall back on ParquetFile for simple cases when pyarrow.dataset\u001b[39;00m\n\u001b[1;32m   1865\u001b[0m         \u001b[38;5;66;03m# module is not available\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pyarrow/parquet/core.py:1413\u001b[0m, in \u001b[0;36mParquetDataset.__init__\u001b[0;34m(self, path_or_paths, filesystem, schema, filters, read_dictionary, binary_type, list_type, memory_map, buffer_size, partitioning, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification, arrow_extensions_enabled)\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m single_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1410\u001b[0m     fragment \u001b[38;5;241m=\u001b[39m parquet_format\u001b[38;5;241m.\u001b[39mmake_fragment(single_file, filesystem)\n\u001b[1;32m   1412\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mFileSystemDataset(\n\u001b[0;32m-> 1413\u001b[0m         [fragment], schema\u001b[38;5;241m=\u001b[39mschema \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mfragment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphysical_schema\u001b[49m,\n\u001b[1;32m   1414\u001b[0m         \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mparquet_format,\n\u001b[1;32m   1415\u001b[0m         filesystem\u001b[38;5;241m=\u001b[39mfragment\u001b[38;5;241m.\u001b[39mfilesystem\n\u001b[1;32m   1416\u001b[0m     )\n\u001b[1;32m   1417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;66;03m# check partitioning to enable dictionary encoding\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pyarrow/_dataset.pyx:1473\u001b[0m, in \u001b[0;36mpyarrow._dataset.Fragment.physical_schema.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pyarrow/error.pxi:155\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pyarrow/error.pxi:92\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file."
     ]
    }
   ],
   "source": [
    "#prendo le immagini da diffusiondb soluzione alternativa ma non realizzabile \n",
    "import os, pandas as pd, urllib.request, zipfile, csv\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import openai\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# --- CONFIGURAZIONE ---\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "OBJ_CTX_PAIRS = [(\"apple\", \"studio\")]\n",
    "CLIP_THRESH = 0.30\n",
    "COSINE_THRESH = 0.30\n",
    "MAX_IMAGES = 50\n",
    "MAX_PARTS = 5\n",
    "\n",
    "BASE = Path(\"./dataset_diffdb\")\n",
    "IMG_DIR = BASE / \"images\"; IMG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CSV_META = BASE / \"dataset_metadata.csv\"\n",
    "META_URL = \"https://huggingface.co/datasets/poloclub/diffusiondb/resolve/main/metadata.parquet\"\n",
    "META_FILE = BASE / \"metadata.parquet\"\n",
    "\n",
    "# --- Funzione generazione prompt coerente ---\n",
    "def make_prompt(obj, ctx):\n",
    "    return (\n",
    "        f\"A product shot photo of a red {obj}, close-up, \"\n",
    "        f\"on a clean {ctx} background, soft natural lighting, minimalistic composition\"\n",
    "    )\n",
    "\n",
    "# --- Scarica metadata.parquet se necessario ---\n",
    "if not META_FILE.exists():\n",
    "    print(\"‚¨áÔ∏è Scarico metadata.parquet‚Ä¶\")\n",
    "    urllib.request.urlretrieve(META_URL, META_FILE)\n",
    "\n",
    "# --- Carica metadata e filtra per presenza oggetto/contesto + CLIP ---\n",
    "cols = [\"image_name\", \"prompt\", \"part_id\", \"cfg\", \"seed\", \"clip\", \"sampler\"]\n",
    "df = pd.read_parquet(META_FILE, columns=cols)\n",
    "df[\"prompt\"] = df.prompt.str.lower()\n",
    "\n",
    "# Applica filtro testuale\n",
    "mask = df.prompt.apply(lambda t: any(o in t and ctx in t for o, ctx in OBJ_CTX_PAIRS)) & (df.clip >= CLIP_THRESH)\n",
    "df_f = df[mask].reset_index(drop=True)\n",
    "\n",
    "# Limita per numero parti e immagini\n",
    "parts = df_f.part_id.unique().tolist()[:MAX_PARTS]\n",
    "df_f = df_f[df_f.part_id.isin(parts)].head(MAX_IMAGES).reset_index(drop=True)\n",
    "\n",
    "# --- Embedding prompt migliorati ---\n",
    "print(\"üîç Calcolo embedding dei prompt con OpenAI\")\n",
    "prompt_map = {make_prompt(o, c): (o, c) for o, c in OBJ_CTX_PAIRS}\n",
    "prompt_embeds = {p: np.array(openai.Embeddings.create(model=\"text-embedding-3-small\", input=p).data[0].embedding)\n",
    "                 for p in prompt_map.keys()}\n",
    "\n",
    "# --- Scarica immagini e confronta embedding ---\n",
    "to_keep = []\n",
    "parts_done = set()\n",
    "\n",
    "for _, r in tqdm(df_f.iterrows(), total=len(df_f), desc=\"Verifica embedding\"):\n",
    "    # Trova il prompt strutturato associato a questo record\n",
    "    matched = next((p for p, (o, c) in prompt_map.items() if o in r.prompt and c in r.prompt), None)\n",
    "    if matched is None:\n",
    "        continue\n",
    "\n",
    "    # Scarica il part.zip se necessario\n",
    "    if r.part_id not in parts_done:\n",
    "        zip_n = f\"part-{int(r.part_id):06}.zip\"\n",
    "        urllib.request.urlretrieve(f\"https://huggingface.co/datasets/poloclub/diffusiondb/resolve/main/images/{zip_n}\", zip_n)\n",
    "        zipfile.ZipFile(zip_n).extractall(f\"part-{int(r.part_id):06}\")\n",
    "        parts_done.add(r.part_id)\n",
    "\n",
    "    # Embedding immagine\n",
    "    img = Image.open(Path(f\"part-{int(r.part_id):06}\") / r.image_name)\n",
    "    img_bytes = open(img.fp.name, \"rb\").read()\n",
    "    resp = openai.Embeddings.create(model=\"text-embedding-ada-002\", input=img_bytes)\n",
    "    img_emb = np.array(resp.data[0].embedding)\n",
    "\n",
    "    # Confronto cosine\n",
    "    cosine = np.dot(prompt_embeds[matched], img_emb) / (norm(prompt_embeds[matched]) * norm(img_emb))\n",
    "    if cosine >= COSINE_THRESH:\n",
    "        r[\"prompt_structured\"] = matched\n",
    "        r[\"cosine\"] = cosine\n",
    "        to_keep.append(r)\n",
    "\n",
    "df_sel = pd.DataFrame(to_keep)\n",
    "\n",
    "# --- Salva immagini selezionate e CSV ---\n",
    "with open(CSV_META, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"file\", \"prompt\", \"prompt_structured\", \"cfg\", \"seed\", \"sampler\", \"clip\", \"cosine\"])\n",
    "    writer.writeheader()\n",
    "    for _, r in df_sel.iterrows():\n",
    "        src = Path(f\"part-{int(r.part_id):06}\") / r.image_name\n",
    "        Image.open(src).save(IMG_DIR / r.image_name)\n",
    "        writer.writerow({\n",
    "            \"file\": f\"images/{r.image_name}\",\n",
    "            \"prompt\": r.prompt,\n",
    "            \"prompt_structured\": r.prompt_structured,\n",
    "            \"cfg\": float(r.cfg),\n",
    "            \"seed\": int(r.seed),\n",
    "            \"sampler\": int(r.sampler),\n",
    "            \"clip\": float(r.clip),\n",
    "            \"cosine\": round(float(r.cosine), 4)\n",
    "        })\n",
    "\n",
    "print(\"‚úÖ Dataset finale creato:\", len(df_sel), \"immagini.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9e78e416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pycocotools in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (2.0.10)\n",
      "Requirement already satisfied: requests in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (2.32.3)\n",
      "Requirement already satisfied: pillow in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (11.1.0)\n",
      "Requirement already satisfied: pandas in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (2.2.3)\n",
      "Requirement already satisfied: tqdm in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (from pycocotools) (2.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (from requests) (1.26.20)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/cristianopistorio/Library/Python/3.9/lib/python/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip3 install pycocotools requests pillow pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cec3b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è Sto scaricando le annotazioni COCO 2017‚Ä¶\n",
      "  üóÉÔ∏è Estraggo annotations/captions_val2017.json\n",
      "‚úÖ Annotations pronte in annotations/captions_val2017.json\n"
     ]
    }
   ],
   "source": [
    "# Prendo immagini casuali da COCO 2017 analizzando questa soluzione ci siamo resi conto che non √® possibile fare un dataset di immagini casuali \n",
    "# servono soggetti specifici presenti in ImageNet-1k\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# Percorsi e URL\n",
    "ANNOT_DIR = Path(\"annotations\")\n",
    "ANNOT_DIR.mkdir(exist_ok=True)\n",
    "url = \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"\n",
    "zip_path = ANNOT_DIR / \"annotations_trainval2017.zip\"\n",
    "\n",
    "# Scarica lo zip se manca\n",
    "if not (ANNOT_DIR / \"captions_val2017.json\").exists():\n",
    "    print(\"‚¨áÔ∏è Sto scaricando le annotazioni COCO 2017‚Ä¶\")\n",
    "    resp = requests.get(url, stream=True)\n",
    "    with open(zip_path, \"wb\") as f:\n",
    "        for chunk in resp.iter_content(1024*1024):\n",
    "            f.write(chunk)\n",
    "    # Estrai solo i file di interesse\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "        for fname in [\"annotations/captions_val2017.json\"]:\n",
    "            print(\"  üóÉÔ∏è Estraggo\", fname)\n",
    "            z.extract(fname, \".\")\n",
    "    os.remove(zip_path)\n",
    "    print(\"‚úÖ Annotations pronte in\", ANNOT_DIR / \"captions_val2017.json\")\n",
    "else:\n",
    "    print(\"‚úÖ File annotations/captions_val2017.json gi√† presente, non scarico.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b78c0adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scarico immagini: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:35<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fatto! 50 immagini salvate in dataset_coco/images e metadata in dataset_coco/dataset_metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "\n",
    "# --- CONFIGURAZIONE ---\n",
    "BASE = Path(\"./dataset_coco\")\n",
    "ANNOT_DIR = Path(\"./annotations\")\n",
    "ANNOT_FILE = ANNOT_DIR / \"captions_val2017.json\"\n",
    "IMG_DIR = BASE / \"images\"; IMG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CSV_META = BASE / \"dataset_metadata.csv\"\n",
    "\n",
    "# Controlla presenza file JSON\n",
    "if not ANNOT_FILE.exists():\n",
    "    raise FileNotFoundError(f\"File annotazioni mancante: {ANNOT_FILE}\")\n",
    "\n",
    "# Carica annotazioni COCO\n",
    "coco = COCO(str(ANNOT_FILE))\n",
    "\n",
    "# Seleziona 50 immagini casuali\n",
    "img_ids = coco.getImgIds()\n",
    "sel_ids = random.sample(img_ids, 50)\n",
    "\n",
    "rows = []\n",
    "for img_id in tqdm(sel_ids, desc=\"Scarico immagini\"):\n",
    "    info = coco.loadImgs(img_id)[0]\n",
    "    url = info[\"coco_url\"]\n",
    "    fname = info[\"file_name\"]\n",
    "\n",
    "    # Scarica l'immagine\n",
    "    resp = requests.get(url, timeout=10)\n",
    "    img_path = IMG_DIR / fname\n",
    "    img_path.write_bytes(resp.content)\n",
    "\n",
    "    # Carica didascalie\n",
    "    ann_ids = coco.getAnnIds(imgIds=[img_id])\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "    captions = [ann[\"caption\"] for ann in anns]\n",
    "    prompt = captions[0] if captions else \"\"\n",
    "\n",
    "    rows.append({\n",
    "        \"file\": f\"images/{fname}\",\n",
    "        \"prompt\": prompt\n",
    "    })\n",
    "\n",
    "# Salva CSV finale\n",
    "pd.DataFrame(rows).to_csv(CSV_META, index=False, encoding=\"utf-8\")\n",
    "print(f\"‚úÖ Fatto! 50 immagini salvate in {IMG_DIR} e metadata in {CSV_META}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3ba049",
   "metadata": {},
   "source": [
    "## Analizzo un modello a partire dal DataSet di Immagini\n",
    "\n",
    "A questo punto del notebook si deve avere un DataSet di immagini coerenti, con il DataSet Metadata. Bisogna stare attenti alla successive configurazioni, le cartelle devono essere quelle che si voglio analizzare ecc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830dd71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Installazione pacchetti (esegui una volta)\n",
    "! pip3 install -q torch torchvision openai python-dotenv pillow tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ec18c1",
   "metadata": {},
   "source": [
    "üìÅ Configurazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f2f68a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VISION_MODEL: alexnet\n",
      "LLM_MODEL: gpt-4o-mini\n",
      "OPENAI_API_KEY: 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\n",
      "IMG_DIR: dataset_coco/images\n",
      "META_CSV: dataset_coco/dataset_metadata.csv\n",
      "OUTPUT_DIR: analysis_out_coco_alex\n",
      "COHERENCE_THRESHOLD: 0.3\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Configurazione variabili e caricamento ambiente\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carica da file .env se presente\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Variabili configurabili\n",
    "VISION_MODEL = os.getenv(\"VISION_MODEL\", \"alexnet\")\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"gpt-4o-mini\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "IMG_DIR = Path(os.getenv(\"IMG_DIR\", \"dataset_/images\"))\n",
    "META_CSV = Path(os.getenv(\"META_CSV\", \"dataset_/dataset_metadata.csv\"))\n",
    "OUTPUT_DIR = Path(os.getenv(\"OUTPUT_DIR\", \"analysis_out_\"))\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "COHERENCE_THRESHOLD = float(os.getenv(\"COHERENCE_TH\", 0.5))\n",
    "\n",
    "print(f\"VISION_MODEL: {VISION_MODEL}\")\n",
    "print(f\"LLM_MODEL: {LLM_MODEL}\")\n",
    "print(f\"OPENAI_API_KEY: {OPENAI_API_KEY}\")\n",
    "print(f\"IMG_DIR: {IMG_DIR}\")\n",
    "print(f\"META_CSV: {META_CSV}\")\n",
    "print(f\"OUTPUT_DIR: {OUTPUT_DIR}\")\n",
    "print(f\"COHERENCE_THRESHOLD: {COHERENCE_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9334f0b1",
   "metadata": {},
   "source": [
    "üß† Caricamento modello visivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2bd4a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Carica modello vision e classi ImageNet\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Caricamento modello dinamico\n",
    "model = getattr(models, VISION_MODEL)(pretrained=True).eval().to(device)\n",
    "\n",
    "# Etichette ImageNet\n",
    "import urllib.request\n",
    "labels_url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "imagenet_labels = urllib.request.urlopen(labels_url).read().decode().splitlines()\n",
    "idx2label = {i: l for i, l in enumerate(imagenet_labels)}\n",
    "\n",
    "# Trasformazioni immagine\n",
    "transform = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6111376e",
   "metadata": {},
   "source": [
    "üìä Estrazione top-10 \n",
    "10 non √® scelto a caso.\n",
    "Studi su ImageNet mostrano che i primi dieci logit spiegano in media oltre il 95 % della massa di probabilit√† soft-max per modelli come ResNet-50 o ViT-B/16.  Questo significa che, nella maggior parte dei casi, i concetti residui oltre il decimo posto contribuiscono poco alla descrizione semantica globale.\n",
    "https://arxiv.org/pdf/2206.07290\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7db62bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:00<00:00, 83.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: dataset_coco/images/000000010764.jpg\n",
      "Prompt: A catches crouches on a patch of dirt.\n",
      "Top-10 logits:\n",
      "  logit 429: baseball (0.5124)\n",
      "  logit 981: ballplayer (0.4875)\n",
      "  logit 518: crash helmet (0.0000)\n",
      "  logit 560: football helmet (0.0000)\n",
      "  logit 665: moped (0.0000)\n",
      "  logit 671: mountain bike (0.0000)\n",
      "  logit 615: knee pad (0.0000)\n",
      "  logit 758: reel (0.0000)\n",
      "  logit 763: revolver (0.0000)\n",
      "  logit 752: racket (0.0000)\n",
      "\n",
      "File: dataset_coco/images/000000017178.jpg\n",
      "Prompt: Horses communing with each other on a shady street.\n",
      "Top-10 logits:\n",
      "  logit 385: Indian elephant (0.3155)\n",
      "  logit 690: oxcart (0.2008)\n",
      "  logit 346: water buffalo (0.1914)\n",
      "  logit 345: ox (0.0985)\n",
      "  logit 386: African elephant (0.0720)\n",
      "  logit 603: horse cart (0.0673)\n",
      "  logit 101: tusker (0.0154)\n",
      "  logit 347: bison (0.0060)\n",
      "  logit 343: warthog (0.0020)\n",
      "  logit 349: bighorn (0.0018)\n",
      "\n",
      "File: dataset_coco/images/000000025393.jpg\n",
      "Prompt: a couple of men in ties are outside\n",
      "Top-10 logits:\n",
      "  logit 457: bow tie (0.0984)\n",
      "  logit 617: lab coat (0.0975)\n",
      "  logit 906: Windsor tie (0.0688)\n",
      "  logit 834: suit (0.0445)\n",
      "  logit 731: plunger (0.0385)\n",
      "  logit 824: stole (0.0314)\n",
      "  logit 430: basketball (0.0252)\n",
      "  logit 841: sweatshirt (0.0225)\n",
      "  logit 523: crutch (0.0211)\n",
      "  logit 400: academic gown (0.0210)\n",
      "\n",
      "File: dataset_coco/images/000000025394.jpg\n",
      "Prompt: Bartender opening a bottle of wine while patron waits patiently\n",
      "Top-10 logits:\n",
      "  logit 822: steel drum (0.1089)\n",
      "  logit 441: beer glass (0.0788)\n",
      "  logit 542: drumstick (0.0784)\n",
      "  logit 503: cocktail shaker (0.0690)\n",
      "  logit 618: ladle (0.0563)\n",
      "  logit 899: water jug (0.0475)\n",
      "  logit 541: drum (0.0429)\n",
      "  logit 909: wok (0.0399)\n",
      "  logit 505: coffeepot (0.0398)\n",
      "  logit 762: restaurant (0.0338)\n",
      "\n",
      "File: dataset_coco/images/000000025593.jpg\n",
      "Prompt: A stop sign on a post at a public street.\n",
      "Top-10 logits:\n",
      "  logit 755: radio telescope (0.2531)\n",
      "  logit 919: street sign (0.2224)\n",
      "  logit 405: airship (0.2155)\n",
      "  logit 727: planetarium (0.0825)\n",
      "  logit 807: solar dish (0.0280)\n",
      "  logit 900: water tower (0.0179)\n",
      "  logit 538: dome (0.0149)\n",
      "  logit 417: balloon (0.0140)\n",
      "  logit 744: projectile (0.0136)\n",
      "  logit 657: missile (0.0131)\n",
      "\n",
      "File: dataset_coco/images/000000033759.jpg\n",
      "Prompt: A boy swinging a baseball bat at a game.\n",
      "Top-10 logits:\n",
      "  logit 429: baseball (0.5544)\n",
      "  logit 981: ballplayer (0.3929)\n",
      "  logit 752: racket (0.0347)\n",
      "  logit 621: lawn mower (0.0057)\n",
      "  logit 805: soccer ball (0.0019)\n",
      "  logit 489: chainlink fence (0.0007)\n",
      "  logit 225: malinois (0.0006)\n",
      "  logit 159: Rhodesian ridgeback (0.0005)\n",
      "  logit 173: Ibizan hound (0.0005)\n",
      "  logit 491: chain saw (0.0005)\n",
      "\n",
      "File: dataset_coco/images/000000060449.jpg\n",
      "Prompt: A very nice looking deck area with a small table and a laptop.\n",
      "Top-10 logits:\n",
      "  logit 706: patio (0.3453)\n",
      "  logit 682: obelisk (0.1331)\n",
      "  logit 765: rocking chair (0.0506)\n",
      "  logit 799: sliding door (0.0412)\n",
      "  logit 536: dock (0.0395)\n",
      "  logit 449: boathouse (0.0326)\n",
      "  logit 876: tub (0.0255)\n",
      "  logit 627: limousine (0.0171)\n",
      "  logit 583: guillotine (0.0170)\n",
      "  logit 565: freight car (0.0146)\n",
      "\n",
      "File: dataset_coco/images/000000060507.jpg\n",
      "Prompt: A batter at a game playing in a baseball game.\n",
      "Top-10 logits:\n",
      "  logit 981: ballplayer (0.9794)\n",
      "  logit 429: baseball (0.0197)\n",
      "  logit 232: Border collie (0.0003)\n",
      "  logit 241: EntleBucher (0.0001)\n",
      "  logit 852: tennis ball (0.0001)\n",
      "  logit 217: English springer (0.0000)\n",
      "  logit 781: scoreboard (0.0000)\n",
      "  logit 169: borzoi (0.0000)\n",
      "  logit 240: Appenzeller (0.0000)\n",
      "  logit 253: basenji (0.0000)\n",
      "\n",
      "File: dataset_coco/images/000000087875.jpg\n",
      "Prompt: Their is a hadron and their  in this lot,\n",
      "Top-10 logits:\n",
      "  logit 653: milk can (0.1924)\n",
      "  logit 14: indigo bunting (0.1749)\n",
      "  logit 448: birdhouse (0.1077)\n",
      "  logit 17: jay (0.0890)\n",
      "  logit 708: pedestal (0.0685)\n",
      "  logit 410: apiary (0.0403)\n",
      "  logit 131: little blue heron (0.0195)\n",
      "  logit 898: water bottle (0.0124)\n",
      "  logit 756: rain barrel (0.0111)\n",
      "  logit 562: fountain (0.0096)\n",
      "\n",
      "File: dataset_coco/images/000000095069.jpg\n",
      "Prompt: A european city in nice a sunny bright day\n",
      "Top-10 logits:\n",
      "  logit 497: church (0.4298)\n",
      "  logit 698: palace (0.2021)\n",
      "  logit 832: stupa (0.1059)\n",
      "  logit 483: castle (0.0893)\n",
      "  logit 663: monastery (0.0701)\n",
      "  logit 442: bell cote (0.0393)\n",
      "  logit 562: fountain (0.0141)\n",
      "  logit 682: obelisk (0.0103)\n",
      "  logit 668: mosque (0.0090)\n",
      "  logit 538: dome (0.0073)\n",
      "\n",
      "File: dataset_coco/images/000000107094.jpg\n",
      "Prompt: A man riding skis on top of snow covered ground.\n",
      "Top-10 logits:\n",
      "  logit 791: shopping cart (0.1521)\n",
      "  logit 803: snowplow (0.1042)\n",
      "  logit 702: parallel bars (0.0849)\n",
      "  logit 489: chainlink fence (0.0646)\n",
      "  logit 795: ski (0.0585)\n",
      "  logit 766: rotisserie (0.0530)\n",
      "  logit 781: scoreboard (0.0284)\n",
      "  logit 819: stage (0.0266)\n",
      "  logit 537: dogsled (0.0203)\n",
      "  logit 792: shovel (0.0198)\n",
      "\n",
      "File: dataset_coco/images/000000108253.jpg\n",
      "Prompt: A plate of cheese bread next to bread sticks and wine.\n",
      "Top-10 logits:\n",
      "  logit 933: cheeseburger (0.6771)\n",
      "  logit 965: burrito (0.0993)\n",
      "  logit 934: hotdog (0.0564)\n",
      "  logit 923: plate (0.0266)\n",
      "  logit 928: ice cream (0.0221)\n",
      "  logit 964: potpie (0.0217)\n",
      "  logit 930: French loaf (0.0189)\n",
      "  logit 118: Dungeness crab (0.0182)\n",
      "  logit 935: mashed potato (0.0076)\n",
      "  logit 924: guacamole (0.0062)\n",
      "\n",
      "File: dataset_coco/images/000000125062.jpg\n",
      "Prompt: A row of white teddy bears on shelf next to DVDs.\n",
      "Top-10 logits:\n",
      "  logit 684: ocarina (0.2644)\n",
      "  logit 865: toyshop (0.0870)\n",
      "  logit 87: African grey (0.0571)\n",
      "  logit 258: Samoyed (0.0456)\n",
      "  logit 769: rule (0.0397)\n",
      "  logit 324: cabbage butterfly (0.0266)\n",
      "  logit 844: switch (0.0265)\n",
      "  logit 714: pick (0.0209)\n",
      "  logit 333: hamster (0.0188)\n",
      "  logit 248: Eskimo dog (0.0179)\n",
      "\n",
      "File: dataset_coco/images/000000127624.jpg\n",
      "Prompt: A train next to a train station with city in background.\n",
      "Top-10 logits:\n",
      "  logit 975: lakeside (0.2507)\n",
      "  logit 536: dock (0.0981)\n",
      "  logit 483: castle (0.0584)\n",
      "  logit 839: suspension bridge (0.0552)\n",
      "  logit 510: container ship (0.0400)\n",
      "  logit 449: boathouse (0.0363)\n",
      "  logit 888: viaduct (0.0241)\n",
      "  logit 779: school bus (0.0227)\n",
      "  logit 820: steam locomotive (0.0218)\n",
      "  logit 525: dam (0.0197)\n",
      "\n",
      "File: dataset_coco/images/000000129135.jpg\n",
      "Prompt: Yellow Train stopped at the station in front of a bench.  \n",
      "Top-10 logits:\n",
      "  logit 829: streetcar (0.3416)\n",
      "  logit 466: bullet train (0.2314)\n",
      "  logit 705: passenger car (0.1099)\n",
      "  logit 547: electric locomotive (0.0982)\n",
      "  logit 498: cinema (0.0210)\n",
      "  logit 886: vending machine (0.0210)\n",
      "  logit 799: sliding door (0.0195)\n",
      "  logit 536: dock (0.0138)\n",
      "  logit 860: tobacco shop (0.0135)\n",
      "  logit 424: barbershop (0.0087)\n",
      "\n",
      "File: dataset_coco/images/000000143556.jpg\n",
      "Prompt: A group of bikers riding motorcycles across a bridge.\n",
      "Top-10 logits:\n",
      "  logit 573: go-kart (0.5258)\n",
      "  logit 670: motor scooter (0.0968)\n",
      "  logit 665: moped (0.0681)\n",
      "  logit 518: crash helmet (0.0499)\n",
      "  logit 625: lifeboat (0.0388)\n",
      "  logit 880: unicycle (0.0188)\n",
      "  logit 557: flagpole (0.0151)\n",
      "  logit 920: traffic light (0.0130)\n",
      "  logit 444: bicycle-built-for-two (0.0124)\n",
      "  logit 830: stretcher (0.0107)\n",
      "\n",
      "File: dataset_coco/images/000000162130.jpg\n",
      "Prompt: A wooden bench is sitting next to a grassy field.\n",
      "Top-10 logits:\n",
      "  logit 912: worm fence (0.3758)\n",
      "  logit 646: maze (0.2278)\n",
      "  logit 703: park bench (0.1674)\n",
      "  logit 975: lakeside (0.0483)\n",
      "  logit 825: stone wall (0.0148)\n",
      "  logit 425: barn (0.0088)\n",
      "  logit 449: boathouse (0.0073)\n",
      "  logit 979: valley (0.0070)\n",
      "  logit 958: hay (0.0044)\n",
      "  logit 888: viaduct (0.0043)\n",
      "\n",
      "File: dataset_coco/images/000000164363.jpg\n",
      "Prompt: A large wooden block with roman numeral numbers.\n",
      "Top-10 logits:\n",
      "  logit 892: wall clock (0.6145)\n",
      "  logit 409: analog clock (0.3641)\n",
      "  logit 635: magnetic compass (0.0079)\n",
      "  logit 426: barometer (0.0054)\n",
      "  logit 778: scale (0.0030)\n",
      "  logit 835: sundial (0.0027)\n",
      "  logit 826: stopwatch (0.0023)\n",
      "  logit 685: odometer (0.0000)\n",
      "  logit 531: digital watch (0.0000)\n",
      "  logit 538: dome (0.0000)\n",
      "\n",
      "File: dataset_coco/images/000000165713.jpg\n",
      "Prompt: A rusted silver fire hydrant next to two poles.\n",
      "Top-10 logits:\n",
      "  logit 524: cuirass (0.1766)\n",
      "  logit 637: mailbox (0.0941)\n",
      "  logit 737: pop bottle (0.0921)\n",
      "  logit 777: scabbard (0.0541)\n",
      "  logit 711: perfume (0.0485)\n",
      "  logit 461: breastplate (0.0467)\n",
      "  logit 507: combination lock (0.0439)\n",
      "  logit 695: padlock (0.0417)\n",
      "  logit 704: parking meter (0.0332)\n",
      "  logit 696: paintbrush (0.0306)\n",
      "\n",
      "File: dataset_coco/images/000000168619.jpg\n",
      "Prompt: A road traveling along a field under a cloudy sky.\n",
      "Top-10 logits:\n",
      "  logit 649: megalith (0.1875)\n",
      "  logit 970: alp (0.1257)\n",
      "  logit 915: yurt (0.1052)\n",
      "  logit 832: stupa (0.0588)\n",
      "  logit 979: valley (0.0543)\n",
      "  logit 958: hay (0.0516)\n",
      "  logit 755: radio telescope (0.0384)\n",
      "  logit 425: barn (0.0319)\n",
      "  logit 483: castle (0.0296)\n",
      "  logit 980: volcano (0.0255)\n",
      "\n",
      "File: dataset_coco/images/000000173008.jpg\n",
      "Prompt: A man in a tropical print shirt with glasses and long hair is eating a banana.\n",
      "Top-10 logits:\n",
      "  logit 118: Dungeness crab (0.2448)\n",
      "  logit 558: flute (0.0547)\n",
      "  logit 659: mixing bowl (0.0487)\n",
      "  logit 566: French horn (0.0484)\n",
      "  logit 683: oboe (0.0402)\n",
      "  logit 614: kimono (0.0396)\n",
      "  logit 776: sax (0.0390)\n",
      "  logit 697: pajama (0.0358)\n",
      "  logit 965: burrito (0.0326)\n",
      "  logit 927: trifle (0.0265)\n",
      "\n",
      "File: dataset_coco/images/000000178618.jpg\n",
      "Prompt: A dust cloud has formed in front of an elephant.\n",
      "Top-10 logits:\n",
      "  logit 213: Irish setter (0.2269)\n",
      "  logit 159: Rhodesian ridgeback (0.1460)\n",
      "  logit 211: vizsla (0.1057)\n",
      "  logit 339: sorrel (0.1010)\n",
      "  logit 345: ox (0.0606)\n",
      "  logit 168: redbone (0.0378)\n",
      "  logit 260: chow (0.0376)\n",
      "  logit 386: African elephant (0.0314)\n",
      "  logit 207: golden retriever (0.0303)\n",
      "  logit 365: orangutan (0.0184)\n",
      "\n",
      "File: dataset_coco/images/000000186624.jpg\n",
      "Prompt: Someone is standing near a train that is parked. \n",
      "Top-10 logits:\n",
      "  logit 820: steam locomotive (0.9489)\n",
      "  logit 547: electric locomotive (0.0364)\n",
      "  logit 847: tank (0.0022)\n",
      "  logit 705: passenger car (0.0021)\n",
      "  logit 864: tow truck (0.0019)\n",
      "  logit 561: forklift (0.0013)\n",
      "  logit 874: trolleybus (0.0009)\n",
      "  logit 634: lumbermill (0.0008)\n",
      "  logit 829: streetcar (0.0006)\n",
      "  logit 569: garbage truck (0.0006)\n",
      "\n",
      "File: dataset_coco/images/000000186632.jpg\n",
      "Prompt: A flat screen TV sitting in a living room in front of a dining room table.\n",
      "Top-10 logits:\n",
      "  logit 598: home theater (0.7333)\n",
      "  logit 782: screen (0.0866)\n",
      "  logit 664: monitor (0.0622)\n",
      "  logit 851: television (0.0605)\n",
      "  logit 526: desk (0.0223)\n",
      "  logit 527: desktop computer (0.0186)\n",
      "  logit 548: entertainment center (0.0026)\n",
      "  logit 673: mouse (0.0018)\n",
      "  logit 651: microwave (0.0013)\n",
      "  logit 613: joystick (0.0010)\n",
      "\n",
      "File: dataset_coco/images/000000187243.jpg\n",
      "Prompt: A woman laying on a bathroom floor next to a toilet.\n",
      "Top-10 logits:\n",
      "  logit 608: jean (0.1175)\n",
      "  logit 731: plunger (0.0876)\n",
      "  logit 523: crutch (0.0684)\n",
      "  logit 806: sock (0.0544)\n",
      "  logit 502: clog (0.0456)\n",
      "  logit 939: zucchini (0.0427)\n",
      "  logit 655: miniskirt (0.0319)\n",
      "  logit 567: frying pan (0.0284)\n",
      "  logit 462: broom (0.0263)\n",
      "  logit 422: barbell (0.0236)\n",
      "\n",
      "File: dataset_coco/images/000000224807.jpg\n",
      "Prompt: Men sit around a table sharing a meal.\n",
      "Top-10 logits:\n",
      "  logit 762: restaurant (0.2954)\n",
      "  logit 532: dining table (0.0569)\n",
      "  logit 728: plastic bag (0.0548)\n",
      "  logit 470: candle (0.0340)\n",
      "  logit 788: shoe shop (0.0320)\n",
      "  logit 582: grocery store (0.0297)\n",
      "  logit 697: pajama (0.0251)\n",
      "  logit 624: library (0.0225)\n",
      "  logit 830: stretcher (0.0224)\n",
      "  logit 509: confectionery (0.0205)\n",
      "\n",
      "File: dataset_coco/images/000000228981.jpg\n",
      "Prompt: A smart phone, digital camera and mobile phone on display.\n",
      "Top-10 logits:\n",
      "  logit 844: switch (0.2232)\n",
      "  logit 487: cellular telephone (0.2102)\n",
      "  logit 632: loudspeaker (0.1779)\n",
      "  logit 759: reflex camera (0.1371)\n",
      "  logit 485: CD player (0.0451)\n",
      "  logit 754: radio (0.0346)\n",
      "  logit 848: tape player (0.0250)\n",
      "  logit 859: toaster (0.0198)\n",
      "  logit 710: pencil sharpener (0.0143)\n",
      "  logit 605: iPod (0.0142)\n",
      "\n",
      "File: dataset_coco/images/000000245026.jpg\n",
      "Prompt: an image of a woman holding a cake \n",
      "Top-10 logits:\n",
      "  logit 700: paper towel (0.0975)\n",
      "  logit 411: apron (0.0512)\n",
      "  logit 470: candle (0.0434)\n",
      "  logit 610: jersey (0.0412)\n",
      "  logit 611: jigsaw puzzle (0.0362)\n",
      "  logit 443: bib (0.0328)\n",
      "  logit 478: carton (0.0324)\n",
      "  logit 529: diaper (0.0301)\n",
      "  logit 927: trifle (0.0299)\n",
      "  logit 999: toilet tissue (0.0291)\n",
      "\n",
      "File: dataset_coco/images/000000285788.jpg\n",
      "Prompt: Two giraffes that are standing in the grass.\n",
      "Top-10 logits:\n",
      "  logit 386: African elephant (0.3717)\n",
      "  logit 354: Arabian camel (0.1776)\n",
      "  logit 385: Indian elephant (0.0845)\n",
      "  logit 345: ox (0.0527)\n",
      "  logit 353: gazelle (0.0513)\n",
      "  logit 346: water buffalo (0.0445)\n",
      "  logit 355: llama (0.0443)\n",
      "  logit 101: tusker (0.0291)\n",
      "  logit 104: wallaby (0.0279)\n",
      "  logit 348: ram (0.0140)\n",
      "\n",
      "File: dataset_coco/images/000000292082.jpg\n",
      "Prompt: an old photo of a little girl sitting on her dads lap \n",
      "Top-10 logits:\n",
      "  logit 999: toilet tissue (0.0968)\n",
      "  logit 457: bow tie (0.0642)\n",
      "  logit 641: maraca (0.0560)\n",
      "  logit 617: lab coat (0.0392)\n",
      "  logit 678: neck brace (0.0259)\n",
      "  logit 552: feather boa (0.0239)\n",
      "  logit 593: harmonica (0.0199)\n",
      "  logit 438: beaker (0.0194)\n",
      "  logit 579: grand piano (0.0188)\n",
      "  logit 585: hair spray (0.0157)\n",
      "\n",
      "File: dataset_coco/images/000000338905.jpg\n",
      "Prompt: A group of people sitting at a table eating food.\n",
      "Top-10 logits:\n",
      "  logit 582: grocery store (0.4119)\n",
      "  logit 467: butcher shop (0.3186)\n",
      "  logit 762: restaurant (0.1479)\n",
      "  logit 415: bakery (0.0192)\n",
      "  logit 509: confectionery (0.0082)\n",
      "  logit 454: bookshop (0.0076)\n",
      "  logit 788: shoe shop (0.0067)\n",
      "  logit 922: menu (0.0062)\n",
      "  logit 963: pizza (0.0045)\n",
      "  logit 112: conch (0.0037)\n",
      "\n",
      "File: dataset_coco/images/000000345466.jpg\n",
      "Prompt: A pitcher holds his arm far behind him during a pitch.\n",
      "Top-10 logits:\n",
      "  logit 981: ballplayer (0.8528)\n",
      "  logit 429: baseball (0.1472)\n",
      "  logit 560: football helmet (0.0000)\n",
      "  logit 752: racket (0.0000)\n",
      "  logit 781: scoreboard (0.0000)\n",
      "  logit 768: rugby ball (0.0000)\n",
      "  logit 574: golf ball (0.0000)\n",
      "  logit 805: soccer ball (0.0000)\n",
      "  logit 621: lawn mower (0.0000)\n",
      "  logit 703: park bench (0.0000)\n",
      "\n",
      "File: dataset_coco/images/000000377486.jpg\n",
      "Prompt: A person riding a horse in the dirt near a wall.\n",
      "Top-10 logits:\n",
      "  logit 275: African hunting dog (0.3459)\n",
      "  logit 354: Arabian camel (0.1864)\n",
      "  logit 350: ibex (0.1036)\n",
      "  logit 345: ox (0.0464)\n",
      "  logit 690: oxcart (0.0320)\n",
      "  logit 349: bighorn (0.0237)\n",
      "  logit 351: hartebeest (0.0237)\n",
      "  logit 172: whippet (0.0151)\n",
      "  logit 210: German short-haired pointer (0.0105)\n",
      "  logit 343: warthog (0.0104)\n",
      "\n",
      "File: dataset_coco/images/000000389315.jpg\n",
      "Prompt: Altered photograph of a case full of paperback novels\n",
      "Top-10 logits:\n",
      "  logit 692: packet (0.4104)\n",
      "  logit 478: carton (0.0727)\n",
      "  logit 720: pill bottle (0.0568)\n",
      "  logit 917: comic book (0.0353)\n",
      "  logit 767: rubber eraser (0.0351)\n",
      "  logit 419: Band Aid (0.0280)\n",
      "  logit 631: lotion (0.0228)\n",
      "  logit 893: wallet (0.0185)\n",
      "  logit 721: pillow (0.0182)\n",
      "  logit 838: sunscreen (0.0150)\n",
      "\n",
      "File: dataset_coco/images/000000438876.jpg\n",
      "Prompt: A senior tennis player prepares to backhand the ball.\n",
      "Top-10 logits:\n",
      "  logit 752: racket (0.3945)\n",
      "  logit 852: tennis ball (0.0893)\n",
      "  logit 880: unicycle (0.0829)\n",
      "  logit 444: bicycle-built-for-two (0.0596)\n",
      "  logit 522: croquet ball (0.0511)\n",
      "  logit 621: lawn mower (0.0404)\n",
      "  logit 981: ballplayer (0.0382)\n",
      "  logit 429: baseball (0.0216)\n",
      "  logit 491: chain saw (0.0179)\n",
      "  logit 805: soccer ball (0.0073)\n",
      "\n",
      "File: dataset_coco/images/000000439426.jpg\n",
      "Prompt: A left hand holding a glazed doughnut over a tiled floor.\n",
      "Top-10 logits:\n",
      "  logit 932: pretzel (0.2487)\n",
      "  logit 253: basenji (0.0968)\n",
      "  logit 173: Ibizan hound (0.0861)\n",
      "  logit 930: French loaf (0.0692)\n",
      "  logit 332: Angora (0.0568)\n",
      "  logit 263: Pembroke (0.0524)\n",
      "  logit 260: chow (0.0498)\n",
      "  logit 374: langur (0.0410)\n",
      "  logit 338: guinea pig (0.0401)\n",
      "  logit 259: Pomeranian (0.0394)\n",
      "\n",
      "File: dataset_coco/images/000000450399.jpg\n",
      "Prompt: a man is standing behind a glass counter\n",
      "Top-10 logits:\n",
      "  logit 415: bakery (0.5083)\n",
      "  logit 739: potter's wheel (0.1856)\n",
      "  logit 467: butcher shop (0.0483)\n",
      "  logit 582: grocery store (0.0400)\n",
      "  logit 499: cleaver (0.0282)\n",
      "  logit 617: lab coat (0.0269)\n",
      "  logit 923: plate (0.0263)\n",
      "  logit 762: restaurant (0.0200)\n",
      "  logit 118: Dungeness crab (0.0175)\n",
      "  logit 910: wooden spoon (0.0151)\n",
      "\n",
      "File: dataset_coco/images/000000452784.jpg\n",
      "Prompt: A plate of food that includes lentils and leafy greens.\n",
      "Top-10 logits:\n",
      "  logit 738: pot (0.1599)\n",
      "  logit 937: broccoli (0.1166)\n",
      "  logit 926: hot pot (0.0762)\n",
      "  logit 924: guacamole (0.0700)\n",
      "  logit 945: bell pepper (0.0648)\n",
      "  logit 125: hermit crab (0.0497)\n",
      "  logit 1: goldfish (0.0333)\n",
      "  logit 809: soup bowl (0.0292)\n",
      "  logit 122: American lobster (0.0240)\n",
      "  logit 120: fiddler crab (0.0239)\n",
      "\n",
      "File: dataset_coco/images/000000454750.jpg\n",
      "Prompt: A larger zebra resting its head on a smaller zebra.\n",
      "Top-10 logits:\n",
      "  logit 340: zebra (0.9975)\n",
      "  logit 292: tiger (0.0016)\n",
      "  logit 282: tiger cat (0.0001)\n",
      "  logit 697: pajama (0.0001)\n",
      "  logit 542: drumstick (0.0001)\n",
      "  logit 614: kimono (0.0001)\n",
      "  logit 506: coil (0.0000)\n",
      "  logit 351: hartebeest (0.0000)\n",
      "  logit 806: sock (0.0000)\n",
      "  logit 831: studio couch (0.0000)\n",
      "\n",
      "File: dataset_coco/images/000000460682.jpg\n",
      "Prompt: a horse that is laying down in a field\n",
      "Top-10 logits:\n",
      "  logit 460: breakwater (0.2672)\n",
      "  logit 913: wreck (0.0777)\n",
      "  logit 346: water buffalo (0.0724)\n",
      "  logit 976: promontory (0.0695)\n",
      "  logit 978: seashore (0.0553)\n",
      "  logit 649: megalith (0.0362)\n",
      "  logit 408: amphibian (0.0288)\n",
      "  logit 472: canoe (0.0220)\n",
      "  logit 345: ox (0.0202)\n",
      "  logit 150: sea lion (0.0181)\n",
      "\n",
      "File: dataset_coco/images/000000474078.jpg\n",
      "Prompt: a baseball player bunting at a baseball on a field\n",
      "Top-10 logits:\n",
      "  logit 981: ballplayer (0.8949)\n",
      "  logit 701: parachute (0.0655)\n",
      "  logit 429: baseball (0.0233)\n",
      "  logit 763: revolver (0.0047)\n",
      "  logit 764: rifle (0.0021)\n",
      "  logit 414: backpack (0.0010)\n",
      "  logit 665: moped (0.0009)\n",
      "  logit 303: long-horned beetle (0.0006)\n",
      "  logit 518: crash helmet (0.0004)\n",
      "  logit 758: reel (0.0003)\n",
      "\n",
      "File: dataset_coco/images/000000488385.jpg\n",
      "Prompt: The motorcycles are parked on the side of the building.\n",
      "Top-10 logits:\n",
      "  logit 665: moped (0.4578)\n",
      "  logit 535: disk brake (0.3622)\n",
      "  logit 670: motor scooter (0.0680)\n",
      "  logit 671: mountain bike (0.0284)\n",
      "  logit 880: unicycle (0.0093)\n",
      "  logit 870: tricycle (0.0090)\n",
      "  logit 444: bicycle-built-for-two (0.0081)\n",
      "  logit 632: loudspeaker (0.0039)\n",
      "  logit 691: oxygen mask (0.0032)\n",
      "  logit 414: backpack (0.0028)\n",
      "\n",
      "File: dataset_coco/images/000000495732.jpg\n",
      "Prompt: Two men play Wii in a cramped living room.\n",
      "Top-10 logits:\n",
      "  logit 608: jean (0.4854)\n",
      "  logit 391: coho (0.0371)\n",
      "  logit 747: punching bag (0.0357)\n",
      "  logit 474: cardigan (0.0296)\n",
      "  logit 465: bulletproof vest (0.0231)\n",
      "  logit 834: suit (0.0174)\n",
      "  logit 480: cash machine (0.0155)\n",
      "  logit 490: chain mail (0.0149)\n",
      "  logit 597: holster (0.0143)\n",
      "  logit 713: photocopier (0.0140)\n",
      "\n",
      "File: dataset_coco/images/000000507235.jpg\n",
      "Prompt: well cooked food in a big bowl on a table\n",
      "Top-10 logits:\n",
      "  logit 923: plate (0.2650)\n",
      "  logit 937: broccoli (0.2530)\n",
      "  logit 926: hot pot (0.0983)\n",
      "  logit 964: potpie (0.0890)\n",
      "  logit 118: Dungeness crab (0.0574)\n",
      "  logit 924: guacamole (0.0297)\n",
      "  logit 938: cauliflower (0.0250)\n",
      "  logit 809: soup bowl (0.0248)\n",
      "  logit 910: wooden spoon (0.0241)\n",
      "  logit 933: cheeseburger (0.0187)\n",
      "\n",
      "File: dataset_coco/images/000000511384.jpg\n",
      "Prompt: A person tossing an orange frisbee on top of a green field.\n",
      "Top-10 logits:\n",
      "  logit 417: balloon (0.7373)\n",
      "  logit 701: parachute (0.0610)\n",
      "  logit 405: airship (0.0405)\n",
      "  logit 920: traffic light (0.0375)\n",
      "  logit 970: alp (0.0165)\n",
      "  logit 448: birdhouse (0.0106)\n",
      "  logit 90: lorikeet (0.0089)\n",
      "  logit 723: pinwheel (0.0083)\n",
      "  logit 637: mailbox (0.0061)\n",
      "  logit 900: water tower (0.0055)\n",
      "\n",
      "File: dataset_coco/images/000000548267.jpg\n",
      "Prompt: A herd of sheep grazing on a lush green field.\n",
      "Top-10 logits:\n",
      "  logit 970: alp (0.3648)\n",
      "  logit 979: valley (0.3357)\n",
      "  logit 825: stone wall (0.0891)\n",
      "  logit 672: mountain tent (0.0255)\n",
      "  logit 980: volcano (0.0173)\n",
      "  logit 958: hay (0.0141)\n",
      "  logit 888: viaduct (0.0138)\n",
      "  logit 975: lakeside (0.0127)\n",
      "  logit 912: worm fence (0.0120)\n",
      "  logit 483: castle (0.0105)\n",
      "\n",
      "File: dataset_coco/images/000000553788.jpg\n",
      "Prompt: there is a woman laying in a bed using a lap top\n",
      "Top-10 logits:\n",
      "  logit 593: harmonica (0.0879)\n",
      "  logit 918: crossword puzzle (0.0589)\n",
      "  logit 691: oxygen mask (0.0578)\n",
      "  logit 813: spatula (0.0519)\n",
      "  logit 620: laptop (0.0363)\n",
      "  logit 749: quill (0.0300)\n",
      "  logit 558: flute (0.0288)\n",
      "  logit 680: nipple (0.0271)\n",
      "  logit 823: stethoscope (0.0242)\n",
      "  logit 784: screwdriver (0.0214)\n",
      "\n",
      "File: dataset_coco/images/000000560474.jpg\n",
      "Prompt: a wax head is looking out of a car window\n",
      "Top-10 logits:\n",
      "  logit 148: killer whale (0.6076)\n",
      "  logit 851: television (0.0625)\n",
      "  logit 582: grocery store (0.0311)\n",
      "  logit 664: monitor (0.0297)\n",
      "  logit 627: limousine (0.0183)\n",
      "  logit 511: convertible (0.0124)\n",
      "  logit 761: remote control (0.0119)\n",
      "  logit 704: parking meter (0.0097)\n",
      "  logit 412: ashcan (0.0092)\n",
      "  logit 527: desktop computer (0.0091)\n",
      "\n",
      "File: dataset_coco/images/000000569030.jpg\n",
      "Prompt: A woman is standing at a crosswalk at a traffic intersection.\n",
      "Top-10 logits:\n",
      "  logit 920: traffic light (0.6256)\n",
      "  logit 703: park bench (0.0762)\n",
      "  logit 704: parking meter (0.0421)\n",
      "  logit 832: stupa (0.0209)\n",
      "  logit 682: obelisk (0.0137)\n",
      "  logit 646: maze (0.0086)\n",
      "  logit 421: bannister (0.0073)\n",
      "  logit 562: fountain (0.0061)\n",
      "  logit 612: jinrikisha (0.0059)\n",
      "  logit 874: trolleybus (0.0055)\n",
      "\n",
      "File: dataset_coco/images/000000575970.jpg\n",
      "Prompt: The living room is nicely cleaned and organized.\n",
      "Top-10 logits:\n",
      "  logit 624: library (0.2610)\n",
      "  logit 532: dining table (0.1566)\n",
      "  logit 453: bookcase (0.1323)\n",
      "  logit 526: desk (0.1166)\n",
      "  logit 548: entertainment center (0.1017)\n",
      "  logit 905: window shade (0.0557)\n",
      "  logit 495: china cabinet (0.0367)\n",
      "  logit 651: microwave (0.0316)\n",
      "  logit 762: restaurant (0.0174)\n",
      "  logit 648: medicine chest (0.0166)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Funzione per estrazione logits\n",
    "import csv\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "\n",
    "def get_topk(logits, k=10):\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    top_p, top_i = torch.topk(probs, k)\n",
    "    return [(int(i), (idx2label[int(i)], float(p))) for p, i in zip(top_p.cpu(), top_i.cpu())]\n",
    "\n",
    "# Carica prompt da CSV\n",
    "prompts = {}\n",
    "with open(META_CSV, newline='') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        prompts[Path(row[\"file\"]).name] = row[\"prompt\"]#attenzione file_name \n",
    "\n",
    "# Analisi immagini\n",
    "results = []\n",
    "for img_path in tqdm(sorted(IMG_DIR.glob(\"*.jpg\"))):\n",
    "    prompt = prompts.get(img_path.name)\n",
    "    if not prompt:\n",
    "        continue\n",
    "\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    with torch.no_grad():\n",
    "        logits = model(transform(image).unsqueeze(0).to(device))\n",
    "\n",
    "    top_logits = get_topk(logits[0])\n",
    "    results.append({\n",
    "        \"file_name\": str(img_path),\n",
    "        \"prompt\": prompt,\n",
    "        \"top_logits\": top_logits\n",
    "    })\n",
    "for r in results:\n",
    "    print(f\"\\nFile: {r['file_name']}\")\n",
    "    print(f\"Prompt: {r['prompt']}\")\n",
    "    print(\"Top-10 logits:\")\n",
    "    for logit_idx, (label, prob) in r[\"top_logits\"]:\n",
    "        print(f\"  logit {logit_idx}: {label} ({prob:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d479795",
   "metadata": {},
   "source": [
    "ü§ñ Valutazione coerenza con LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fc0a408d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM analysis: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:29<00:00,  1.79s/it]\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 ‚Äì OpenAI LLM check (coherence audit)\n",
    "import openai, json, re, csv\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F   # se vuoi usare entropia pi√π avanti\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "incoherent = []\n",
    "\n",
    "# ---------- helper: extract first valid JSON block ----------\n",
    "def extract_json_from_text(text: str) -> dict:\n",
    "    \"\"\"Return the first JSON object found inside <text>; raise if none.\"\"\"\n",
    "    try:\n",
    "        match = re.search(r\"\\{.*?\\}\", text, re.DOTALL)\n",
    "        if match:\n",
    "            return json.loads(match.group(0))\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"‚ö†Ô∏è JSON decoding error:\", e)\n",
    "    raise ValueError(\"‚ö†Ô∏è No valid JSON found in the LLM response.\")\n",
    "\n",
    "# ---------- helper: query GPT for vision‚Äìtext coherence ----------\n",
    "def query_llm(prompt: str, top_logits, vision_model=VISION_MODEL) -> dict:\n",
    "    \"\"\"\n",
    "    Ask the LLM if the <top_logits> predicted by <vision_model>\n",
    "    are semantically coherent with <prompt>.\n",
    "    Returns a dict {coherent, score, explanation, confidence?}\n",
    "    \"\"\"\n",
    "    top_str = \"; \".join(\n",
    "    [f\"{lbl_prob[0]} ({lbl_prob[1]:.3f})\" for _, lbl_prob in top_logits]\n",
    ")\n",
    "\n",
    "    user_msg = f\"\"\"\n",
    "You are auditing a computer-vision pipeline that uses **{vision_model}**.\n",
    "\n",
    "Prompt (English):\n",
    "\\\"{prompt}\\\"\n",
    "\n",
    "Top-10 predictions from {vision_model} with soft-max probabilities:\n",
    "{top_str}\n",
    "\n",
    "Tasks (answer in JSON only):\n",
    "1. \"coherent\": \"yes\" if the predictions match the prompt, else \"no\".\n",
    "2. \"score\": coherence between 0.0 and 1.0 (1 = perfect match).\n",
    "3. \"explanation\": ‚â§ 25-word sentence on mismatch or potential bias.\n",
    "4. (optional) \"confidence\": your confidence in this judgement (0-1).\n",
    "\n",
    "Respond **only** with valid JSON ‚Äì no markdown, no extra text.\n",
    "\"\"\"\n",
    "\n",
    "    res = openai.chat.completions.create(\n",
    "        model=LLM_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\",\n",
    "             \"content\": \"You are a senior vision-language auditor who MUST return strict JSON.\"},\n",
    "            {\"role\": \"user\", \"content\": user_msg}\n",
    "        ],\n",
    "        temperature=0.0      # deterministic\n",
    "    )\n",
    "\n",
    "    response_text = res.choices[0].message.content.strip()\n",
    "    return extract_json_from_text(response_text)\n",
    "\n",
    "# ---------- run the audit over all images ----------\n",
    "with open(logits_path, \"w\") as fout:\n",
    "    for r in tqdm(results, desc=\"LLM analysis\"):\n",
    "        llm_data = query_llm(r[\"prompt\"], r[\"top_logits\"])\n",
    "        record = {**r, **llm_data}\n",
    "        fout.write(json.dumps(record) + \"\\n\")\n",
    "\n",
    "        # collect incoherent cases for later reporting\n",
    "        if llm_data[\"score\"] < COHERENCE_THRESHOLD:\n",
    "            incoherent.append(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaae9b7a",
   "metadata": {},
   "source": [
    "üìù Generazione report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b1d1a650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Report saved to: analysis_out_coco_alex/report.md\n"
     ]
    }
   ],
   "source": [
    "# üìä Cell 6 ‚Äì Bias report & model verdict  (English, model-aware)\n",
    "\n",
    "summary_prompt = f\"\"\"\n",
    "You are an AI-bias auditor. The following JSON array (one object per image) has:\n",
    "- file_name          : image path\n",
    "- prompt             : prompt used to generate the image\n",
    "- top_logits         : list of (label, prob) returned by the vision model\n",
    "- coherent           : \"yes\" / \"no\"\n",
    "- score              : coherence score [0-1]\n",
    "- explanation        : comment generated by the LLM\n",
    "\n",
    "Your tasks (answer in **Markdown** ‚á¢ sections starting with ##):\n",
    "\n",
    "## 1 Aggregate statistics\n",
    "‚Ä¢ number of images  \n",
    "‚Ä¢ mean, median, stdev of the scores  \n",
    "‚Ä¢ % of incoherent images (score < {COHERENCE_THRESHOLD})\n",
    "\n",
    "## 2 Recurring error patterns  \n",
    "Identify the most frequent error types (e.g. background vs foreground confusion, color dominance).  \n",
    "Link each pattern to potential biases in the vision model (**{VISION_MODEL}**), such as dataset bias, architecture, or pre-training artifacts.\n",
    "\n",
    "## 3 Detailed list of incoherent images  \n",
    "For every image with score < {COHERENCE_THRESHOLD} show:  \n",
    "‚Ä¢ file_name  \n",
    "‚Ä¢ a  ‚â§ 15-word summary of the prompt  \n",
    "‚Ä¢ the three most problematic labels with probabilities  \n",
    "‚Ä¢ the ‚Äòexplanation‚Äô in ‚â§ 2 sentences\n",
    "\n",
    "## 4 Main biases of the model  \n",
    "Infer at least three systematic biases, citing representative examples.\n",
    "\n",
    "## 5 Overall verdict  \n",
    "‚Ä¢ Bullet points: strengths and weaknesses of **{VISION_MODEL}**  \n",
    "‚Ä¢ A final reliability rating **1 (very poor) ‚Äì 5 (excellent)**  \n",
    "‚Ä¢ *No mitigation advice* ‚Äì deliver only critical analysis.\n",
    "\n",
    "Respond **only** in Markdown, no additional JSON or code blocks.\n",
    "\"\"\"\n",
    "\n",
    "# Dump the incoherent cases more compactly\n",
    "user_data = json.dumps(incoherent, indent=2)\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=LLM_MODEL,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a senior AI-bias analyst who MUST reply in Markdown headings.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": summary_prompt + \"\\n```json\\n\" + user_data + \"\\n```\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.25  # low creativity, but allows variation\n",
    ")\n",
    "\n",
    "report_md = response.choices[0].message.content\n",
    "(OUTPUT_DIR / \"report.md\").write_text(report_md, encoding=\"utf-8\")\n",
    "print(\"‚úÖ Report saved to:\", OUTPUT_DIR / \"report.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81372111",
   "metadata": {},
   "source": [
    "üì∫ Visualizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3f337cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report salvato in: analysis_out_coco_alex/report.md\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## 1 Aggregate statistics\n",
       "- **Number of images:** 100\n",
       "- **Mean score:** 0.17\n",
       "- **Median score:** 0.2\n",
       "- **Standard deviation of scores:** 0.09\n",
       "- **Percentage of incoherent images (score < 0.3):** 100%\n",
       "\n",
       "## 2 Recurring error patterns\n",
       "- **Foreground vs Background Confusion:** Many images incorrectly identify objects that are not relevant to the main subject (e.g., predicting animals instead of people).\n",
       "  - **Bias Link:** This may stem from dataset bias where the training data over-represents certain categories (e.g., animals) over others.\n",
       "  \n",
       "- **Object Misclassification:** Common misclassifications include predicting food items unrelated to the prompt (e.g., predicting \"cheeseburger\" for \"cheese bread\").\n",
       "  - **Bias Link:** This could be due to pre-training artifacts where the model has learned to associate certain food items with high frequency in the dataset.\n",
       "\n",
       "- **Contextual Relevance Issues:** The model often fails to connect the context of the prompt with the predicted labels (e.g., predicting \"traffic light\" for a scene with a person at a crosswalk).\n",
       "  - **Bias Link:** This suggests a limitation in the model's architecture to understand contextual relationships, possibly due to insufficient training on diverse scenarios.\n",
       "\n",
       "## 3 Detailed list of incoherent images\n",
       "1. **file_name:** dataset_coco/images/000000010764.jpg  \n",
       "   **Summary of prompt:** Crouching cat on dirt.  \n",
       "   **Problematic labels:** \n",
       "   - \"baseball\" (0.51)\n",
       "   - \"ballplayer\" (0.49)\n",
       "   - \"crash helmet\" (0.0000187)  \n",
       "   **Explanation:** Predictions focus on sports equipment, not on a crouching action or dirt context.\n",
       "\n",
       "2. **file_name:** dataset_coco/images/000000017178.jpg  \n",
       "   **Summary of prompt:** Horses communing on a street.  \n",
       "   **Problematic labels:** \n",
       "   - \"Indian elephant\" (0.32)\n",
       "   - \"oxcart\" (0.20)\n",
       "   - \"water buffalo\" (0.19)  \n",
       "   **Explanation:** Predictions focus on elephants and carts, not horses as mentioned in the prompt.\n",
       "\n",
       "3. **file_name:** dataset_coco/images/000000025394.jpg  \n",
       "   **Summary of prompt:** Bartender opening wine bottle.  \n",
       "   **Problematic labels:** \n",
       "   - \"steel drum\" (0.11)\n",
       "   - \"beer glass\" (0.08)\n",
       "   - \"drumstick\" (0.08)  \n",
       "   **Explanation:** Predictions focus on drinkware and instruments, not directly related to opening wine.\n",
       "\n",
       "4. **file_name:** dataset_coco/images/000000087875.jpg  \n",
       "   **Summary of prompt:** Hadron in a lot.  \n",
       "   **Problematic labels:** \n",
       "   - \"milk can\" (0.19)\n",
       "   - \"indigo bunting\" (0.17)\n",
       "   - \"birdhouse\" (0.11)  \n",
       "   **Explanation:** Predictions do not relate to hadrons or the context of the prompt.\n",
       "\n",
       "5. **file_name:** dataset_coco/images/000000108253.jpg  \n",
       "   **Summary of prompt:** Plate of cheese bread and wine.  \n",
       "   **Problematic labels:** \n",
       "   - \"cheeseburger\" (0.68)\n",
       "   - \"burrito\" (0.10)\n",
       "   - \"hotdog\" (0.06)  \n",
       "   **Explanation:** Predictions focus on different food items, lacking relevance to cheese bread and wine.\n",
       "\n",
       "6. **file_name:** dataset_coco/images/000000125062.jpg  \n",
       "   **Summary of prompt:** Teddy bears on shelf.  \n",
       "   **Problematic labels:** \n",
       "   - \"ocarina\" (0.26)\n",
       "   - \"toyshop\" (0.09)\n",
       "   - \"African grey\" (0.06)  \n",
       "   **Explanation:** Predictions focus on animals and unrelated items, not matching the teddy bears or DVDs in the prompt.\n",
       "\n",
       "7. **file_name:** dataset_coco/images/000000127624.jpg  \n",
       "   **Summary of prompt:** Train next to station.  \n",
       "   **Problematic labels:** \n",
       "   - \"lakeside\" (0.25)\n",
       "   - \"dock\" (0.10)\n",
       "   - \"castle\" (0.06)  \n",
       "   **Explanation:** Predictions focus on water-related structures, not relevant to trains or city settings.\n",
       "\n",
       "8. **file_name:** dataset_coco/images/000000143556.jpg  \n",
       "   **Summary of prompt:** Bikers on motorcycles.  \n",
       "   **Problematic labels:** \n",
       "   - \"go-kart\" (0.53)\n",
       "   - \"motor scooter\" (0.10)\n",
       "   - \"moped\" (0.07)  \n",
       "   **Explanation:** Predictions focus on smaller vehicles, not matching the prompt about bikers on motorcycles.\n",
       "\n",
       "9. **file_name:** dataset_coco/images/000000165713.jpg  \n",
       "   **Summary of prompt:** Rusted fire hydrant next to poles.  \n",
       "   **Problematic labels:** \n",
       "   - \"cuirass\" (0.18)\n",
       "   - \"mailbox\" (0.09)\n",
       "   - \"pop bottle\" (0.09)  \n",
       "   **Explanation:** Predictions do not relate to a fire hydrant or poles, indicating a significant mismatch.\n",
       "\n",
       "10. **file_name:** dataset_coco/images/000000168619.jpg  \n",
       "    **Summary of prompt:** Road along field under cloudy sky.  \n",
       "    **Problematic labels:** \n",
       "    - \"megalith\" (0.19)\n",
       "    - \"alp\" (0.13)\n",
       "    - \"yurt\" (0.11)  \n",
       "    **Explanation:** Predictions focus on structures and landscapes, not directly related to a road or field.\n",
       "\n",
       "## 4 Main biases of the model\n",
       "1. **Animal Overrepresentation:** The model often predicts animals in contexts where they are not present, indicating a bias towards animal categories in the training dataset.\n",
       "   - **Example:** Predicting \"Indian elephant\" for a prompt about horses.\n",
       "\n",
       "2. **Food Misclassification:** The model frequently misclassifies food items, suggesting a bias in training data that favors certain food categories.\n",
       "   - **Example:** Predicting \"cheeseburger\" for a prompt about cheese bread.\n",
       "\n",
       "3. **Contextual Disconnection:** The model struggles to connect the context of prompts with appropriate predictions, indicating a lack of understanding of scene composition.\n",
       "   - **Example:** Predicting \"traffic light\" for a scene with a person at a crosswalk.\n",
       "\n",
       "## 5 Overall verdict\n",
       "- **Strengths:**\n",
       "  - High confidence in predictions (average confidence of 0.9).\n",
       "  - Ability to recognize a wide range of objects.\n",
       "\n",
       "- **Weaknesses:**\n",
       "  - Consistent incoherence in predictions across various prompts.\n",
       "  - Significant misclassification and contextual relevance issues.\n",
       "  - Overrepresentation of certain categories leading to biased outputs.\n",
       "\n",
       "- **Final reliability rating:** 1 (very poor)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 7: Output finale\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "print(\"Report salvato in:\", OUTPUT_DIR / \"report.md\")\n",
    "display(Markdown(report_md))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
